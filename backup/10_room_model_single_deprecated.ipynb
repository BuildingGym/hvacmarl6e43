{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8090027795142a9ae6680d1e6c17543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import controllables.energyplus as _ooep_\n",
    "from energyplus.dataset.basic import dataset as _epds_\n",
    "\n",
    "simulator = _ooep_.World(\n",
    "    input=_ooep_.World.Specs.Input(\n",
    "        world='tmp_timestep 10 min.idf',\n",
    "        weather='SGP_Singapore_486980_IWEC.epw',\n",
    "    ),\n",
    "    # output=_ooep_.World.Specs.Output(\n",
    "    #     report='./tmp',\n",
    "    # ),\n",
    "    runtime=_ooep_.World.Specs.Runtime(\n",
    "        recurring=True,\n",
    "        #design_day=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# add progress provider\n",
    "_ = simulator.add('logging:progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_hlvbl9og'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_jw8xvbgo'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_puimws66'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_1lbwywfy'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_jh3lrm6z'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_5ezo3n4x'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_4mx8h1b4'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_4oxm6b3z'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_hbhgc292'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_bft2ftof'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_5k4s46d2'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_1ygwfgpj'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_3hkcvf1f'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_n1nnfsx3'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_d2akgxwe'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_y66109h0'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output__d7mogui'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_mjfnlgbu'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_ao_fh1cp'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_i4gwmic6'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_4rjhh85s'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_vsur0q16'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_ishj4r9n'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_aw43whb3'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output__s_7wds3'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_jvo60np7'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_g61735rd'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_jb2yscz7'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_6dzm3fn5'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_6j7y2wsc'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_j689lapu'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_qwixmalt'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_dolpnrbv'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_e5aixh9a'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_rwxv1ct3'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_thogefln'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_suv__z3t'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_nsb8xtwx'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_k1xtplvg'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_j9g72s9q'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_ptfpidxo'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_gwji5p9g'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_wl_ztwot'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_crjotjbl'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "Exception ignored on calling ctypes callback function: <function EventManager._core_callback_setters.<locals>._Dispatcher._state at 0x7fb6584c5120>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/energyplus/events.py\", line 212, in cb_\n",
      "    raise e\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/energyplus/events.py\", line 209, in cb_\n",
      "    return cb(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/energyplus/events.py\", line 200, in _state\n",
      "    self._manager.__call__(\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/energyplus/events.py\", line 291, in __call__\n",
      "    return super().__call__(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/core/callbacks.py\", line 619, in __call__\n",
      "    return self[ref].__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/energyplus/events.py\", line 102, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/core/callbacks.py\", line 563, in __call__\n",
      "    return self._callables.__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/core/callbacks.py\", line 87, in __call__\n",
      "    res[f] = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/core/tools/ray/env.py\", line 318, in <lambda>\n",
      "    ('step', lambda _, tracker=tracker: tracker.step()),\n",
      "                                        ^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/core/tools/ray/env.py\", line 258, in step\n",
      "    self._manager.action.value = self.get_action()\n",
      "                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/core/tools/ray/env.py\", line 272, in get_action\n",
      "    return super().get_action(observation=observation)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/controllables/core/tools/ray/env.py\", line 146, in get_action\n",
      "    return self._manager.get_action(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/env/external_env.py\", line 136, in get_action\n",
      "    return episode.wait_for_action(observation)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/env/external_env.py\", line 296, in wait_for_action\n",
      "    return self.action_queue.get(True, timeout=300.0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/queue.py\", line 179, in get\n",
      "    raise Empty\n",
      "_queue.Empty: \n"
     ]
    }
   ],
   "source": [
    "_ = simulator.awaitable.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as _numpy_\n",
    "\n",
    "from controllables.core import TemporaryUnavailableError\n",
    "from controllables.core.tools.gymnasium import BoxSpace, DictSpace\n",
    "from controllables.core.tools.rllib import Env\n",
    "from controllables.energyplus import Actuator, OutputVariable\n",
    "from controllables.energyplus import System\n",
    "\n",
    "\n",
    "class UserEnv(Env):\n",
    "    action_space = DictSpace({\n",
    "        'thermostat': BoxSpace(\n",
    "            low=15., high=20.,\n",
    "            dtype=_numpy_.float32,\n",
    "            shape=(),\n",
    "        ).bind(\n",
    "            Actuator.Ref(\n",
    "                type='Zone Temperature Control',\n",
    "                control_type='Heating Setpoint',\n",
    "                key='MAIN ZONE',\n",
    "            )            \n",
    "        )\n",
    "    })\n",
    "\n",
    "    observation_space = DictSpace({\n",
    "        'temperature': BoxSpace(\n",
    "            low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "            dtype=_numpy_.float32,\n",
    "            shape=(),\n",
    "        ).bind(\n",
    "            OutputVariable.Ref(\n",
    "                type='Zone Mean Air Temperature',\n",
    "                key='MAIN ZONE',\n",
    "            )\n",
    "        ),\n",
    "    })\n",
    "\n",
    "    @staticmethod\n",
    "    def reward(agent):\n",
    "        r\"\"\"\n",
    "        Reward function.\n",
    "\n",
    "        This reward function aims to minimize the control error, \n",
    "        i.e., the difference between the thermostat setpoint and the actual temperature.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            return -abs(\n",
    "                agent.observation['temperature'].value - agent.action['thermostat'].value\n",
    "            )\n",
    "        except TemporaryUnavailableError:\n",
    "            return 0.\n",
    "\n",
    "    def __init__(self, config: dict = dict()):\n",
    "        super().__init__({\n",
    "            'action_space': self.__class__.action_space,\n",
    "            'observation_space': self.__class__.observation_space,\n",
    "            'reward': self.__class__.reward,\n",
    "            **config,\n",
    "        })\n",
    "\n",
    "    def run(self):\n",
    "        system = System(\n",
    "            building='all_room_have_hvac.idf',\n",
    "            weather='SGP_Singapore_486980_IWEC.epw',\n",
    "            # TODO\n",
    "            report='tmp/',\n",
    "            repeat=True,\n",
    "        )\n",
    "        # system.add('logging:progress')\n",
    "        self.__attach__(system).schedule_episode()\n",
    "        system.start().wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/tempfile.py:1043: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/.energyplus_output_k8sl442p'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:442: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-09-13 05:44:23,438\tWARNING env.py:85 -- Env checking isn't implemented for RemoteBaseEnvs, ExternalMultiAgentEnv, ExternalEnvs or environments that are Ray actors.\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/catalog.py:789: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  prep = cls(observation_space, options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/catalog.py:725: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  return wrapper(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/catalog.py:725: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  return wrapper(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  preprocessor = preprocessor_class(space, self._options)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/models/modelv2.py:440: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  prep = get_preprocessor(space)(space)\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "/home/AD/user/lab/reports/2024xxxx/.venv/lib/python3.11/site-packages/ray/rllib/policy/policy.py:1609: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  _, shape = ModelCatalog.get_action_shape(\n",
      "WARNING:ray.tune.utils.util:Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "import numpy as _numpy_\n",
    "import gymnasium as _gymnasium_\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from controllables.core.tools.gymnasium import (\n",
    "    BoxSpace,\n",
    "    DictSpace,\n",
    ")\n",
    "from controllables.core.tools.ray import (\n",
    "    ExternalEnv,\n",
    ")\n",
    "\n",
    "import ray\n",
    "from ray import tune , air\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "from controllables.energyplus import (\n",
    "    World,\n",
    "    Actuator,\n",
    "    OutputVariable,\n",
    ")\n",
    "import pythermalcomfort as pytc\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.impala import ImpalaConfig\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "import logging\n",
    "import csv\n",
    "import math\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', filename='training.log')\n",
    "\n",
    "class CustomExternalEnv(ExternalEnv):\n",
    "    def __init__(self, env_config):\n",
    "        pass\n",
    "\n",
    "    def step(self, action):\n",
    "        pass\n",
    "\n",
    "class RewardFunction:\n",
    "    def __init__(self, metab_rate=1.5, clothing=.5, pmv_limit=.5):\n",
    "        self._metab_rate = _numpy_.asarray(metab_rate)\n",
    "        self._clothing = _numpy_.asarray(clothing)\n",
    "        self._pmv_limit = _numpy_.asarray(pmv_limit)\n",
    "    \n",
    "   \n",
    "    def __call__(self, agent):\n",
    "        observation = agent.observation.value     \n",
    "        AHU_COOLING_COIL = observation['AHU COOLING COIL']\n",
    "        #Fan_Electricity_Rate = observation['Fan Electricity Rate']\n",
    "        Office_Occupancy = observation['Office Occupancy']\n",
    "        total_reward = 0\n",
    "        zones = ['1FWEST', '1FEAST', '0FWEST', '0FEAST']\n",
    "        for zone in zones:\n",
    "            tdb = observation[f'temperature:drybulb_{zone}']\n",
    "            tr = observation[f'temperature:radiant_{zone}']\n",
    "            rh = observation[f'humidity_{zone}']\n",
    "            vr = pytc.utilities.v_relative(v=observation.get('airspeed', .1), met=self._metab_rate)\n",
    "            clo = pytc.utilities.clo_dynamic(clo=self._clothing, met=self._metab_rate)\n",
    "            pmv = pytc.models.pmv_ppd(\n",
    "                    tdb=tdb, \n",
    "                    tr=tr, \n",
    "                    vr=vr, \n",
    "                    rh=rh, \n",
    "                    met=self._metab_rate, \n",
    "                    clo=clo,\n",
    "                    limit_inputs=False,\n",
    "                )['pmv']\n",
    "            zone_reward = 2 * Office_Occupancy * ((self._pmv_limit - _numpy_.abs(pmv)) / self._pmv_limit)\n",
    "            total_reward += zone_reward\n",
    "        total_reward -= (AHU_COOLING_COIL / 180000)\n",
    "        # inputs = {'AHU_energy': AHU_COOLING_COIL, 'tdb': observation['temperature:drybulb'],\n",
    "        #         'tr': observation['temperature:radiant'], \n",
    "        #         'vr': pytc.utilities.v_relative(v=observation.get('airspeed', .1), met=self._metab_rate), \n",
    "        #         'rh': observation['humidity'], 'met': self._metab_rate,\n",
    "        #         'clo': pytc.utilities.clo_dynamic(clo=self._clothing, met=self._metab_rate),\n",
    "        #         'pmv':pmv ,\n",
    "        #         'reward':reward}\n",
    "        # for name, value in inputs.items():\n",
    "        #     if math.isnan(value):\n",
    "        #         print(f\"NaN detected in input: {name}\")\n",
    "        #         print(dict(\n",
    "        #             tdb=(observation['temperature:drybulb']), \n",
    "        #             tr=observation['temperature:radiant'], \n",
    "        #             # calculate relative air speed\n",
    "        #             vr=pytc.utilities.v_relative(v=observation.get('airspeed', .1), met=self._metab_rate), \n",
    "        #             rh=observation['humidity'], \n",
    "        #             met=self._metab_rate, \n",
    "        #             # calculate dynamic clothing\n",
    "        #             clo=pytc.utilities.clo_dynamic(clo=self._clothing, met=self._metab_rate),\n",
    "        #         ))\n",
    "        #         raise Exception('TODO')\n",
    "        # if math.isnan(reward):\n",
    "        #     reward = 0\n",
    "\n",
    "\n",
    "        return total_reward\n",
    "\n",
    "\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "\n",
    "class TraceCallbacks(DefaultCallbacks):\n",
    "    def on_episode_start(self, *, worker, episode, base_env, **kwargs) -> None:\n",
    "        from energyplus.ooep.specs.tools import VariableHistory\n",
    "\n",
    "        env = worker.env\n",
    "\n",
    "        episode._user_history = VariableHistory()\n",
    "        display(\n",
    "            episode._user_history.plot({\n",
    "                'traces': [{\n",
    "                    'x': env.world['wallclock:calendar'], \n",
    "                    'y': env.reward,\n",
    "                }],\n",
    "            }, autoupdate=1_000)\n",
    "        )\n",
    "\n",
    "    def on_episode_step(self, *, worker, episode, base_env, **kwargs) -> None:\n",
    "        episode._user_history.poll()\n",
    "\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(\n",
    "        ExternalEnv,\n",
    "        env_config=ExternalEnv.Config(\n",
    "            action_space=DictSpace({\n",
    "                'thermostat_1FWEST': BoxSpace(\n",
    "                    low=22., high=30.,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(Actuator.Ref(\n",
    "                    type='Zone Temperature Control',\n",
    "                    control_type='Cooling Setpoint',\n",
    "                    key='1FFIRSTFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "                'thermostat_1FEAST': BoxSpace(\n",
    "                    low=22., high=30.,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(Actuator.Ref(\n",
    "                    type='Zone Temperature Control',\n",
    "                    control_type='Cooling Setpoint',\n",
    "                    key='1FFIRSTFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "                'thermostat_0FWEST': BoxSpace(\n",
    "                    low=22., high=30.,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(Actuator.Ref(\n",
    "                    type='Zone Temperature Control',\n",
    "                    control_type='Cooling Setpoint',\n",
    "                    key='0FGROUNDFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "                'thermostat_0FEAST': BoxSpace(\n",
    "                    low=22., high=30.,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(Actuator.Ref(\n",
    "                    type='Zone Temperature Control',\n",
    "                    control_type='Cooling Setpoint',\n",
    "                    key='0FGROUNDFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "            }),    \n",
    "            observation_space=DictSpace({\n",
    "                #1FWEST\n",
    "                'temperature:drybulb_1FWEST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Air Temperature',\n",
    "                    key='1FFIRSTFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "                'temperature:radiant_1FWEST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Radiant Temperature',\n",
    "                    key='1FFIRSTFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "                'humidity_1FWEST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Air Relative Humidity',\n",
    "                    key='1FFIRSTFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "\n",
    "                #1FEAST\n",
    "                'temperature:drybulb_1FEAST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Air Temperature',\n",
    "                    key='1FFIRSTFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "                'temperature:radiant_1FEAST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Radiant Temperature',\n",
    "                    key='1FFIRSTFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "                'humidity_1FEAST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Air Relative Humidity',\n",
    "                    key='1FFIRSTFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "\n",
    "                #0FWEST\n",
    "                'temperature:drybulb_0FWEST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Air Temperature',\n",
    "                    key='0FGROUNDFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "                'temperature:radiant_0FWEST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Radiant Temperature',\n",
    "                    key='0FGROUNDFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "                'humidity_0FWEST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Air Relative Humidity',\n",
    "                    key='0FGROUNDFLOORWEST:OPENOFFICE',\n",
    "                )),\n",
    "\n",
    "                #0FEAST\n",
    "                'temperature:drybulb_0FEAST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Air Temperature',\n",
    "                    key='0FGROUNDFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "                'temperature:radiant_0FEAST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Mean Radiant Temperature',\n",
    "                    key='0FGROUNDFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "                'humidity_0FEAST': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Zone Air Relative Humidity',\n",
    "                    key='0FGROUNDFLOOREAST:OPENOFFICE',\n",
    "                )),\n",
    "\n",
    "                #AHU\n",
    "                'AHU COOLING COIL': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Cooling Coil Total Cooling Rate',\n",
    "                    key='AIR LOOP AHU COOLING COIL',\n",
    "                )),\n",
    "                'Fan Electricity Rate': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Fan Electricity Rate',\n",
    "                    key='AIR LOOP AHU SUPPLY FAN',\n",
    "                )),\n",
    "                'Office Occupancy':BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(OutputVariable.Ref(\n",
    "                    type='Schedule Value',\n",
    "                    key='Office_OpenOff_Occ',\n",
    "                )),\n",
    "            }),\n",
    "            reward_function=RewardFunction(),\n",
    "            episode_events={\n",
    "                'step': 'begin_zone_timestep_after_init_heat_balance',\n",
    "            },\n",
    "            system=lambda: simulator\n",
    "        ),  \n",
    "\n",
    "    )\n",
    "    .rollouts(\n",
    "        num_rollout_workers=0,\n",
    "        enable_connectors=False,\n",
    "    )\n",
    "    .training(\n",
    "        model={\"fcnet_hiddens\": [128, 128]},\n",
    "        lr=0.0001,\n",
    "        train_batch_size=1000,\n",
    "    )\n",
    "    .framework(\"torch\")    \n",
    ")\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U ../../EnergyPlus-OOEP/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.567764001233237, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.59916451772054, 'policy_loss': -0.06418245832125345, 'vf_loss': 9.661329137711299, 'vf_explained_var': -0.0008304505121140253, 'kl': 0.010089638425935327, 'entropy': 5.627097879137311, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 105.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 1000, 'num_env_steps_trained': 1000, 'num_agent_steps_sampled': 1000, 'num_agent_steps_trained': 1000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1000, 'num_agent_steps_trained': 1000, 'num_env_steps_sampled': 1000, 'num_env_steps_trained': 1000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 100.5594165137906, 'num_env_steps_trained_throughput_per_sec': 100.5594165137906, 'timesteps_total': 1000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 1000, 'timers': {'training_iteration_time_ms': 9944.347, 'sample_time_ms': 8453.604, 'load_time_ms': 0.148, 'load_throughput': 6754112.721, 'learn_time_ms': 1490.369, 'learn_throughput': 670.975, 'synch_weights_time_ms': 0.003}, 'counters': {'num_env_steps_sampled': 1000, 'num_env_steps_trained': 1000, 'num_agent_steps_sampled': 1000, 'num_agent_steps_trained': 1000}, 'done': False, 'episodes_total': 0, 'training_iteration': 1, 'trial_id': 'default', 'date': '2024-09-13_05-44-34', 'timestamp': 1726206274, 'time_this_iter_s': 9.944462060928345, 'time_total_s': 9.944462060928345, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7babb60d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 9.944462060928345, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 9.973333333333334, 'ram_util_percent': 12.099999999999998}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.1199669480323795, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.682094301496234, 'policy_loss': -0.009997427463531494, 'vf_loss': 9.690506158556257, 'vf_explained_var': -0.0025007849647885275, 'kl': 0.007927942163358442, 'entropy': 5.666599398567563, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 315.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 2000, 'num_env_steps_trained': 2000, 'num_agent_steps_sampled': 2000, 'num_agent_steps_trained': 2000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 2000, 'num_agent_steps_trained': 2000, 'num_env_steps_sampled': 2000, 'num_env_steps_trained': 2000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.68875142976938, 'num_env_steps_trained_throughput_per_sec': 179.68875142976938, 'timesteps_total': 2000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 2000, 'timers': {'training_iteration_time_ms': 7754.754, 'sample_time_ms': 6265.771, 'load_time_ms': 0.132, 'load_throughput': 7557304.505, 'learn_time_ms': 1488.624, 'learn_throughput': 671.761, 'synch_weights_time_ms': 0.003}, 'counters': {'num_env_steps_sampled': 2000, 'num_env_steps_trained': 2000, 'num_agent_steps_sampled': 2000, 'num_agent_steps_trained': 2000}, 'done': False, 'episodes_total': 0, 'training_iteration': 2, 'trial_id': 'default', 'date': '2024-09-13_05-44-39', 'timestamp': 1726206279, 'time_this_iter_s': 5.5652782917022705, 'time_total_s': 15.509740352630615, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c657fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 15.509740352630615, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 11.225000000000001, 'ram_util_percent': 12.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 13.096832221036866, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.740701897939045, 'policy_loss': -0.032802443490141914, 'vf_loss': 9.770401173546201, 'vf_explained_var': -0.0022463310332525343, 'kl': 0.015515962084810738, 'entropy': 5.554162842886789, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 525.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 3000, 'num_env_steps_trained': 3000, 'num_agent_steps_sampled': 3000, 'num_agent_steps_trained': 3000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3000, 'num_agent_steps_trained': 3000, 'num_env_steps_sampled': 3000, 'num_env_steps_trained': 3000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.46284844270963, 'num_env_steps_trained_throughput_per_sec': 178.46284844270963, 'timesteps_total': 3000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 3000, 'timers': {'training_iteration_time_ms': 7037.634, 'sample_time_ms': 5543.025, 'load_time_ms': 0.127, 'load_throughput': 7864320.0, 'learn_time_ms': 1494.257, 'learn_throughput': 669.229, 'synch_weights_time_ms': 0.003}, 'counters': {'num_env_steps_sampled': 3000, 'num_env_steps_trained': 3000, 'num_agent_steps_sampled': 3000, 'num_agent_steps_trained': 3000}, 'done': False, 'episodes_total': 0, 'training_iteration': 3, 'trial_id': 'default', 'date': '2024-09-13_05-44-45', 'timestamp': 1726206285, 'time_this_iter_s': 5.603485345840454, 'time_total_s': 21.11322569847107, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659505d50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 21.11322569847107, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 11.7375, 'ram_util_percent': 12.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.5134590004171644, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.578421615418934, 'policy_loss': 0.003037832464490618, 'vf_loss': 9.574279026758104, 'vf_explained_var': -0.003029440130506243, 'kl': 0.005523655701524393, 'entropy': 5.6433495362599695, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 735.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.99963967203908, 'num_env_steps_trained_throughput_per_sec': 181.99963967203908, 'timesteps_total': 4000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 4000, 'timers': {'training_iteration_time_ms': 6651.851, 'sample_time_ms': 5155.162, 'load_time_ms': 0.123, 'load_throughput': 8112773.694, 'learn_time_ms': 1496.343, 'learn_throughput': 668.296, 'synch_weights_time_ms': 0.003}, 'counters': {'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'done': False, 'episodes_total': 0, 'training_iteration': 4, 'trial_id': 'default', 'date': '2024-09-13_05-44-50', 'timestamp': 1726206290, 'time_this_iter_s': 5.494598388671875, 'time_total_s': 26.607824087142944, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab1e950>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 26.607824087142944, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 11.6875, 'ram_util_percent': 12.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.9442108208224886, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.4923324630374, 'policy_loss': 0.010492104682184401, 'vf_loss': 9.479855541955857, 'vf_explained_var': -0.0011047613053094772, 'kl': 0.00992443459212414, 'entropy': 5.564585792450678, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 945.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 134.15124049878895, 'num_env_steps_trained_throughput_per_sec': 134.15124049878895, 'timesteps_total': 5000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 5000, 'timers': {'training_iteration_time_ms': 6812.333, 'sample_time_ms': 5317.332, 'load_time_ms': 0.121, 'load_throughput': 8250007.868, 'learn_time_ms': 1494.66, 'learn_throughput': 669.049, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000}, 'done': False, 'episodes_total': 1, 'training_iteration': 5, 'trial_id': 'default', 'date': '2024-09-13_05-44-58', 'timestamp': 1726206298, 'time_this_iter_s': 7.45442271232605, 'time_total_s': 34.062246799468994, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab84650>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 34.062246799468994, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 10.28, 'ram_util_percent': 12.099999999999998}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.50977923926853, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.54600588934762, 'policy_loss': 0.00833614454382942, 'vf_loss': 9.535959498087566, 'vf_explained_var': -0.0023345300129481725, 'kl': 0.008551149941299012, 'entropy': 5.596369366418748, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1155.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 6000, 'num_env_steps_trained': 6000, 'num_agent_steps_sampled': 6000, 'num_agent_steps_trained': 6000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 6000, 'num_agent_steps_trained': 6000, 'num_env_steps_sampled': 6000, 'num_env_steps_trained': 6000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 183.26109448840916, 'num_env_steps_trained_throughput_per_sec': 183.26109448840916, 'timesteps_total': 6000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 6000, 'timers': {'training_iteration_time_ms': 6586.391, 'sample_time_ms': 5096.55, 'load_time_ms': 0.12, 'load_throughput': 8360738.87, 'learn_time_ms': 1489.501, 'learn_throughput': 671.366, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 6000, 'num_env_steps_trained': 6000, 'num_agent_steps_sampled': 6000, 'num_agent_steps_trained': 6000}, 'done': False, 'episodes_total': 1, 'training_iteration': 6, 'trial_id': 'default', 'date': '2024-09-13_05-45-03', 'timestamp': 1726206303, 'time_this_iter_s': 5.456862688064575, 'time_total_s': 39.51910948753357, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659521810>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 39.51910948753357, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 11.8875, 'ram_util_percent': 12.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2733136171386354, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.800363817669096, 'policy_loss': 0.06355782591161274, 'vf_loss': 9.734782368796212, 'vf_explained_var': -0.0013260012581234886, 'kl': 0.010117617087997287, 'entropy': 5.610758295513334, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1365.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 7000, 'num_env_steps_trained': 7000, 'num_agent_steps_sampled': 7000, 'num_agent_steps_trained': 7000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 7000, 'num_agent_steps_trained': 7000, 'num_env_steps_sampled': 7000, 'num_env_steps_trained': 7000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.74232309101959, 'num_env_steps_trained_throughput_per_sec': 180.74232309101959, 'timesteps_total': 7000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 7000, 'timers': {'training_iteration_time_ms': 6435.867, 'sample_time_ms': 4944.163, 'load_time_ms': 0.118, 'load_throughput': 8439243.461, 'learn_time_ms': 1491.367, 'learn_throughput': 670.526, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 7000, 'num_env_steps_trained': 7000, 'num_agent_steps_sampled': 7000, 'num_agent_steps_trained': 7000}, 'done': False, 'episodes_total': 1, 'training_iteration': 7, 'trial_id': 'default', 'date': '2024-09-13_05-45-09', 'timestamp': 1726206309, 'time_this_iter_s': 5.532909393310547, 'time_total_s': 45.052018880844116, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab63dd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 45.052018880844116, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 11.6125, 'ram_util_percent': 12.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.5301592271952402, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.806131467365084, 'policy_loss': 0.16686498253118423, 'vf_loss': 9.63685877209618, 'vf_explained_var': 0.001140432698386056, 'kl': 0.012038325217980898, 'entropy': 5.5803669066656205, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1575.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.58051568418986, 'num_env_steps_trained_throughput_per_sec': 181.58051568418986, 'timesteps_total': 8000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 8000, 'timers': {'training_iteration_time_ms': 6319.782, 'sample_time_ms': 4832.997, 'load_time_ms': 0.118, 'load_throughput': 8447742.195, 'learn_time_ms': 1486.448, 'learn_throughput': 672.745, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'done': False, 'episodes_total': 1, 'training_iteration': 8, 'trial_id': 'default', 'date': '2024-09-13_05-45-14', 'timestamp': 1726206314, 'time_this_iter_s': 5.507328748703003, 'time_total_s': 50.55934762954712, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab84b10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 50.55934762954712, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 11.662500000000001, 'ram_util_percent': 12.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.4220510057040623, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.641295158295405, 'policy_loss': 0.10475608876773289, 'vf_loss': 9.534977699461438, 'vf_explained_var': -0.0071233570575714115, 'kl': 0.007807314048282673, 'entropy': 5.518595686412993, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1785.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 9000, 'num_env_steps_trained': 9000, 'num_agent_steps_sampled': 9000, 'num_agent_steps_trained': 9000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -375.6073166666661, 'episode_reward_mean': -375.6073166666661, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661], 'episode_lengths': [4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1559978196831619, 'mean_inference_ms': 0.9282223466204339, 'mean_action_processing_ms': 0.13445539981639182, 'mean_env_wait_ms': 4.091673067025021, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 9000, 'num_agent_steps_trained': 9000, 'num_env_steps_sampled': 9000, 'num_env_steps_trained': 9000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 184.76860246868026, 'num_env_steps_trained_throughput_per_sec': 184.76860246868026, 'timesteps_total': 9000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 9000, 'timers': {'training_iteration_time_ms': 6218.936, 'sample_time_ms': 4745.865, 'load_time_ms': 0.118, 'load_throughput': 8500053.141, 'learn_time_ms': 1472.737, 'learn_throughput': 679.008, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 9000, 'num_env_steps_trained': 9000, 'num_agent_steps_sampled': 9000, 'num_agent_steps_trained': 9000}, 'done': False, 'episodes_total': 1, 'training_iteration': 9, 'trial_id': 'default', 'date': '2024-09-13_05-45-20', 'timestamp': 1726206320, 'time_this_iter_s': 5.41228461265564, 'time_total_s': 55.97163224220276, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab853d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 55.97163224220276, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 11.3, 'ram_util_percent': 12.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 14.337118969928651, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.32858347665696, 'policy_loss': -0.0993498145513946, 'vf_loss': 9.426180117470878, 'vf_explained_var': -0.0037832410562606087, 'kl': 0.008765924799930266, 'entropy': 5.51559275445484, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1995.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000, 'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 130.54799665990672, 'num_env_steps_trained_throughput_per_sec': 130.54799665990672, 'timesteps_total': 10000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 10000, 'timers': {'training_iteration_time_ms': 6363.043, 'sample_time_ms': 4893.161, 'load_time_ms': 0.117, 'load_throughput': 8556311.71, 'learn_time_ms': 1469.55, 'learn_throughput': 680.48, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000}, 'done': False, 'episodes_total': 2, 'training_iteration': 10, 'trial_id': 'default', 'date': '2024-09-13_05-45-27', 'timestamp': 1726206327, 'time_this_iter_s': 7.660144090652466, 'time_total_s': 63.631776332855225, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c6b49d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 63.631776332855225, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 11.52727272727273, 'ram_util_percent': 12.154545454545454}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.0786884665489196, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.521555714380174, 'policy_loss': -0.027743277379444667, 'vf_loss': 9.54774391537621, 'vf_explained_var': -7.947285970052083e-09, 'kl': 0.007775011168139047, 'entropy': 5.4210165546053934, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 2205.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 11000, 'num_env_steps_trained': 11000, 'num_agent_steps_sampled': 11000, 'num_agent_steps_trained': 11000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 11000, 'num_agent_steps_trained': 11000, 'num_env_steps_sampled': 11000, 'num_env_steps_trained': 11000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.39948148155477, 'num_env_steps_trained_throughput_per_sec': 180.39948148155477, 'timesteps_total': 11000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 11000, 'timers': {'training_iteration_time_ms': 5922.932, 'sample_time_ms': 4456.43, 'load_time_ms': 0.115, 'load_throughput': 8721779.996, 'learn_time_ms': 1466.175, 'learn_throughput': 682.047, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 11000, 'num_env_steps_trained': 11000, 'num_agent_steps_sampled': 11000, 'num_agent_steps_trained': 11000}, 'done': False, 'episodes_total': 2, 'training_iteration': 11, 'trial_id': 'default', 'date': '2024-09-13_05-45-33', 'timestamp': 1726206333, 'time_this_iter_s': 5.54338812828064, 'time_total_s': 69.17516446113586, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c670e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 69.17516446113586, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': 10.928571428571429, 'ram_util_percent': 12.114285714285714}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.4019960460208711, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.740284161340623, 'policy_loss': -0.04360005131789616, 'vf_loss': 9.782443128313338, 'vf_explained_var': -1.419158208937872e-09, 'kl': 0.007205489164672534, 'entropy': 5.4297030085609075, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 2415.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.47360962107368, 'num_env_steps_trained_throughput_per_sec': 179.47360962107368, 'timesteps_total': 12000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 12000, 'timers': {'training_iteration_time_ms': 5923.6, 'sample_time_ms': 4460.841, 'load_time_ms': 0.114, 'load_throughput': 8776530.655, 'learn_time_ms': 1462.435, 'learn_throughput': 683.791, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'done': False, 'episodes_total': 2, 'training_iteration': 12, 'trial_id': 'default', 'date': '2024-09-13_05-45-39', 'timestamp': 1726206339, 'time_this_iter_s': 5.571971654891968, 'time_total_s': 74.74713611602783, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab72310>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 74.74713611602783, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': 12.125, 'ram_util_percent': 12.1125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2908425192038218, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.445161796751476, 'policy_loss': -0.014579067853767247, 'vf_loss': 9.457652573358445, 'vf_explained_var': -5.108969552176339e-09, 'kl': 0.010441084213934596, 'entropy': 5.386405617850167, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 2625.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 13000, 'num_env_steps_trained': 13000, 'num_agent_steps_sampled': 13000, 'num_agent_steps_trained': 13000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -485.84682467447846, 'episode_reward_mean': -430.7270706705723, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846], 'episode_lengths': [4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15554759757824702, 'mean_inference_ms': 0.9312001387417117, 'mean_action_processing_ms': 0.1349471330330314, 'mean_env_wait_ms': 3.877123716666799, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 13000, 'num_agent_steps_trained': 13000, 'num_env_steps_sampled': 13000, 'num_env_steps_trained': 13000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.8984063717679, 'num_env_steps_trained_throughput_per_sec': 179.8984063717679, 'timesteps_total': 13000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 13000, 'timers': {'training_iteration_time_ms': 5919.128, 'sample_time_ms': 4460.005, 'load_time_ms': 0.114, 'load_throughput': 8809712.245, 'learn_time_ms': 1458.804, 'learn_throughput': 685.493, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 13000, 'num_env_steps_trained': 13000, 'num_agent_steps_sampled': 13000, 'num_agent_steps_trained': 13000}, 'done': False, 'episodes_total': 2, 'training_iteration': 13, 'trial_id': 'default', 'date': '2024-09-13_05-45-44', 'timestamp': 1726206344, 'time_this_iter_s': 5.558808088302612, 'time_total_s': 80.30594420433044, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab85450>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 80.30594420433044, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': 11.900000000000002, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.7577413445427303, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.304456738063267, 'policy_loss': -0.1072949781304314, 'vf_loss': 9.409893494560604, 'vf_explained_var': -1.3056255522228423e-08, 'kl': 0.009291512194059102, 'entropy': 5.3545649642036075, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 2835.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 14000, 'num_env_steps_trained': 14000, 'num_agent_steps_sampled': 14000, 'num_agent_steps_trained': 14000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 14000, 'num_agent_steps_trained': 14000, 'num_env_steps_sampled': 14000, 'num_env_steps_trained': 14000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 130.6616285732345, 'num_env_steps_trained_throughput_per_sec': 130.6616285732345, 'timesteps_total': 14000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 14000, 'timers': {'training_iteration_time_ms': 6135.012, 'sample_time_ms': 4679.686, 'load_time_ms': 0.114, 'load_throughput': 8806013.017, 'learn_time_ms': 1455.008, 'learn_throughput': 687.281, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 14000, 'num_env_steps_trained': 14000, 'num_agent_steps_sampled': 14000, 'num_agent_steps_trained': 14000}, 'done': False, 'episodes_total': 3, 'training_iteration': 14, 'trial_id': 'default', 'date': '2024-09-13_05-45-52', 'timestamp': 1726206352, 'time_this_iter_s': 7.653498888015747, 'time_total_s': 87.95944309234619, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bb58a590>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 87.95944309234619, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': 11.645454545454545, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.0694487049466086, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.477229767753965, 'policy_loss': -0.05663945930344718, 'vf_loss': 9.5305738676162, 'vf_explained_var': -9.65027582077753e-09, 'kl': 0.016477054988319563, 'entropy': 5.229943080175491, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3045.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000, 'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.00422024785146, 'num_env_steps_trained_throughput_per_sec': 182.00422024785146, 'timesteps_total': 15000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 15000, 'timers': {'training_iteration_time_ms': 5939.023, 'sample_time_ms': 4484.633, 'load_time_ms': 0.113, 'load_throughput': 8826397.306, 'learn_time_ms': 1454.073, 'learn_throughput': 687.723, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000}, 'done': False, 'episodes_total': 3, 'training_iteration': 15, 'trial_id': 'default', 'date': '2024-09-13_05-45-57', 'timestamp': 1726206357, 'time_this_iter_s': 5.494494915008545, 'time_total_s': 93.45393800735474, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65d84b3d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 93.45393800735474, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 12.075, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.8311759999820165, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.63155997140067, 'policy_loss': 0.05798990806298596, 'vf_loss': 9.569638379414876, 'vf_explained_var': -7.09579104468936e-09, 'kl': 0.019657997847597114, 'entropy': 5.127561551048642, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3255.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.86679929130585, 'num_env_steps_trained_throughput_per_sec': 179.86679929130585, 'timesteps_total': 16000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 16000, 'timers': {'training_iteration_time_ms': 5949.321, 'sample_time_ms': 4494.847, 'load_time_ms': 0.113, 'load_throughput': 8848742.616, 'learn_time_ms': 1454.16, 'learn_throughput': 687.682, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'done': False, 'episodes_total': 3, 'training_iteration': 16, 'trial_id': 'default', 'date': '2024-09-13_05-46-03', 'timestamp': 1726206363, 'time_this_iter_s': 5.559789657592773, 'time_total_s': 99.01372766494751, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6599d6090>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 99.01372766494751, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': 11.8875, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.5754997821081251, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.697486614045642, 'policy_loss': 0.006913715884799049, 'vf_loss': 9.688765857333228, 'vf_explained_var': -4.4453711736769906e-05, 'kl': 0.009035523192332697, 'entropy': 5.144002476192656, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3465.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 17000, 'num_env_steps_trained': 17000, 'num_agent_steps_sampled': 17000, 'num_agent_steps_trained': 17000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 17000, 'num_agent_steps_trained': 17000, 'num_env_steps_sampled': 17000, 'num_env_steps_trained': 17000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.40025309426335, 'num_env_steps_trained_throughput_per_sec': 181.40025309426335, 'timesteps_total': 17000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 17000, 'timers': {'training_iteration_time_ms': 5947.315, 'sample_time_ms': 4498.087, 'load_time_ms': 0.113, 'load_throughput': 8867450.317, 'learn_time_ms': 1448.916, 'learn_throughput': 690.171, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 17000, 'num_env_steps_trained': 17000, 'num_agent_steps_sampled': 17000, 'num_agent_steps_trained': 17000}, 'done': False, 'episodes_total': 3, 'training_iteration': 17, 'trial_id': 'default', 'date': '2024-09-13_05-46-08', 'timestamp': 1726206368, 'time_this_iter_s': 5.5127928256988525, 'time_total_s': 104.52652049064636, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c657790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 104.52652049064636, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': 12.15, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.4056027653671446, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.59947548820859, 'policy_loss': 0.0805719619794261, 'vf_loss': 9.517611658005487, 'vf_explained_var': -1.7029898507254464e-09, 'kl': 0.006459749243177203, 'entropy': 5.149926333200364, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3675.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 18000, 'num_env_steps_trained': 18000, 'num_agent_steps_sampled': 18000, 'num_agent_steps_trained': 18000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -465.276710286458, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294], 'episode_lengths': [4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1556747722818966, 'mean_inference_ms': 0.9344320436621277, 'mean_action_processing_ms': 0.13542028009812215, 'mean_env_wait_ms': 3.776973217840947, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 18000, 'num_agent_steps_trained': 18000, 'num_env_steps_sampled': 18000, 'num_env_steps_trained': 18000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.19361302951174, 'num_env_steps_trained_throughput_per_sec': 181.19361302951174, 'timesteps_total': 18000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 18000, 'timers': {'training_iteration_time_ms': 5948.491, 'sample_time_ms': 4510.346, 'load_time_ms': 0.112, 'load_throughput': 8941172.458, 'learn_time_ms': 1437.838, 'learn_throughput': 695.489, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 18000, 'num_env_steps_trained': 18000, 'num_agent_steps_sampled': 18000, 'num_agent_steps_trained': 18000}, 'done': False, 'episodes_total': 3, 'training_iteration': 18, 'trial_id': 'default', 'date': '2024-09-13_05-46-14', 'timestamp': 1726206374, 'time_this_iter_s': 5.519076347351074, 'time_total_s': 110.04559683799744, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbeaa8d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 110.04559683799744, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': 11.7375, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.5380442500114442, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.411787886846634, 'policy_loss': -0.06379518285393715, 'vf_loss': 9.47374895640782, 'vf_explained_var': 1.1353265671502977e-09, 'kl': 0.00917082466881506, 'entropy': 5.208719498770577, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3885.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 19000, 'num_env_steps_trained': 19000, 'num_agent_steps_sampled': 19000, 'num_agent_steps_trained': 19000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 19000, 'num_agent_steps_trained': 19000, 'num_env_steps_sampled': 19000, 'num_env_steps_trained': 19000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.17490776545746, 'num_env_steps_trained_throughput_per_sec': 127.17490776545746, 'timesteps_total': 19000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 19000, 'timers': {'training_iteration_time_ms': 6193.592, 'sample_time_ms': 4746.752, 'load_time_ms': 0.114, 'load_throughput': 8806013.017, 'learn_time_ms': 1446.529, 'learn_throughput': 691.31, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 19000, 'num_env_steps_trained': 19000, 'num_agent_steps_sampled': 19000, 'num_agent_steps_trained': 19000}, 'done': False, 'episodes_total': 4, 'training_iteration': 19, 'trial_id': 'default', 'date': '2024-09-13_05-46-22', 'timestamp': 1726206382, 'time_this_iter_s': 7.8633222579956055, 'time_total_s': 117.90891909599304, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597616d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 117.90891909599304, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': 11.445454545454544, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3562558374234608, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.486730400721232, 'policy_loss': 0.021309344501545032, 'vf_loss': 9.463143911815825, 'vf_explained_var': 1.0785602387927827e-08, 'kl': 0.011385702549263702, 'entropy': 5.2007263546898255, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4095.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.32719575978908, 'num_env_steps_trained_throughput_per_sec': 180.32719575978908, 'timesteps_total': 20000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 5982.138, 'sample_time_ms': 4531.782, 'load_time_ms': 0.114, 'load_throughput': 8789404.862, 'learn_time_ms': 1450.045, 'learn_throughput': 689.634, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'done': False, 'episodes_total': 4, 'training_iteration': 20, 'trial_id': 'default', 'date': '2024-09-13_05-46-27', 'timestamp': 1726206387, 'time_this_iter_s': 5.545604944229126, 'time_total_s': 123.45452404022217, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65975cc90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 123.45452404022217, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 12.0125, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.430054391565777, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.674543444315592, 'policy_loss': -0.09347711425452006, 'vf_loss': 9.765464328584217, 'vf_explained_var': 7.09579104468936e-09, 'kl': 0.012780809340828064, 'entropy': 5.338028271993001, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4305.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 21000, 'num_env_steps_trained': 21000, 'num_agent_steps_sampled': 21000, 'num_agent_steps_trained': 21000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 21000, 'num_agent_steps_trained': 21000, 'num_env_steps_sampled': 21000, 'num_env_steps_trained': 21000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 183.4100933919999, 'num_env_steps_trained_throughput_per_sec': 183.4100933919999, 'timesteps_total': 21000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 21000, 'timers': {'training_iteration_time_ms': 5973.039, 'sample_time_ms': 4525.284, 'load_time_ms': 0.113, 'load_throughput': 8863702.451, 'learn_time_ms': 1447.446, 'learn_throughput': 690.872, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 21000, 'num_env_steps_trained': 21000, 'num_agent_steps_sampled': 21000, 'num_agent_steps_trained': 21000}, 'done': False, 'episodes_total': 4, 'training_iteration': 21, 'trial_id': 'default', 'date': '2024-09-13_05-46-33', 'timestamp': 1726206393, 'time_this_iter_s': 5.4523985385894775, 'time_total_s': 128.90692257881165, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c670e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 128.90692257881165, 'iterations_since_restore': 21, 'perf': {'cpu_util_percent': 11.7625, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3565943845680781, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.698456709725516, 'policy_loss': -0.003124435175032843, 'vf_loss': 9.699640837169829, 'vf_explained_var': -1.7597561790829613e-08, 'kl': 0.00970146925416581, 'entropy': 5.368629228501093, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4515.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 22000, 'num_env_steps_trained': 22000, 'num_agent_steps_sampled': 22000, 'num_agent_steps_trained': 22000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 22000, 'num_agent_steps_trained': 22000, 'num_env_steps_sampled': 22000, 'num_env_steps_trained': 22000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.58129277268662, 'num_env_steps_trained_throughput_per_sec': 178.58129277268662, 'timesteps_total': 22000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 22000, 'timers': {'training_iteration_time_ms': 5975.824, 'sample_time_ms': 4531.597, 'load_time_ms': 0.113, 'load_throughput': 8835694.123, 'learn_time_ms': 1443.917, 'learn_throughput': 692.561, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 22000, 'num_env_steps_trained': 22000, 'num_agent_steps_sampled': 22000, 'num_agent_steps_trained': 22000}, 'done': False, 'episodes_total': 4, 'training_iteration': 22, 'trial_id': 'default', 'date': '2024-09-13_05-46-38', 'timestamp': 1726206398, 'time_this_iter_s': 5.5998101234436035, 'time_total_s': 134.50673270225525, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab71d10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 134.50673270225525, 'iterations_since_restore': 22, 'perf': {'cpu_util_percent': 11.9125, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.8081030831450509, 'cur_kl_coeff': 0.2, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.511385563441685, 'policy_loss': 0.03014712447211856, 'vf_loss': 9.480259191422235, 'vf_explained_var': -1.986821492513021e-09, 'kl': 0.004896359110915987, 'entropy': 5.3324841794513524, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4725.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 23000, 'num_env_steps_trained': 23000, 'num_agent_steps_sampled': 23000, 'num_agent_steps_trained': 23000}, 'sampler_results': {'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -375.6073166666661, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -444.6964845920137, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806], 'episode_lengths': [4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15572492480566852, 'mean_inference_ms': 0.9369332227513414, 'mean_action_processing_ms': 0.13581390096603674, 'mean_env_wait_ms': 3.708610558850651, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 23000, 'num_agent_steps_trained': 23000, 'num_env_steps_sampled': 23000, 'num_env_steps_trained': 23000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 183.73679268487942, 'num_env_steps_trained_throughput_per_sec': 183.73679268487942, 'timesteps_total': 23000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 23000, 'timers': {'training_iteration_time_ms': 5964.211, 'sample_time_ms': 4532.78, 'load_time_ms': 0.113, 'load_throughput': 8826397.306, 'learn_time_ms': 1431.122, 'learn_throughput': 698.753, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 23000, 'num_env_steps_trained': 23000, 'num_agent_steps_sampled': 23000, 'num_agent_steps_trained': 23000}, 'done': False, 'episodes_total': 4, 'training_iteration': 23, 'trial_id': 'default', 'date': '2024-09-13_05-46-44', 'timestamp': 1726206404, 'time_this_iter_s': 5.442686319351196, 'time_total_s': 139.94941902160645, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659763790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 139.94941902160645, 'iterations_since_restore': 23, 'perf': {'cpu_util_percent': 11.7625, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.6924059853667304, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.254858932040987, 'policy_loss': -0.07676425321648518, 'vf_loss': 9.330327131634666, 'vf_explained_var': 3.973642985026042e-09, 'kl': 0.012960393944047697, 'entropy': 5.346009722210112, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4935.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000}, 'sampler_results': {'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.89508685021525, 'num_env_steps_trained_throughput_per_sec': 128.89508685021525, 'timesteps_total': 24000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 24000, 'timers': {'training_iteration_time_ms': 5974.701, 'sample_time_ms': 4547.444, 'load_time_ms': 0.116, 'load_throughput': 8653402.104, 'learn_time_ms': 1426.945, 'learn_throughput': 700.798, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000}, 'done': False, 'episodes_total': 5, 'training_iteration': 24, 'trial_id': 'default', 'date': '2024-09-13_05-46-52', 'timestamp': 1726206412, 'time_this_iter_s': 7.758376598358154, 'time_total_s': 147.7077956199646, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c671e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 147.7077956199646, 'iterations_since_restore': 24, 'perf': {'cpu_util_percent': 11.245454545454548, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.6729674972238995, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.448967098054432, 'policy_loss': -0.08352501434939248, 'vf_loss': 9.531279491242909, 'vf_explained_var': -3.973642985026042e-09, 'kl': 0.012126181161563311, 'entropy': 5.3119385628473195, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 5145.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000}, 'sampler_results': {'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000, 'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.16489606132413, 'num_env_steps_trained_throughput_per_sec': 180.16489606132413, 'timesteps_total': 25000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 25000, 'timers': {'training_iteration_time_ms': 5980.31, 'sample_time_ms': 4560.07, 'load_time_ms': 0.116, 'load_throughput': 8637364.086, 'learn_time_ms': 1419.928, 'learn_throughput': 704.261, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000}, 'done': False, 'episodes_total': 5, 'training_iteration': 25, 'trial_id': 'default', 'date': '2024-09-13_05-46-57', 'timestamp': 1726206417, 'time_this_iter_s': 5.550623893737793, 'time_total_s': 153.2584195137024, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea5450>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 153.2584195137024, 'iterations_since_restore': 25, 'perf': {'cpu_util_percent': 11.7, 'ram_util_percent': 12.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.874813793386732, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.713087906156268, 'policy_loss': -0.04117418456645239, 'vf_loss': 9.753047043936593, 'vf_explained_var': 8.514949253627232e-10, 'kl': 0.012149715236765179, 'entropy': 5.238978658403669, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 5355.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 26000, 'num_env_steps_trained': 26000, 'num_agent_steps_sampled': 26000, 'num_agent_steps_trained': 26000}, 'sampler_results': {'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 26000, 'num_agent_steps_trained': 26000, 'num_env_steps_sampled': 26000, 'num_env_steps_trained': 26000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.51696582173886, 'num_env_steps_trained_throughput_per_sec': 176.51696582173886, 'timesteps_total': 26000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 26000, 'timers': {'training_iteration_time_ms': 5990.861, 'sample_time_ms': 4573.703, 'load_time_ms': 0.116, 'load_throughput': 8623157.895, 'learn_time_ms': 1416.845, 'learn_throughput': 705.793, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 26000, 'num_env_steps_trained': 26000, 'num_agent_steps_sampled': 26000, 'num_agent_steps_trained': 26000}, 'done': False, 'episodes_total': 5, 'training_iteration': 26, 'trial_id': 'default', 'date': '2024-09-13_05-47-03', 'timestamp': 1726206423, 'time_this_iter_s': 5.665317058563232, 'time_total_s': 158.92373657226562, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab7a4d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 158.92373657226562, 'iterations_since_restore': 26, 'perf': {'cpu_util_percent': 11.45, 'ram_util_percent': 12.212499999999999}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.63304580279759, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.430186548687162, 'policy_loss': -0.02026060153951957, 'vf_loss': 9.449652789887928, 'vf_explained_var': -2.4693352835518975e-08, 'kl': 0.007944342745689763, 'entropy': 5.248827477863856, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 5565.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 27000, 'num_env_steps_trained': 27000, 'num_agent_steps_sampled': 27000, 'num_agent_steps_trained': 27000}, 'sampler_results': {'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -362.98076304253425, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -428.3533402821178, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425], 'episode_lengths': [4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.155736457117423, 'mean_inference_ms': 0.9382358525809849, 'mean_action_processing_ms': 0.13607423509973676, 'mean_env_wait_ms': 3.659303881153445, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 27000, 'num_agent_steps_trained': 27000, 'num_env_steps_sampled': 27000, 'num_env_steps_trained': 27000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.52358029183478, 'num_env_steps_trained_throughput_per_sec': 180.52358029183478, 'timesteps_total': 27000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 27000, 'timers': {'training_iteration_time_ms': 5993.538, 'sample_time_ms': 4575.31, 'load_time_ms': 0.117, 'load_throughput': 8582574.176, 'learn_time_ms': 1417.912, 'learn_throughput': 705.263, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 27000, 'num_env_steps_trained': 27000, 'num_agent_steps_sampled': 27000, 'num_agent_steps_trained': 27000}, 'done': False, 'episodes_total': 5, 'training_iteration': 27, 'trial_id': 'default', 'date': '2024-09-13_05-47-08', 'timestamp': 1726206428, 'time_this_iter_s': 5.539578437805176, 'time_total_s': 164.4633150100708, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659754cd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 164.4633150100708, 'iterations_since_restore': 27, 'perf': {'cpu_util_percent': 12.0, 'ram_util_percent': 12.275}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.8536298164299556, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.461614917573474, 'policy_loss': 0.03409103877132847, 'vf_loss': 9.425883665538969, 'vf_explained_var': 2.8383164178757443e-10, 'kl': 0.016401306109245135, 'entropy': 5.234975953329177, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 5775.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000}, 'sampler_results': {'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 129.42467465198735, 'num_env_steps_trained_throughput_per_sec': 129.42467465198735, 'timesteps_total': 28000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 28000, 'timers': {'training_iteration_time_ms': 6214.292, 'sample_time_ms': 4788.117, 'load_time_ms': 0.118, 'load_throughput': 8505990.671, 'learn_time_ms': 1425.856, 'learn_throughput': 701.333, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000}, 'done': False, 'episodes_total': 6, 'training_iteration': 28, 'trial_id': 'default', 'date': '2024-09-13_05-47-16', 'timestamp': 1726206436, 'time_this_iter_s': 7.726674795150757, 'time_total_s': 172.18998980522156, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6599b1b90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 172.18998980522156, 'iterations_since_restore': 28, 'perf': {'cpu_util_percent': 11.7, 'ram_util_percent': 12.290909090909093}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.047785198972339, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.546295456659227, 'policy_loss': 0.017469568586065656, 'vf_loss': 9.527801391056606, 'vf_explained_var': -2.8383164178757443e-10, 'kl': 0.010245027384510087, 'entropy': 5.2455772785913375, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 5985.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 29000, 'num_env_steps_trained': 29000, 'num_agent_steps_sampled': 29000, 'num_agent_steps_trained': 29000}, 'sampler_results': {'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 29000, 'num_agent_steps_trained': 29000, 'num_env_steps_sampled': 29000, 'num_env_steps_trained': 29000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.44017866394438, 'num_env_steps_trained_throughput_per_sec': 179.44017866394438, 'timesteps_total': 29000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 29000, 'timers': {'training_iteration_time_ms': 5985.262, 'sample_time_ms': 4562.061, 'load_time_ms': 0.116, 'load_throughput': 8610765.757, 'learn_time_ms': 1422.885, 'learn_throughput': 702.797, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 29000, 'num_env_steps_trained': 29000, 'num_agent_steps_sampled': 29000, 'num_agent_steps_trained': 29000}, 'done': False, 'episodes_total': 6, 'training_iteration': 29, 'trial_id': 'default', 'date': '2024-09-13_05-47-22', 'timestamp': 1726206442, 'time_this_iter_s': 5.573012590408325, 'time_total_s': 177.76300239562988, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab80350>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 177.76300239562988, 'iterations_since_restore': 29, 'perf': {'cpu_util_percent': 11.8125, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.364024525596982, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.62234685080392, 'policy_loss': -0.06788514909733619, 'vf_loss': 9.689550912947881, 'vf_explained_var': -1.1920928955078126e-08, 'kl': 0.006810957207233668, 'entropy': 5.324648269017538, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6195.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000}, 'sampler_results': {'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.1962983385894, 'num_env_steps_trained_throughput_per_sec': 180.1962983385894, 'timesteps_total': 30000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 30000, 'timers': {'training_iteration_time_ms': 5985.665, 'sample_time_ms': 4566.277, 'load_time_ms': 0.117, 'load_throughput': 8551078.491, 'learn_time_ms': 1419.068, 'learn_throughput': 704.688, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000}, 'done': False, 'episodes_total': 6, 'training_iteration': 30, 'trial_id': 'default', 'date': '2024-09-13_05-47-27', 'timestamp': 1726206447, 'time_this_iter_s': 5.5496602058410645, 'time_total_s': 183.31266260147095, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab708d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 183.31266260147095, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 11.7875, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.649595269418898, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.797681304386684, 'policy_loss': 0.015224290922993705, 'vf_loss': 9.780743444533575, 'vf_explained_var': -1.1069434029715402e-08, 'kl': 0.017135354817444402, 'entropy': 5.450595764886765, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6405.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 31000, 'num_env_steps_trained': 31000, 'num_agent_steps_sampled': 31000, 'num_agent_steps_trained': 31000}, 'sampler_results': {'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 31000, 'num_agent_steps_trained': 31000, 'num_env_steps_sampled': 31000, 'num_env_steps_trained': 31000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.58385517992744, 'num_env_steps_trained_throughput_per_sec': 178.58385517992744, 'timesteps_total': 31000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 31000, 'timers': {'training_iteration_time_ms': 6000.4, 'sample_time_ms': 4581.392, 'load_time_ms': 0.117, 'load_throughput': 8577308.793, 'learn_time_ms': 1418.69, 'learn_throughput': 704.876, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 31000, 'num_env_steps_trained': 31000, 'num_agent_steps_sampled': 31000, 'num_agent_steps_trained': 31000}, 'done': False, 'episodes_total': 6, 'training_iteration': 31, 'trial_id': 'default', 'date': '2024-09-13_05-47-33', 'timestamp': 1726206453, 'time_this_iter_s': 5.599732398986816, 'time_total_s': 188.91239500045776, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597685d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 188.91239500045776, 'iterations_since_restore': 31, 'perf': {'cpu_util_percent': 11.8625, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1863540053367614, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.437828824633645, 'policy_loss': -0.0673019579833462, 'vf_loss': 9.504231702713739, 'vf_explained_var': -1.986821492513021e-09, 'kl': 0.008990991618130889, 'entropy': 5.438366538002377, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6615.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000}, 'sampler_results': {'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -228.26136458333337, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -395.0046776656538, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15583622496353075, 'mean_inference_ms': 0.93942860290947, 'mean_action_processing_ms': 0.13631272320435103, 'mean_env_wait_ms': 3.6256023164227216, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.57705262373713, 'num_env_steps_trained_throughput_per_sec': 179.57705262373713, 'timesteps_total': 32000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 32000, 'timers': {'training_iteration_time_ms': 5997.295, 'sample_time_ms': 4579.758, 'load_time_ms': 0.116, 'load_throughput': 8605465.737, 'learn_time_ms': 1417.221, 'learn_throughput': 705.606, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000}, 'done': False, 'episodes_total': 6, 'training_iteration': 32, 'trial_id': 'default', 'date': '2024-09-13_05-47-39', 'timestamp': 1726206459, 'time_this_iter_s': 5.5687596797943115, 'time_total_s': 194.48115468025208, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659767790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 194.48115468025208, 'iterations_since_restore': 32, 'perf': {'cpu_util_percent': 11.7625, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.5240801095962524, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.317015470777239, 'policy_loss': -0.1574561259221463, 'vf_loss': 9.473328340621222, 'vf_explained_var': -1.0217939104352679e-08, 'kl': 0.011433380653726913, 'entropy': 5.303101337523687, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6825.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 33000, 'num_env_steps_trained': 33000, 'num_agent_steps_sampled': 33000, 'num_agent_steps_trained': 33000}, 'sampler_results': {'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 33000, 'num_agent_steps_trained': 33000, 'num_env_steps_sampled': 33000, 'num_env_steps_trained': 33000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.39451298645145, 'num_env_steps_trained_throughput_per_sec': 128.39451298645145, 'timesteps_total': 33000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 33000, 'timers': {'training_iteration_time_ms': 6231.887, 'sample_time_ms': 4808.195, 'load_time_ms': 0.116, 'load_throughput': 8617842.614, 'learn_time_ms': 1423.374, 'learn_throughput': 702.556, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 33000, 'num_env_steps_trained': 33000, 'num_agent_steps_sampled': 33000, 'num_agent_steps_trained': 33000}, 'done': False, 'episodes_total': 7, 'training_iteration': 33, 'trial_id': 'default', 'date': '2024-09-13_05-47-46', 'timestamp': 1726206466, 'time_this_iter_s': 7.7886574268341064, 'time_total_s': 202.26981210708618, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab39390>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 202.26981210708618, 'iterations_since_restore': 33, 'perf': {'cpu_util_percent': 11.29090909090909, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.9550032456715902, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.336999089377267, 'policy_loss': -0.06713724077812262, 'vf_loss': 9.402321633838472, 'vf_explained_var': -5.960464477539063e-09, 'kl': 0.01814624867443594, 'entropy': 5.41900912920634, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 7035.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 34000, 'num_env_steps_trained': 34000, 'num_agent_steps_sampled': 34000, 'num_agent_steps_trained': 34000}, 'sampler_results': {'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 34000, 'num_agent_steps_trained': 34000, 'num_env_steps_sampled': 34000, 'num_env_steps_trained': 34000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.54606739510967, 'num_env_steps_trained_throughput_per_sec': 181.54606739510967, 'timesteps_total': 34000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 34000, 'timers': {'training_iteration_time_ms': 6006.887, 'sample_time_ms': 4585.676, 'load_time_ms': 0.114, 'load_throughput': 8800469.996, 'learn_time_ms': 1420.893, 'learn_throughput': 703.783, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 34000, 'num_env_steps_trained': 34000, 'num_agent_steps_sampled': 34000, 'num_agent_steps_trained': 34000}, 'done': False, 'episodes_total': 7, 'training_iteration': 34, 'trial_id': 'default', 'date': '2024-09-13_05-47-52', 'timestamp': 1726206472, 'time_this_iter_s': 5.508368968963623, 'time_total_s': 207.7781810760498, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659523c10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 207.7781810760498, 'iterations_since_restore': 34, 'perf': {'cpu_util_percent': 12.1375, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.6252613621098655, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.6516384942191, 'policy_loss': -0.12582912577449212, 'vf_loss': 9.776705505734398, 'vf_explained_var': 3.973642985026042e-09, 'kl': 0.007621605070917645, 'entropy': 5.493705172765822, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 7245.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000}, 'sampler_results': {'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000, 'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.99363416297632, 'num_env_steps_trained_throughput_per_sec': 179.99363416297632, 'timesteps_total': 35000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 35000, 'timers': {'training_iteration_time_ms': 6007.415, 'sample_time_ms': 4585.731, 'load_time_ms': 0.115, 'load_throughput': 8712721.23, 'learn_time_ms': 1421.368, 'learn_throughput': 703.548, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000}, 'done': False, 'episodes_total': 7, 'training_iteration': 35, 'trial_id': 'default', 'date': '2024-09-13_05-47-57', 'timestamp': 1726206477, 'time_this_iter_s': 5.5558741092681885, 'time_total_s': 213.334055185318, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab84050>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 213.334055185318, 'iterations_since_restore': 35, 'perf': {'cpu_util_percent': 11.675, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.2677561811038425, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.443162159692674, 'policy_loss': -0.02000022226323684, 'vf_loss': 9.4614956901187, 'vf_explained_var': -2.0435878208705357e-08, 'kl': 0.0166670071516863, 'entropy': 5.415465434392293, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 7455.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000}, 'sampler_results': {'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -212.97378602430524, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -369.00026457403254, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15596207889308658, 'mean_inference_ms': 0.9405232064042363, 'mean_action_processing_ms': 0.13654217291458579, 'mean_env_wait_ms': 3.5989403016792174, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.3637879080747, 'num_env_steps_trained_throughput_per_sec': 177.3637879080747, 'timesteps_total': 36000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 36000, 'timers': {'training_iteration_time_ms': 6004.711, 'sample_time_ms': 4585.63, 'load_time_ms': 0.115, 'load_throughput': 8673085.194, 'learn_time_ms': 1418.763, 'learn_throughput': 704.84, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000}, 'done': False, 'episodes_total': 7, 'training_iteration': 36, 'trial_id': 'default', 'date': '2024-09-13_05-48-03', 'timestamp': 1726206483, 'time_this_iter_s': 5.6382505893707275, 'time_total_s': 218.97230577468872, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c657a50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 218.97230577468872, 'iterations_since_restore': 36, 'perf': {'cpu_util_percent': 11.649999999999999, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.6813332376025971, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.375857344127837, 'policy_loss': -0.03647306646619524, 'vf_loss': 9.411073680151077, 'vf_explained_var': -1.0217939104352679e-08, 'kl': 0.012567442469783903, 'entropy': 5.404327324458531, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 7665.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 37000, 'num_env_steps_trained': 37000, 'num_agent_steps_sampled': 37000, 'num_agent_steps_trained': 37000}, 'sampler_results': {'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 37000, 'num_agent_steps_trained': 37000, 'num_env_steps_sampled': 37000, 'num_env_steps_trained': 37000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 130.70699255410563, 'num_env_steps_trained_throughput_per_sec': 130.70699255410563, 'timesteps_total': 37000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 37000, 'timers': {'training_iteration_time_ms': 6215.836, 'sample_time_ms': 4803.741, 'load_time_ms': 0.115, 'load_throughput': 8703681.262, 'learn_time_ms': 1411.783, 'learn_throughput': 708.324, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 37000, 'num_env_steps_trained': 37000, 'num_agent_steps_sampled': 37000, 'num_agent_steps_trained': 37000}, 'done': False, 'episodes_total': 8, 'training_iteration': 37, 'trial_id': 'default', 'date': '2024-09-13_05-48-11', 'timestamp': 1726206491, 'time_this_iter_s': 7.650835752487183, 'time_total_s': 226.6231415271759, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659941f50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 226.6231415271759, 'iterations_since_restore': 37, 'perf': {'cpu_util_percent': 11.045454545454549, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.4954826459998176, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.757374268486386, 'policy_loss': 0.04427211305924824, 'vf_loss': 9.712181722550165, 'vf_explained_var': 1.3623918805803571e-08, 'kl': 0.009204270453414105, 'entropy': 5.363641212100075, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 7875.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 38000, 'num_env_steps_trained': 38000, 'num_agent_steps_sampled': 38000, 'num_agent_steps_trained': 38000}, 'sampler_results': {'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 38000, 'num_agent_steps_trained': 38000, 'num_env_steps_sampled': 38000, 'num_env_steps_trained': 38000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.75894960603216, 'num_env_steps_trained_throughput_per_sec': 178.75894960603216, 'timesteps_total': 38000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 38000, 'timers': {'training_iteration_time_ms': 6002.599, 'sample_time_ms': 4592.499, 'load_time_ms': 0.114, 'load_throughput': 8750895.055, 'learn_time_ms': 1409.791, 'learn_throughput': 709.325, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 38000, 'num_env_steps_trained': 38000, 'num_agent_steps_sampled': 38000, 'num_agent_steps_trained': 38000}, 'done': False, 'episodes_total': 8, 'training_iteration': 38, 'trial_id': 'default', 'date': '2024-09-13_05-48-16', 'timestamp': 1726206496, 'time_this_iter_s': 5.594243764877319, 'time_total_s': 232.21738529205322, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659762890>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 232.21738529205322, 'iterations_since_restore': 38, 'perf': {'cpu_util_percent': 12.0375, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.7471814518883115, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.560475635528565, 'policy_loss': 0.16253290013188407, 'vf_loss': 9.396825372605097, 'vf_explained_var': 2.8383164178757443e-10, 'kl': 0.01117345088563788, 'entropy': 5.412227760042463, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 8085.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 39000, 'num_env_steps_trained': 39000, 'num_agent_steps_sampled': 39000, 'num_agent_steps_trained': 39000}, 'sampler_results': {'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 39000, 'num_agent_steps_trained': 39000, 'num_env_steps_sampled': 39000, 'num_env_steps_trained': 39000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.73536550458888, 'num_env_steps_trained_throughput_per_sec': 178.73536550458888, 'timesteps_total': 39000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 39000, 'timers': {'training_iteration_time_ms': 6004.797, 'sample_time_ms': 4597.639, 'load_time_ms': 0.114, 'load_throughput': 8789404.862, 'learn_time_ms': 1406.849, 'learn_throughput': 710.808, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 39000, 'num_env_steps_trained': 39000, 'num_agent_steps_sampled': 39000, 'num_agent_steps_trained': 39000}, 'done': False, 'episodes_total': 8, 'training_iteration': 39, 'trial_id': 'default', 'date': '2024-09-13_05-48-22', 'timestamp': 1726206502, 'time_this_iter_s': 5.594987154006958, 'time_total_s': 237.81237244606018, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab7a490>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 237.81237244606018, 'iterations_since_restore': 39, 'perf': {'cpu_util_percent': 11.285714285714286, 'ram_util_percent': 12.299999999999999}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.6179770886898042, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.697450501578194, 'policy_loss': 0.0640890223639352, 'vf_loss': 9.632487142653693, 'vf_explained_var': -2.1855036417643228e-08, 'kl': 0.008743616174823372, 'entropy': 5.462294417335873, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 8295.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'sampler_results': {'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.05702868926906, 'num_env_steps_trained_throughput_per_sec': 179.05702868926906, 'timesteps_total': 40000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 6008.328, 'sample_time_ms': 4604.018, 'load_time_ms': 0.114, 'load_throughput': 8782043.551, 'learn_time_ms': 1404.004, 'learn_throughput': 712.249, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'done': False, 'episodes_total': 8, 'training_iteration': 40, 'trial_id': 'default', 'date': '2024-09-13_05-48-28', 'timestamp': 1726206508, 'time_this_iter_s': 5.584935426712036, 'time_total_s': 243.39730787277222, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c657790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 243.39730787277222, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 11.8875, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.5187030400548662, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.715064521062942, 'policy_loss': 0.17900236564732733, 'vf_loss': 9.53518496013823, 'vf_explained_var': -5.960464477539063e-09, 'kl': 0.008772306145588835, 'entropy': 5.405314409165156, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 8505.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 41000, 'num_env_steps_trained': 41000, 'num_agent_steps_sampled': 41000, 'num_agent_steps_trained': 41000}, 'sampler_results': {'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 200.11550944010418, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -297.8607928222654, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1560731016948721, 'mean_inference_ms': 0.9414312067304254, 'mean_action_processing_ms': 0.1367414524985699, 'mean_env_wait_ms': 3.5788038764860963, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 41000, 'num_agent_steps_trained': 41000, 'num_env_steps_sampled': 41000, 'num_env_steps_trained': 41000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 175.23404625108208, 'num_env_steps_trained_throughput_per_sec': 175.23404625108208, 'timesteps_total': 41000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 41000, 'timers': {'training_iteration_time_ms': 6019.032, 'sample_time_ms': 4617.617, 'load_time_ms': 0.115, 'load_throughput': 8709102.99, 'learn_time_ms': 1401.107, 'learn_throughput': 713.721, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 41000, 'num_env_steps_trained': 41000, 'num_agent_steps_sampled': 41000, 'num_agent_steps_trained': 41000}, 'done': False, 'episodes_total': 8, 'training_iteration': 41, 'trial_id': 'default', 'date': '2024-09-13_05-48-33', 'timestamp': 1726206513, 'time_this_iter_s': 5.70677375793457, 'time_total_s': 249.1040816307068, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6595adb50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 249.1040816307068, 'iterations_since_restore': 41, 'perf': {'cpu_util_percent': 11.966666666666667, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.2710853150912693, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.515860589345296, 'policy_loss': 0.03003293640379395, 'vf_loss': 9.484912095751081, 'vf_explained_var': -4.541306268601191e-09, 'kl': 0.009155336260179562, 'entropy': 5.352750131062099, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 8715.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 42000, 'num_env_steps_trained': 42000, 'num_agent_steps_sampled': 42000, 'num_agent_steps_trained': 42000}, 'sampler_results': {'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 42000, 'num_agent_steps_trained': 42000, 'num_env_steps_sampled': 42000, 'num_env_steps_trained': 42000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.01468527838017, 'num_env_steps_trained_throughput_per_sec': 128.01468527838017, 'timesteps_total': 42000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 42000, 'timers': {'training_iteration_time_ms': 6243.328, 'sample_time_ms': 4843.171, 'load_time_ms': 0.115, 'load_throughput': 8673085.194, 'learn_time_ms': 1399.847, 'learn_throughput': 714.364, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 42000, 'num_env_steps_trained': 42000, 'num_agent_steps_sampled': 42000, 'num_agent_steps_trained': 42000}, 'done': False, 'episodes_total': 9, 'training_iteration': 42, 'trial_id': 'default', 'date': '2024-09-13_05-48-41', 'timestamp': 1726206521, 'time_this_iter_s': 7.811738967895508, 'time_total_s': 256.9158205986023, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65960dd10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 256.9158205986023, 'iterations_since_restore': 42, 'perf': {'cpu_util_percent': 11.172727272727274, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.9339220373403458, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.601282460348946, 'policy_loss': 0.1482005163007194, 'vf_loss': 9.451878384181432, 'vf_explained_var': -8.231117611839658e-09, 'kl': 0.012035939864290615, 'entropy': 5.219028958820162, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 8925.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 43000, 'num_env_steps_trained': 43000, 'num_agent_steps_sampled': 43000, 'num_agent_steps_trained': 43000}, 'sampler_results': {'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 43000, 'num_agent_steps_trained': 43000, 'num_env_steps_sampled': 43000, 'num_env_steps_trained': 43000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.4137154634075, 'num_env_steps_trained_throughput_per_sec': 177.4137154634075, 'timesteps_total': 43000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 43000, 'timers': {'training_iteration_time_ms': 6028.133, 'sample_time_ms': 4626.335, 'load_time_ms': 0.115, 'load_throughput': 8692858.031, 'learn_time_ms': 1401.486, 'learn_throughput': 713.528, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 43000, 'num_env_steps_trained': 43000, 'num_agent_steps_sampled': 43000, 'num_agent_steps_trained': 43000}, 'done': False, 'episodes_total': 9, 'training_iteration': 43, 'trial_id': 'default', 'date': '2024-09-13_05-48-47', 'timestamp': 1726206527, 'time_this_iter_s': 5.636732578277588, 'time_total_s': 262.5525531768799, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab3ffd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 262.5525531768799, 'iterations_since_restore': 43, 'perf': {'cpu_util_percent': 11.537500000000001, 'ram_util_percent': 12.325000000000001}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.5179482003053029, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.608453805106027, 'policy_loss': -0.006060571542807988, 'vf_loss': 9.613496462504068, 'vf_explained_var': -2.838316417875744e-09, 'kl': 0.010179399778938942, 'entropy': 5.2329318250928605, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 9135.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 44000, 'num_env_steps_trained': 44000, 'num_agent_steps_sampled': 44000, 'num_agent_steps_trained': 44000}, 'sampler_results': {'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 44000, 'num_agent_steps_trained': 44000, 'num_env_steps_sampled': 44000, 'num_env_steps_trained': 44000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.0161071277662, 'num_env_steps_trained_throughput_per_sec': 182.0161071277662, 'timesteps_total': 44000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 44000, 'timers': {'training_iteration_time_ms': 6026.711, 'sample_time_ms': 4625.963, 'load_time_ms': 0.115, 'load_throughput': 8685657.486, 'learn_time_ms': 1400.437, 'learn_throughput': 714.063, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 44000, 'num_env_steps_trained': 44000, 'num_agent_steps_sampled': 44000, 'num_agent_steps_trained': 44000}, 'done': False, 'episodes_total': 9, 'training_iteration': 44, 'trial_id': 'default', 'date': '2024-09-13_05-48-52', 'timestamp': 1726206532, 'time_this_iter_s': 5.494145393371582, 'time_total_s': 268.04669857025146, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597f4cd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 268.04669857025146, 'iterations_since_restore': 44, 'perf': {'cpu_util_percent': 11.875, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.9698330152602423, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.774180289677211, 'policy_loss': 0.12287835840667997, 'vf_loss': 9.649626582009452, 'vf_explained_var': -7.09579104468936e-09, 'kl': 0.01675454772315615, 'entropy': 5.191477112543016, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 9345.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000}, 'sampler_results': {'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000, 'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.27392916411407, 'num_env_steps_trained_throughput_per_sec': 176.27392916411407, 'timesteps_total': 45000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 45000, 'timers': {'training_iteration_time_ms': 6038.434, 'sample_time_ms': 4639.761, 'load_time_ms': 0.114, 'load_throughput': 8791247.118, 'learn_time_ms': 1398.364, 'learn_throughput': 715.122, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000}, 'done': False, 'episodes_total': 9, 'training_iteration': 45, 'trial_id': 'default', 'date': '2024-09-13_05-48-58', 'timestamp': 1726206538, 'time_this_iter_s': 5.673117160797119, 'time_total_s': 273.7198157310486, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab79750>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 273.7198157310486, 'iterations_since_restore': 45, 'perf': {'cpu_util_percent': 11.55, 'ram_util_percent': 12.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.982558145125707, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.711846964699882, 'policy_loss': 0.010312806318203608, 'vf_loss': 9.699985099974132, 'vf_explained_var': -1.3907750447591146e-08, 'kl': 0.015490204581250836, 'entropy': 5.2091888881865005, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 9555.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 46000, 'num_env_steps_trained': 46000, 'num_agent_steps_sampled': 46000, 'num_agent_steps_trained': 46000}, 'sampler_results': {'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 337.99918446180607, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -227.20968423514634, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15619252498096756, 'mean_inference_ms': 0.9426393046239964, 'mean_action_processing_ms': 0.1369288543056833, 'mean_env_wait_ms': 3.5622445970804386, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 46000, 'num_agent_steps_trained': 46000, 'num_env_steps_sampled': 46000, 'num_env_steps_trained': 46000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.90946757901892, 'num_env_steps_trained_throughput_per_sec': 178.90946757901892, 'timesteps_total': 46000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 46000, 'timers': {'training_iteration_time_ms': 6033.563, 'sample_time_ms': 4639.419, 'load_time_ms': 0.114, 'load_throughput': 8780205.15, 'learn_time_ms': 1393.836, 'learn_throughput': 717.445, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 46000, 'num_env_steps_trained': 46000, 'num_agent_steps_sampled': 46000, 'num_agent_steps_trained': 46000}, 'done': False, 'episodes_total': 9, 'training_iteration': 46, 'trial_id': 'default', 'date': '2024-09-13_05-49-03', 'timestamp': 1726206543, 'time_this_iter_s': 5.58954644203186, 'time_total_s': 279.30936217308044, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659523ed0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 279.30936217308044, 'iterations_since_restore': 46, 'perf': {'cpu_util_percent': 11.600000000000001, 'ram_util_percent': 12.375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.7369662801424661, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.635338651566279, 'policy_loss': -0.13318083441062342, 'vf_loss': 9.766957687196278, 'vf_explained_var': -1.5043077014741443e-08, 'kl': 0.015617545170105308, 'entropy': 5.112562545140585, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 9765.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 47000, 'num_env_steps_trained': 47000, 'num_agent_steps_sampled': 47000, 'num_agent_steps_trained': 47000}, 'sampler_results': {'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 47000, 'num_agent_steps_trained': 47000, 'num_env_steps_sampled': 47000, 'num_env_steps_trained': 47000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.81888523658913, 'num_env_steps_trained_throughput_per_sec': 128.81888523658913, 'timesteps_total': 47000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 47000, 'timers': {'training_iteration_time_ms': 6044.777, 'sample_time_ms': 4650.189, 'load_time_ms': 0.114, 'load_throughput': 8758204.218, 'learn_time_ms': 1394.278, 'learn_throughput': 717.217, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 47000, 'num_env_steps_trained': 47000, 'num_agent_steps_sampled': 47000, 'num_agent_steps_trained': 47000}, 'done': False, 'episodes_total': 10, 'training_iteration': 47, 'trial_id': 'default', 'date': '2024-09-13_05-49-11', 'timestamp': 1726206551, 'time_this_iter_s': 7.762973785400391, 'time_total_s': 287.07233595848083, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597f9390>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 287.07233595848083, 'iterations_since_restore': 47, 'perf': {'cpu_util_percent': 11.0, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.9474910642419543, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.351693246478126, 'policy_loss': -0.1177910233537356, 'vf_loss': 9.468328244345528, 'vf_explained_var': -9.65027582077753e-09, 'kl': 0.011560492993088528, 'entropy': 5.093478843144008, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 9975.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 48000, 'num_env_steps_trained': 48000, 'num_agent_steps_sampled': 48000, 'num_agent_steps_trained': 48000}, 'sampler_results': {'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 48000, 'num_agent_steps_trained': 48000, 'num_env_steps_sampled': 48000, 'num_env_steps_trained': 48000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.30971473064008, 'num_env_steps_trained_throughput_per_sec': 180.30971473064008, 'timesteps_total': 48000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 48000, 'timers': {'training_iteration_time_ms': 6039.966, 'sample_time_ms': 4644.358, 'load_time_ms': 0.114, 'load_throughput': 8752721.202, 'learn_time_ms': 1395.295, 'learn_throughput': 716.694, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 48000, 'num_env_steps_trained': 48000, 'num_agent_steps_sampled': 48000, 'num_agent_steps_trained': 48000}, 'done': False, 'episodes_total': 10, 'training_iteration': 48, 'trial_id': 'default', 'date': '2024-09-13_05-49-17', 'timestamp': 1726206557, 'time_this_iter_s': 5.546146869659424, 'time_total_s': 292.61848282814026, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659520e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 292.61848282814026, 'iterations_since_restore': 48, 'perf': {'cpu_util_percent': 11.7375, 'ram_util_percent': 12.350000000000001}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.0788056717032477, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.489018730890184, 'policy_loss': -0.09470103872673852, 'vf_loss': 9.582650270916167, 'vf_explained_var': -1.9868214925130207e-08, 'kl': 0.010695601784027531, 'entropy': 4.992483929225377, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 10185.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 49000, 'num_env_steps_trained': 49000, 'num_agent_steps_sampled': 49000, 'num_agent_steps_trained': 49000}, 'sampler_results': {'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 49000, 'num_agent_steps_trained': 49000, 'num_env_steps_sampled': 49000, 'num_env_steps_trained': 49000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.43795242338334, 'num_env_steps_trained_throughput_per_sec': 179.43795242338334, 'timesteps_total': 49000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 49000, 'timers': {'training_iteration_time_ms': 6037.775, 'sample_time_ms': 4643.611, 'load_time_ms': 0.115, 'load_throughput': 8729040.583, 'learn_time_ms': 1393.851, 'learn_throughput': 717.437, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 49000, 'num_env_steps_trained': 49000, 'num_agent_steps_sampled': 49000, 'num_agent_steps_trained': 49000}, 'done': False, 'episodes_total': 10, 'training_iteration': 49, 'trial_id': 'default', 'date': '2024-09-13_05-49-22', 'timestamp': 1726206562, 'time_this_iter_s': 5.573096036911011, 'time_total_s': 298.19157886505127, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659522b10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 298.19157886505127, 'iterations_since_restore': 49, 'perf': {'cpu_util_percent': 11.9125, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.2914849956830343, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.313386442547753, 'policy_loss': -0.12503666791710116, 'vf_loss': 9.437082937785558, 'vf_explained_var': -1.731373014904204e-08, 'kl': 0.013401800782109301, 'entropy': 4.938410690852574, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 10395.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000}, 'sampler_results': {'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 471.4494873697916, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -157.34376707465256, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15630153177183448, 'mean_inference_ms': 0.9437974781122435, 'mean_action_processing_ms': 0.13711905164760502, 'mean_env_wait_ms': 3.5482922068559524, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000, 'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.1961273744007, 'num_env_steps_trained_throughput_per_sec': 178.1961273744007, 'timesteps_total': 50000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 50000, 'timers': {'training_iteration_time_ms': 6040.473, 'sample_time_ms': 4645.248, 'load_time_ms': 0.114, 'load_throughput': 8800469.996, 'learn_time_ms': 1394.913, 'learn_throughput': 716.891, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000}, 'done': False, 'episodes_total': 10, 'training_iteration': 50, 'trial_id': 'default', 'date': '2024-09-13_05-49-28', 'timestamp': 1726206568, 'time_this_iter_s': 5.611930847167969, 'time_total_s': 303.80350971221924, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6595210d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 303.80350971221924, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': 11.712500000000002, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.7863257013616107, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.696080607459658, 'policy_loss': -0.1670923391268367, 'vf_loss': 9.8613800684611, 'vf_explained_var': -6.244296119326637e-09, 'kl': 0.017928902146204132, 'entropy': 4.759598273322696, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 10605.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 51000, 'num_env_steps_trained': 51000, 'num_agent_steps_sampled': 51000, 'num_agent_steps_trained': 51000}, 'sampler_results': {'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 51000, 'num_agent_steps_trained': 51000, 'num_env_steps_sampled': 51000, 'num_env_steps_trained': 51000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 129.14108651015906, 'num_env_steps_trained_throughput_per_sec': 129.14108651015906, 'timesteps_total': 51000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 51000, 'timers': {'training_iteration_time_ms': 6244.154, 'sample_time_ms': 4849.554, 'load_time_ms': 0.114, 'load_throughput': 8789404.862, 'learn_time_ms': 1394.287, 'learn_throughput': 717.212, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 51000, 'num_env_steps_trained': 51000, 'num_agent_steps_sampled': 51000, 'num_agent_steps_trained': 51000}, 'done': False, 'episodes_total': 11, 'training_iteration': 51, 'trial_id': 'default', 'date': '2024-09-13_05-49-36', 'timestamp': 1726206576, 'time_this_iter_s': 7.743616819381714, 'time_total_s': 311.54712653160095, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659601490>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 311.54712653160095, 'iterations_since_restore': 51, 'perf': {'cpu_util_percent': 11.118181818181817, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.8877167099998111, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.792544178735643, 'policy_loss': -0.06412522831843012, 'vf_loss': 9.855869602021716, 'vf_explained_var': -6.244296119326637e-09, 'kl': 0.007998599748931329, 'entropy': 4.693776534852527, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 10815.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 52000, 'num_env_steps_trained': 52000, 'num_agent_steps_sampled': 52000, 'num_agent_steps_trained': 52000}, 'sampler_results': {'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 52000, 'num_agent_steps_trained': 52000, 'num_env_steps_sampled': 52000, 'num_env_steps_trained': 52000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.81453270788003, 'num_env_steps_trained_throughput_per_sec': 181.81453270788003, 'timesteps_total': 52000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 52000, 'timers': {'training_iteration_time_ms': 6013.005, 'sample_time_ms': 4619.972, 'load_time_ms': 0.114, 'load_throughput': 8783882.723, 'learn_time_ms': 1392.72, 'learn_throughput': 718.019, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 52000, 'num_env_steps_trained': 52000, 'num_agent_steps_sampled': 52000, 'num_agent_steps_trained': 52000}, 'done': False, 'episodes_total': 11, 'training_iteration': 52, 'trial_id': 'default', 'date': '2024-09-13_05-49-41', 'timestamp': 1726206581, 'time_this_iter_s': 5.500239849090576, 'time_total_s': 317.0473663806915, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c657790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 317.0473663806915, 'iterations_since_restore': 52, 'perf': {'cpu_util_percent': 11.837499999999999, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.184641201439358, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.837063816615514, 'policy_loss': -0.04061645446788697, 'vf_loss': 9.87667944771903, 'vf_explained_var': -2.2706531343005954e-09, 'kl': 0.010007961379458441, 'entropy': 4.681349331992013, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 11025.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 53000, 'num_env_steps_trained': 53000, 'num_agent_steps_sampled': 53000, 'num_agent_steps_trained': 53000}, 'sampler_results': {'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 53000, 'num_agent_steps_trained': 53000, 'num_env_steps_sampled': 53000, 'num_env_steps_trained': 53000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.71273195341888, 'num_env_steps_trained_throughput_per_sec': 181.71273195341888, 'timesteps_total': 53000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 53000, 'timers': {'training_iteration_time_ms': 5999.67, 'sample_time_ms': 4610.381, 'load_time_ms': 0.114, 'load_throughput': 8794933.948, 'learn_time_ms': 1388.982, 'learn_throughput': 719.952, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 53000, 'num_env_steps_trained': 53000, 'num_agent_steps_sampled': 53000, 'num_agent_steps_trained': 53000}, 'done': False, 'episodes_total': 11, 'training_iteration': 53, 'trial_id': 'default', 'date': '2024-09-13_05-49-47', 'timestamp': 1726206587, 'time_this_iter_s': 5.503323793411255, 'time_total_s': 322.5506901741028, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659523e10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 322.5506901741028, 'iterations_since_restore': 53, 'perf': {'cpu_util_percent': 11.575, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.120425833974566, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.772058763958158, 'policy_loss': 0.00017403193882533483, 'vf_loss': 9.770819822947184, 'vf_explained_var': -1.0501770746140254e-08, 'kl': 0.010649297684929998, 'entropy': 4.606443509601411, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 11235.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 54000, 'num_env_steps_trained': 54000, 'num_agent_steps_sampled': 54000, 'num_agent_steps_trained': 54000}, 'sampler_results': {'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 54000, 'num_agent_steps_trained': 54000, 'num_env_steps_sampled': 54000, 'num_env_steps_trained': 54000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.42768241437244, 'num_env_steps_trained_throughput_per_sec': 180.42768241437244, 'timesteps_total': 54000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 54000, 'timers': {'training_iteration_time_ms': 6004.507, 'sample_time_ms': 4614.31, 'load_time_ms': 0.115, 'load_throughput': 8680264.901, 'learn_time_ms': 1389.888, 'learn_throughput': 719.482, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 54000, 'num_env_steps_trained': 54000, 'num_agent_steps_sampled': 54000, 'num_agent_steps_trained': 54000}, 'done': False, 'episodes_total': 11, 'training_iteration': 54, 'trial_id': 'default', 'date': '2024-09-13_05-49-52', 'timestamp': 1726206592, 'time_this_iter_s': 5.542516231536865, 'time_total_s': 328.09320640563965, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6595ae350>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 328.09320640563965, 'iterations_since_restore': 54, 'perf': {'cpu_util_percent': 11.7875, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.3342899365084513, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.817928795587449, 'policy_loss': 0.0007265630843383926, 'vf_loss': 9.815615781148274, 'vf_explained_var': -1.1069434029715402e-08, 'kl': 0.015864588779645417, 'entropy': 4.5669229779924665, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 11445.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000}, 'sampler_results': {'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1200.4949386284707, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': -33.90388473800499, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15641749531651356, 'mean_inference_ms': 0.9448491171608917, 'mean_action_processing_ms': 0.13729376721089304, 'mean_env_wait_ms': 3.537013069803481, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000, 'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.6235605445779, 'num_env_steps_trained_throughput_per_sec': 177.6235605445779, 'timesteps_total': 55000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 55000, 'timers': {'training_iteration_time_ms': 6000.197, 'sample_time_ms': 4608.036, 'load_time_ms': 0.116, 'load_throughput': 8623157.895, 'learn_time_ms': 1391.851, 'learn_throughput': 718.468, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000}, 'done': False, 'episodes_total': 11, 'training_iteration': 55, 'trial_id': 'default', 'date': '2024-09-13_05-49-58', 'timestamp': 1726206598, 'time_this_iter_s': 5.6300108432769775, 'time_total_s': 333.7232172489166, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab82490>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 333.7232172489166, 'iterations_since_restore': 55, 'perf': {'cpu_util_percent': 12.037500000000001, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.0578351554416474, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.821680691128686, 'policy_loss': -0.05294846387668734, 'vf_loss': 9.87281601315453, 'vf_explained_var': 7.947285970052083e-09, 'kl': 0.018131421426577227, 'entropy': 4.367435500735328, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 11655.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 56000, 'num_env_steps_trained': 56000, 'num_agent_steps_sampled': 56000, 'num_agent_steps_trained': 56000}, 'sampler_results': {'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 56000, 'num_agent_steps_trained': 56000, 'num_env_steps_sampled': 56000, 'num_env_steps_trained': 56000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.59501976210517, 'num_env_steps_trained_throughput_per_sec': 127.59501976210517, 'timesteps_total': 56000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 56000, 'timers': {'training_iteration_time_ms': 6224.984, 'sample_time_ms': 4830.414, 'load_time_ms': 0.116, 'load_throughput': 8653402.104, 'learn_time_ms': 1394.26, 'learn_throughput': 717.226, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 56000, 'num_env_steps_trained': 56000, 'num_agent_steps_sampled': 56000, 'num_agent_steps_trained': 56000}, 'done': False, 'episodes_total': 12, 'training_iteration': 56, 'trial_id': 'default', 'date': '2024-09-13_05-50-06', 'timestamp': 1726206606, 'time_this_iter_s': 7.837438106536865, 'time_total_s': 341.5606553554535, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab82bd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 341.5606553554535, 'iterations_since_restore': 56, 'perf': {'cpu_util_percent': 11.009090909090908, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.14370092465764, 'cur_kl_coeff': 0.1, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.913888404482886, 'policy_loss': 0.015872449818111603, 'vf_loss': 9.896006143660772, 'vf_explained_var': -8.514949253627232e-10, 'kl': 0.020098180674748264, 'entropy': 4.233038023539952, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 11865.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 57000, 'num_env_steps_trained': 57000, 'num_agent_steps_sampled': 57000, 'num_agent_steps_trained': 57000}, 'sampler_results': {'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 57000, 'num_agent_steps_trained': 57000, 'num_env_steps_sampled': 57000, 'num_env_steps_trained': 57000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.65264703743247, 'num_env_steps_trained_throughput_per_sec': 179.65264703743247, 'timesteps_total': 57000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 57000, 'timers': {'training_iteration_time_ms': 6005.33, 'sample_time_ms': 4613.732, 'load_time_ms': 0.116, 'load_throughput': 8637364.086, 'learn_time_ms': 1391.287, 'learn_throughput': 718.759, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 57000, 'num_env_steps_trained': 57000, 'num_agent_steps_sampled': 57000, 'num_agent_steps_trained': 57000}, 'done': False, 'episodes_total': 12, 'training_iteration': 57, 'trial_id': 'default', 'date': '2024-09-13_05-50-11', 'timestamp': 1726206611, 'time_this_iter_s': 5.566449403762817, 'time_total_s': 347.1271047592163, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab40390>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 347.1271047592163, 'iterations_since_restore': 57, 'perf': {'cpu_util_percent': 11.774999999999999, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.9078873254003978, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.581727672758557, 'policy_loss': -0.06037452660855793, 'vf_loss': 9.639822519393194, 'vf_explained_var': -1.475924537295387e-08, 'kl': 0.015197826503797494, 'entropy': 4.098262577965146, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 12075.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 58000, 'num_env_steps_trained': 58000, 'num_agent_steps_sampled': 58000, 'num_agent_steps_trained': 58000}, 'sampler_results': {'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 58000, 'num_agent_steps_trained': 58000, 'num_env_steps_sampled': 58000, 'num_env_steps_trained': 58000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.02118761145223, 'num_env_steps_trained_throughput_per_sec': 181.02118761145223, 'timesteps_total': 58000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 58000, 'timers': {'training_iteration_time_ms': 6003.151, 'sample_time_ms': 4610.311, 'load_time_ms': 0.115, 'load_throughput': 8660549.246, 'learn_time_ms': 1392.529, 'learn_throughput': 718.118, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 58000, 'num_env_steps_trained': 58000, 'num_agent_steps_sampled': 58000, 'num_agent_steps_trained': 58000}, 'done': False, 'episodes_total': 12, 'training_iteration': 58, 'trial_id': 'default', 'date': '2024-09-13_05-50-17', 'timestamp': 1726206617, 'time_this_iter_s': 5.524348258972168, 'time_total_s': 352.6514530181885, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6596247d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 352.6514530181885, 'iterations_since_restore': 58, 'perf': {'cpu_util_percent': 11.7625, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.9192050684066047, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.975483553750175, 'policy_loss': 0.06358686593316851, 'vf_loss': 9.909951255435036, 'vf_explained_var': -3.973642985026042e-09, 'kl': 0.012969687733788132, 'entropy': 4.054678855623518, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 12285.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 59000, 'num_env_steps_trained': 59000, 'num_agent_steps_sampled': 59000, 'num_agent_steps_trained': 59000}, 'sampler_results': {'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1489.4856608072903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 93.04524405743628, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15652669786013435, 'mean_inference_ms': 0.9457230962297071, 'mean_action_processing_ms': 0.13744059730089417, 'mean_env_wait_ms': 3.5270919681270825, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 59000, 'num_agent_steps_trained': 59000, 'num_env_steps_sampled': 59000, 'num_env_steps_trained': 59000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.25045175379486, 'num_env_steps_trained_throughput_per_sec': 180.25045175379486, 'timesteps_total': 59000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 59000, 'timers': {'training_iteration_time_ms': 6000.639, 'sample_time_ms': 4604.995, 'load_time_ms': 0.116, 'load_throughput': 8655187.784, 'learn_time_ms': 1395.333, 'learn_throughput': 716.675, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 59000, 'num_env_steps_trained': 59000, 'num_agent_steps_sampled': 59000, 'num_agent_steps_trained': 59000}, 'done': False, 'episodes_total': 12, 'training_iteration': 59, 'trial_id': 'default', 'date': '2024-09-13_05-50-23', 'timestamp': 1726206623, 'time_this_iter_s': 5.547970294952393, 'time_total_s': 358.19942331314087, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659554850>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 358.19942331314087, 'iterations_since_restore': 59, 'perf': {'cpu_util_percent': 11.774999999999999, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.4123959592410498, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.798380806332542, 'policy_loss': 0.024077383393333072, 'vf_loss': 9.77307984488351, 'vf_explained_var': 3.150531223842076e-08, 'kl': 0.008157000719525275, 'entropy': 3.9750132163365683, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 12495.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'sampler_results': {'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.76566212988388, 'num_env_steps_trained_throughput_per_sec': 128.76566212988388, 'timesteps_total': 60000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 60000, 'timers': {'training_iteration_time_ms': 6216.064, 'sample_time_ms': 4823.09, 'load_time_ms': 0.115, 'load_throughput': 8676673.562, 'learn_time_ms': 1392.664, 'learn_throughput': 718.048, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'done': False, 'episodes_total': 13, 'training_iteration': 60, 'trial_id': 'default', 'date': '2024-09-13_05-50-30', 'timestamp': 1726206630, 'time_this_iter_s': 7.766194105148315, 'time_total_s': 365.9656174182892, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab7bad0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 365.9656174182892, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 11.054545454545455, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.4901106164568945, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.876073483058384, 'policy_loss': 0.009182698598929813, 'vf_loss': 9.86504230045137, 'vf_explained_var': -2.6112511044456845e-08, 'kl': 0.012323376294114617, 'entropy': 3.9977962380363827, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 12705.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 61000, 'num_env_steps_trained': 61000, 'num_agent_steps_sampled': 61000, 'num_agent_steps_trained': 61000}, 'sampler_results': {'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 61000, 'num_agent_steps_trained': 61000, 'num_env_steps_sampled': 61000, 'num_env_steps_trained': 61000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.07010408257167, 'num_env_steps_trained_throughput_per_sec': 177.07010408257167, 'timesteps_total': 61000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 61000, 'timers': {'training_iteration_time_ms': 6006.465, 'sample_time_ms': 4614.7, 'load_time_ms': 0.114, 'load_throughput': 8771024.676, 'learn_time_ms': 1391.46, 'learn_throughput': 718.67, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 61000, 'num_env_steps_trained': 61000, 'num_agent_steps_sampled': 61000, 'num_agent_steps_trained': 61000}, 'done': False, 'episodes_total': 13, 'training_iteration': 61, 'trial_id': 'default', 'date': '2024-09-13_05-50-36', 'timestamp': 1726206636, 'time_this_iter_s': 5.647615432739258, 'time_total_s': 371.61323285102844, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659520e90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 371.61323285102844, 'iterations_since_restore': 61, 'perf': {'cpu_util_percent': 11.600000000000001, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.2274362941583, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.909378142583938, 'policy_loss': 0.03551728640283857, 'vf_loss': 9.871844759441558, 'vf_explained_var': -6.528127761114211e-09, 'kl': 0.013440787925390482, 'entropy': 3.8922248567853654, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 12915.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 62000, 'num_env_steps_trained': 62000, 'num_agent_steps_sampled': 62000, 'num_agent_steps_trained': 62000}, 'sampler_results': {'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 62000, 'num_agent_steps_trained': 62000, 'num_env_steps_sampled': 62000, 'num_env_steps_trained': 62000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.99840013018684, 'num_env_steps_trained_throughput_per_sec': 179.99840013018684, 'timesteps_total': 62000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 62000, 'timers': {'training_iteration_time_ms': 6012.014, 'sample_time_ms': 4619.003, 'load_time_ms': 0.114, 'load_throughput': 8787563.377, 'learn_time_ms': 1392.706, 'learn_throughput': 718.027, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 62000, 'num_env_steps_trained': 62000, 'num_agent_steps_sampled': 62000, 'num_agent_steps_trained': 62000}, 'done': False, 'episodes_total': 13, 'training_iteration': 62, 'trial_id': 'default', 'date': '2024-09-13_05-50-42', 'timestamp': 1726206642, 'time_this_iter_s': 5.555748462677002, 'time_total_s': 377.16898131370544, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658432450>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 377.16898131370544, 'iterations_since_restore': 62, 'perf': {'cpu_util_percent': 11.925, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.4724742026556106, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.809742273603167, 'policy_loss': 0.04099435440841175, 'vf_loss': 9.767084167117165, 'vf_explained_var': 4.257474626813616e-09, 'kl': 0.011091765084226305, 'entropy': 3.8029801539012364, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 13125.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 63000, 'num_env_steps_trained': 63000, 'num_agent_steps_sampled': 63000, 'num_agent_steps_trained': 63000}, 'sampler_results': {'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 63000, 'num_agent_steps_trained': 63000, 'num_env_steps_sampled': 63000, 'num_env_steps_trained': 63000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.6119602512966, 'num_env_steps_trained_throughput_per_sec': 182.6119602512966, 'timesteps_total': 63000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 63000, 'timers': {'training_iteration_time_ms': 6009.304, 'sample_time_ms': 4615.602, 'load_time_ms': 0.115, 'load_throughput': 8719966.736, 'learn_time_ms': 1393.395, 'learn_throughput': 717.671, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 63000, 'num_env_steps_trained': 63000, 'num_agent_steps_sampled': 63000, 'num_agent_steps_trained': 63000}, 'done': False, 'episodes_total': 13, 'training_iteration': 63, 'trial_id': 'default', 'date': '2024-09-13_05-50-47', 'timestamp': 1726206647, 'time_this_iter_s': 5.476227521896362, 'time_total_s': 382.6452088356018, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659557f90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 382.6452088356018, 'iterations_since_restore': 63, 'perf': {'cpu_util_percent': 11.850000000000001, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.5813848245711553, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.97041256768363, 'policy_loss': -0.009967686590694245, 'vf_loss': 9.97863959357852, 'vf_explained_var': 8.514949253627232e-10, 'kl': 0.011603733684612717, 'entropy': 3.7722460894357592, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 13335.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 64000, 'num_env_steps_trained': 64000, 'num_agent_steps_sampled': 64000, 'num_agent_steps_trained': 64000}, 'sampler_results': {'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1721.4506461588535, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 218.3071980652376, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15663036631726315, 'mean_inference_ms': 0.9464913119304531, 'mean_action_processing_ms': 0.1375741385093046, 'mean_env_wait_ms': 3.5187940535742, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 64000, 'num_agent_steps_trained': 64000, 'num_env_steps_sampled': 64000, 'num_env_steps_trained': 64000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.02743011157742, 'num_env_steps_trained_throughput_per_sec': 178.02743011157742, 'timesteps_total': 64000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 64000, 'timers': {'training_iteration_time_ms': 6016.777, 'sample_time_ms': 4622.437, 'load_time_ms': 0.114, 'load_throughput': 8776530.655, 'learn_time_ms': 1394.034, 'learn_throughput': 717.343, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 64000, 'num_env_steps_trained': 64000, 'num_agent_steps_sampled': 64000, 'num_agent_steps_trained': 64000}, 'done': False, 'episodes_total': 13, 'training_iteration': 64, 'trial_id': 'default', 'date': '2024-09-13_05-50-53', 'timestamp': 1726206653, 'time_this_iter_s': 5.617246389389038, 'time_total_s': 388.26245522499084, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65ceac390>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 388.26245522499084, 'iterations_since_restore': 64, 'perf': {'cpu_util_percent': 11.5875, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.568799755119142, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.650334657941546, 'policy_loss': -0.19073016586979585, 'vf_loss': 9.838283834003267, 'vf_explained_var': 7.379622686476935e-09, 'kl': 0.018540011122379275, 'entropy': 3.6680728299277168, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 13545.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000, 'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.7529778107533, 'num_env_steps_trained_throughput_per_sec': 128.7529778107533, 'timesteps_total': 65000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 65000, 'timers': {'training_iteration_time_ms': 6230.469, 'sample_time_ms': 4838.439, 'load_time_ms': 0.113, 'load_throughput': 8820828.601, 'learn_time_ms': 1391.723, 'learn_throughput': 718.534, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000}, 'done': False, 'episodes_total': 14, 'training_iteration': 65, 'trial_id': 'default', 'date': '2024-09-13_05-51-00', 'timestamp': 1726206660, 'time_this_iter_s': 7.766956090927124, 'time_total_s': 396.02941131591797, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659624410>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 396.02941131591797, 'iterations_since_restore': 65, 'perf': {'cpu_util_percent': 11.0, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.8531269402731034, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.720957415444511, 'policy_loss': -0.1062950760835693, 'vf_loss': 9.825324671609062, 'vf_explained_var': 4.825137910388765e-09, 'kl': 0.012851680803509154, 'entropy': 3.578761536734445, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 13755.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 66000, 'num_env_steps_trained': 66000, 'num_agent_steps_sampled': 66000, 'num_agent_steps_trained': 66000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 66000, 'num_agent_steps_trained': 66000, 'num_env_steps_sampled': 66000, 'num_env_steps_trained': 66000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.0028375338498, 'num_env_steps_trained_throughput_per_sec': 181.0028375338498, 'timesteps_total': 66000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 66000, 'timers': {'training_iteration_time_ms': 5999.217, 'sample_time_ms': 4605.642, 'load_time_ms': 0.115, 'load_throughput': 8694660.033, 'learn_time_ms': 1393.268, 'learn_throughput': 717.737, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 66000, 'num_env_steps_trained': 66000, 'num_agent_steps_sampled': 66000, 'num_agent_steps_trained': 66000}, 'done': False, 'episodes_total': 14, 'training_iteration': 66, 'trial_id': 'default', 'date': '2024-09-13_05-51-06', 'timestamp': 1726206666, 'time_this_iter_s': 5.524912357330322, 'time_total_s': 401.5543236732483, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea7fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 401.5543236732483, 'iterations_since_restore': 66, 'perf': {'cpu_util_percent': 11.725, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.017022288413275, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.744824436732701, 'policy_loss': -0.11434149713743301, 'vf_loss': 9.85756653376988, 'vf_explained_var': -9.934107462565104e-09, 'kl': 0.010662666352055625, 'entropy': 3.55364202771868, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 13965.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 67000, 'num_env_steps_trained': 67000, 'num_agent_steps_sampled': 67000, 'num_agent_steps_trained': 67000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 67000, 'num_agent_steps_trained': 67000, 'num_env_steps_sampled': 67000, 'num_env_steps_trained': 67000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.03023893912615, 'num_env_steps_trained_throughput_per_sec': 180.03023893912615, 'timesteps_total': 67000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 67000, 'timers': {'training_iteration_time_ms': 5998.049, 'sample_time_ms': 4602.219, 'load_time_ms': 0.115, 'load_throughput': 8694660.033, 'learn_time_ms': 1395.524, 'learn_throughput': 716.577, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 67000, 'num_env_steps_trained': 67000, 'num_agent_steps_sampled': 67000, 'num_agent_steps_trained': 67000}, 'done': False, 'episodes_total': 14, 'training_iteration': 67, 'trial_id': 'default', 'date': '2024-09-13_05-51-12', 'timestamp': 1726206672, 'time_this_iter_s': 5.554759740829468, 'time_total_s': 407.10908341407776, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab80e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 407.10908341407776, 'iterations_since_restore': 67, 'perf': {'cpu_util_percent': 11.6875, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.896165516262963, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.623709160940988, 'policy_loss': -0.08410236865636848, 'vf_loss': 9.706074882688977, 'vf_explained_var': 8.514949253627232e-10, 'kl': 0.01157730031353865, 'entropy': 3.612693176950727, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 14175.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 68000, 'num_env_steps_trained': 68000, 'num_agent_steps_sampled': 68000, 'num_agent_steps_trained': 68000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 68000, 'num_agent_steps_trained': 68000, 'num_env_steps_sampled': 68000, 'num_env_steps_trained': 68000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.04907099241814, 'num_env_steps_trained_throughput_per_sec': 177.04907099241814, 'timesteps_total': 68000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 68000, 'timers': {'training_iteration_time_ms': 6010.442, 'sample_time_ms': 4617.435, 'load_time_ms': 0.115, 'load_throughput': 8687456.504, 'learn_time_ms': 1392.702, 'learn_throughput': 718.029, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 68000, 'num_env_steps_trained': 68000, 'num_agent_steps_sampled': 68000, 'num_agent_steps_trained': 68000}, 'done': False, 'episodes_total': 14, 'training_iteration': 68, 'trial_id': 'default', 'date': '2024-09-13_05-51-17', 'timestamp': 1726206677, 'time_this_iter_s': 5.648288726806641, 'time_total_s': 412.7573721408844, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597f7790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 412.7573721408844, 'iterations_since_restore': 68, 'perf': {'cpu_util_percent': 11.45, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.286303515093667, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.749947361719041, 'policy_loss': -0.09854935393446967, 'vf_loss': 9.846872175307501, 'vf_explained_var': -1.2488592238653274e-08, 'kl': 0.010830198801548802, 'entropy': 3.6117419117972966, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 14385.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 69000, 'num_env_steps_trained': 69000, 'num_agent_steps_sampled': 69000, 'num_agent_steps_trained': 69000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 335.03982296937005, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1567258952314838, 'mean_inference_ms': 0.9471512392135716, 'mean_action_processing_ms': 0.13768889936347256, 'mean_env_wait_ms': 3.511379134474037, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 69000, 'num_agent_steps_trained': 69000, 'num_env_steps_sampled': 69000, 'num_env_steps_trained': 69000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.7845627897424, 'num_env_steps_trained_throughput_per_sec': 180.7845627897424, 'timesteps_total': 69000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 69000, 'timers': {'training_iteration_time_ms': 6008.803, 'sample_time_ms': 4619.939, 'load_time_ms': 0.116, 'load_throughput': 8655187.784, 'learn_time_ms': 1388.559, 'learn_throughput': 720.171, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 69000, 'num_env_steps_trained': 69000, 'num_agent_steps_sampled': 69000, 'num_agent_steps_trained': 69000}, 'done': False, 'episodes_total': 14, 'training_iteration': 69, 'trial_id': 'default', 'date': '2024-09-13_05-51-23', 'timestamp': 1726206683, 'time_this_iter_s': 5.5315752029418945, 'time_total_s': 418.2889473438263, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab6dbd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 418.2889473438263, 'iterations_since_restore': 69, 'perf': {'cpu_util_percent': 11.674999999999999, 'ram_util_percent': 12.412500000000001}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.793372805345626, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.522431328183128, 'policy_loss': -0.15460840330592224, 'vf_loss': 9.674696400052024, 'vf_explained_var': -2.0152046566917784e-08, 'kl': 0.015622115748382862, 'entropy': 3.4488297632762364, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 14595.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000, 'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.89399801354828, 'num_env_steps_trained_throughput_per_sec': 127.89399801354828, 'timesteps_total': 70000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 70000, 'timers': {'training_iteration_time_ms': 6014.097, 'sample_time_ms': 4625.963, 'load_time_ms': 0.116, 'load_throughput': 8621385.406, 'learn_time_ms': 1387.828, 'learn_throughput': 720.551, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000}, 'done': False, 'episodes_total': 15, 'training_iteration': 70, 'trial_id': 'default', 'date': '2024-09-13_05-51-31', 'timestamp': 1726206691, 'time_this_iter_s': 7.81912088394165, 'time_total_s': 426.10806822776794, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c670110>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 426.10806822776794, 'iterations_since_restore': 70, 'perf': {'cpu_util_percent': 10.972727272727274, 'ram_util_percent': 12.454545454545455}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.166778100104559, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.725565061115084, 'policy_loss': -0.14205868836669694, 'vf_loss': 9.865941338312059, 'vf_explained_var': 8.231117611839658e-09, 'kl': 0.011216050483129774, 'entropy': 3.37881509917123, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 14805.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 71000, 'num_env_steps_trained': 71000, 'num_agent_steps_sampled': 71000, 'num_agent_steps_trained': 71000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 71000, 'num_agent_steps_trained': 71000, 'num_env_steps_sampled': 71000, 'num_env_steps_trained': 71000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.14892873982046, 'num_env_steps_trained_throughput_per_sec': 181.14892873982046, 'timesteps_total': 71000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 71000, 'timers': {'training_iteration_time_ms': 6001.381, 'sample_time_ms': 4613.317, 'load_time_ms': 0.116, 'load_throughput': 8594885.246, 'learn_time_ms': 1387.758, 'learn_throughput': 720.587, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 71000, 'num_env_steps_trained': 71000, 'num_agent_steps_sampled': 71000, 'num_agent_steps_trained': 71000}, 'done': False, 'episodes_total': 15, 'training_iteration': 71, 'trial_id': 'default', 'date': '2024-09-13_05-51-36', 'timestamp': 1726206696, 'time_this_iter_s': 5.520450115203857, 'time_total_s': 431.6285183429718, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea7fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 431.6285183429718, 'iterations_since_restore': 71, 'perf': {'cpu_util_percent': 11.6625, 'ram_util_percent': 12.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.8771584221294948, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.604896899632045, 'policy_loss': -0.1280595197830172, 'vf_loss': 9.731307129632858, 'vf_explained_var': -2.128737313406808e-08, 'kl': 0.01099491557102911, 'entropy': 3.3351198502949306, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 15015.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 72000, 'num_env_steps_trained': 72000, 'num_agent_steps_sampled': 72000, 'num_agent_steps_trained': 72000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 72000, 'num_agent_steps_trained': 72000, 'num_env_steps_sampled': 72000, 'num_env_steps_trained': 72000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.48327986873227, 'num_env_steps_trained_throughput_per_sec': 181.48327986873227, 'timesteps_total': 72000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 72000, 'timers': {'training_iteration_time_ms': 5996.835, 'sample_time_ms': 4607.062, 'load_time_ms': 0.117, 'load_throughput': 8580818.331, 'learn_time_ms': 1389.467, 'learn_throughput': 719.701, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 72000, 'num_env_steps_trained': 72000, 'num_agent_steps_sampled': 72000, 'num_agent_steps_trained': 72000}, 'done': False, 'episodes_total': 15, 'training_iteration': 72, 'trial_id': 'default', 'date': '2024-09-13_05-51-42', 'timestamp': 1726206702, 'time_this_iter_s': 5.510287046432495, 'time_total_s': 437.1388053894043, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea5a90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 437.1388053894043, 'iterations_since_restore': 72, 'perf': {'cpu_util_percent': 12.274999999999999, 'ram_util_percent': 12.4875}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.9579690507480074, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.701721286773681, 'policy_loss': -0.15607611806619734, 'vf_loss': 9.855756954919725, 'vf_explained_var': 1.419158208937872e-09, 'kl': 0.013603107468432947, 'entropy': 3.2665380001068116, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 15225.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 73000, 'num_env_steps_trained': 73000, 'num_agent_steps_sampled': 73000, 'num_agent_steps_trained': 73000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 433.9670603862848, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1568197661575084, 'mean_inference_ms': 0.947764108620468, 'mean_action_processing_ms': 0.13779379517498272, 'mean_env_wait_ms': 3.504683783247949, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 73000, 'num_agent_steps_trained': 73000, 'num_env_steps_sampled': 73000, 'num_env_steps_trained': 73000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.4393180445765, 'num_env_steps_trained_throughput_per_sec': 176.4393180445765, 'timesteps_total': 73000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 73000, 'timers': {'training_iteration_time_ms': 6015.993, 'sample_time_ms': 4622.026, 'load_time_ms': 0.117, 'load_throughput': 8561551.337, 'learn_time_ms': 1393.662, 'learn_throughput': 717.534, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 73000, 'num_env_steps_trained': 73000, 'num_agent_steps_sampled': 73000, 'num_agent_steps_trained': 73000}, 'done': False, 'episodes_total': 15, 'training_iteration': 73, 'trial_id': 'default', 'date': '2024-09-13_05-51-47', 'timestamp': 1726206707, 'time_this_iter_s': 5.667814254760742, 'time_total_s': 442.80661964416504, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea7fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 442.80661964416504, 'iterations_since_restore': 73, 'perf': {'cpu_util_percent': 11.85, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.0081182973725453, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.593126841953822, 'policy_loss': -0.0360453507729939, 'vf_loss': 9.62710827418736, 'vf_explained_var': -6.8119594029017855e-09, 'kl': 0.013759328708346445, 'entropy': 3.1973441407794043, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 15435.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 74000, 'num_env_steps_trained': 74000, 'num_agent_steps_sampled': 74000, 'num_agent_steps_trained': 74000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 74000, 'num_agent_steps_trained': 74000, 'num_env_steps_sampled': 74000, 'num_env_steps_trained': 74000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.71207879306766, 'num_env_steps_trained_throughput_per_sec': 127.71207879306766, 'timesteps_total': 74000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 74000, 'timers': {'training_iteration_time_ms': 6237.293, 'sample_time_ms': 4843.61, 'load_time_ms': 0.116, 'load_throughput': 8596646.854, 'learn_time_ms': 1393.377, 'learn_throughput': 717.681, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 74000, 'num_env_steps_trained': 74000, 'num_agent_steps_sampled': 74000, 'num_agent_steps_trained': 74000}, 'done': False, 'episodes_total': 16, 'training_iteration': 74, 'trial_id': 'default', 'date': '2024-09-13_05-51-55', 'timestamp': 1726206715, 'time_this_iter_s': 7.830263376235962, 'time_total_s': 450.636883020401, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65842a290>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 450.636883020401, 'iterations_since_restore': 74, 'perf': {'cpu_util_percent': 11.01818181818182, 'ram_util_percent': 12.454545454545455}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.317195089090438, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.809228561038063, 'policy_loss': -0.024154969020968392, 'vf_loss': 9.831962008703323, 'vf_explained_var': -3.973642985026042e-09, 'kl': 0.009477160255690906, 'entropy': 3.083377642858596, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 15645.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000, 'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.32059344737598, 'num_env_steps_trained_throughput_per_sec': 178.32059344737598, 'timesteps_total': 75000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 75000, 'timers': {'training_iteration_time_ms': 6021.399, 'sample_time_ms': 4623.84, 'load_time_ms': 0.117, 'load_throughput': 8547593.234, 'learn_time_ms': 1397.254, 'learn_throughput': 715.69, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000}, 'done': False, 'episodes_total': 16, 'training_iteration': 75, 'trial_id': 'default', 'date': '2024-09-13_05-52-01', 'timestamp': 1726206721, 'time_this_iter_s': 5.608022451400757, 'time_total_s': 456.24490547180176, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c671a50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 456.24490547180176, 'iterations_since_restore': 75, 'perf': {'cpu_util_percent': 11.9125, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.0459259737105597, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.92741629736764, 'policy_loss': 0.07979738178352515, 'vf_loss': 9.845948755173456, 'vf_explained_var': 1.419158208937872e-09, 'kl': 0.011134701740714702, 'entropy': 3.0624095928101314, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 15855.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 76000, 'num_env_steps_trained': 76000, 'num_agent_steps_sampled': 76000, 'num_agent_steps_trained': 76000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 76000, 'num_agent_steps_trained': 76000, 'num_env_steps_sampled': 76000, 'num_env_steps_trained': 76000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.89789979097569, 'num_env_steps_trained_throughput_per_sec': 181.89789979097569, 'timesteps_total': 76000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 76000, 'timers': {'training_iteration_time_ms': 6018.682, 'sample_time_ms': 4619.407, 'load_time_ms': 0.116, 'load_throughput': 8600172.237, 'learn_time_ms': 1398.969, 'learn_throughput': 714.812, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 76000, 'num_env_steps_trained': 76000, 'num_agent_steps_sampled': 76000, 'num_agent_steps_trained': 76000}, 'done': False, 'episodes_total': 16, 'training_iteration': 76, 'trial_id': 'default', 'date': '2024-09-13_05-52-06', 'timestamp': 1726206726, 'time_this_iter_s': 5.497725009918213, 'time_total_s': 461.74263048171997, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6595ae810>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 461.74263048171997, 'iterations_since_restore': 76, 'perf': {'cpu_util_percent': 11.825000000000001, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.218035234156109, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.782812763395764, 'policy_loss': 0.052332275626914844, 'vf_loss': 9.728998288654147, 'vf_explained_var': -2.1003541492280507e-08, 'kl': 0.009881755461711283, 'entropy': 3.0381017934708368, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 16065.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 77000, 'num_env_steps_trained': 77000, 'num_agent_steps_sampled': 77000, 'num_agent_steps_trained': 77000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 77000, 'num_agent_steps_trained': 77000, 'num_env_steps_sampled': 77000, 'num_env_steps_trained': 77000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.22748697946489, 'num_env_steps_trained_throughput_per_sec': 180.22748697946489, 'timesteps_total': 77000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 77000, 'timers': {'training_iteration_time_ms': 6018.074, 'sample_time_ms': 4619.152, 'load_time_ms': 0.116, 'load_throughput': 8624931.112, 'learn_time_ms': 1398.618, 'learn_throughput': 714.991, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 77000, 'num_env_steps_trained': 77000, 'num_agent_steps_sampled': 77000, 'num_agent_steps_trained': 77000}, 'done': False, 'episodes_total': 16, 'training_iteration': 77, 'trial_id': 'default', 'date': '2024-09-13_05-52-12', 'timestamp': 1726206732, 'time_this_iter_s': 5.548679351806641, 'time_total_s': 467.2913098335266, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab80150>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 467.2913098335266, 'iterations_since_restore': 77, 'perf': {'cpu_util_percent': 11.9625, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.99029910280591, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.815024466741653, 'policy_loss': 0.052331846881480445, 'vf_loss': 9.761526598249162, 'vf_explained_var': -6.244296119326637e-09, 'kl': 0.007773103087259125, 'entropy': 3.0393190440677462, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 16275.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 78000, 'num_env_steps_trained': 78000, 'num_agent_steps_sampled': 78000, 'num_agent_steps_trained': 78000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 501.69193404947964, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15690593993100893, 'mean_inference_ms': 0.9483106466250448, 'mean_action_processing_ms': 0.13789209870155905, 'mean_env_wait_ms': 3.4990041094060995, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 78000, 'num_agent_steps_trained': 78000, 'num_env_steps_sampled': 78000, 'num_env_steps_trained': 78000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.89333005270498, 'num_env_steps_trained_throughput_per_sec': 180.89333005270498, 'timesteps_total': 78000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 78000, 'timers': {'training_iteration_time_ms': 6006.071, 'sample_time_ms': 4607.073, 'load_time_ms': 0.116, 'load_throughput': 8632031.282, 'learn_time_ms': 1398.694, 'learn_throughput': 714.953, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 78000, 'num_env_steps_trained': 78000, 'num_agent_steps_sampled': 78000, 'num_agent_steps_trained': 78000}, 'done': False, 'episodes_total': 16, 'training_iteration': 78, 'trial_id': 'default', 'date': '2024-09-13_05-52-17', 'timestamp': 1726206737, 'time_this_iter_s': 5.528255939483643, 'time_total_s': 472.81956577301025, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea5650>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 472.81956577301025, 'iterations_since_restore': 78, 'perf': {'cpu_util_percent': 11.575, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.267241773151216, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.783422556377593, 'policy_loss': -0.03342605817264744, 'vf_loss': 9.815447503044492, 'vf_explained_var': -1.2488592238653274e-08, 'kl': 0.009340846017862316, 'entropy': 2.993118221419198, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 16485.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 79000, 'num_env_steps_trained': 79000, 'num_agent_steps_sampled': 79000, 'num_agent_steps_trained': 79000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 79000, 'num_agent_steps_trained': 79000, 'num_env_steps_sampled': 79000, 'num_env_steps_trained': 79000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.243842547911, 'num_env_steps_trained_throughput_per_sec': 128.243842547911, 'timesteps_total': 79000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 79000, 'timers': {'training_iteration_time_ms': 6232.691, 'sample_time_ms': 4829.844, 'load_time_ms': 0.115, 'load_throughput': 8682061.685, 'learn_time_ms': 1402.543, 'learn_throughput': 712.99, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 79000, 'num_env_steps_trained': 79000, 'num_agent_steps_sampled': 79000, 'num_agent_steps_trained': 79000}, 'done': False, 'episodes_total': 17, 'training_iteration': 79, 'trial_id': 'default', 'date': '2024-09-13_05-52-25', 'timestamp': 1726206745, 'time_this_iter_s': 7.797792673110962, 'time_total_s': 480.6173584461212, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659600990>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 480.6173584461212, 'iterations_since_restore': 79, 'perf': {'cpu_util_percent': 11.272727272727273, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.829164209819975, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.923654992239817, 'policy_loss': 0.054445609663214004, 'vf_loss': 9.867682361602784, 'vf_explained_var': 8.514949253627232e-10, 'kl': 0.010179736705287705, 'entropy': 3.016191976411002, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 16695.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.4554152793335, 'num_env_steps_trained_throughput_per_sec': 181.4554152793335, 'timesteps_total': 80000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 6001.893, 'sample_time_ms': 4599.398, 'load_time_ms': 0.115, 'load_throughput': 8689256.267, 'learn_time_ms': 1402.191, 'learn_throughput': 713.17, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'done': False, 'episodes_total': 17, 'training_iteration': 80, 'trial_id': 'default', 'date': '2024-09-13_05-52-31', 'timestamp': 1726206751, 'time_this_iter_s': 5.511136531829834, 'time_total_s': 486.12849497795105, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659602ad0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 486.12849497795105, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 11.95, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.1782938838005066, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.784074183872768, 'policy_loss': -0.035169510224035805, 'vf_loss': 9.816920739128475, 'vf_explained_var': -1.0501770746140254e-08, 'kl': 0.015486702118124437, 'entropy': 2.894632463228135, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 16905.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 81000, 'num_env_steps_trained': 81000, 'num_agent_steps_sampled': 81000, 'num_agent_steps_trained': 81000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 81000, 'num_agent_steps_trained': 81000, 'num_env_steps_sampled': 81000, 'num_env_steps_trained': 81000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.21115629419262, 'num_env_steps_trained_throughput_per_sec': 177.21115629419262, 'timesteps_total': 81000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 81000, 'timers': {'training_iteration_time_ms': 6014.159, 'sample_time_ms': 4610.165, 'load_time_ms': 0.123, 'load_throughput': 8128496.124, 'learn_time_ms': 1403.679, 'learn_throughput': 712.414, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 81000, 'num_env_steps_trained': 81000, 'num_agent_steps_sampled': 81000, 'num_agent_steps_trained': 81000}, 'done': False, 'episodes_total': 17, 'training_iteration': 81, 'trial_id': 'default', 'date': '2024-09-13_05-52-36', 'timestamp': 1726206756, 'time_this_iter_s': 5.643138885498047, 'time_total_s': 491.7716338634491, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659601c90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 491.7716338634491, 'iterations_since_restore': 81, 'perf': {'cpu_util_percent': 11.6, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.744956191948482, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.927757494790214, 'policy_loss': 0.01907519997940177, 'vf_loss': 9.90668714160011, 'vf_explained_var': -3.6898113432384674e-09, 'kl': 0.013300821029614392, 'entropy': 2.8929871774855114, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 17115.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 82000, 'num_env_steps_trained': 82000, 'num_agent_steps_sampled': 82000, 'num_agent_steps_trained': 82000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 570.450303476052, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15698263239929128, 'mean_inference_ms': 0.9487779708678725, 'mean_action_processing_ms': 0.13797993609132772, 'mean_env_wait_ms': 3.493696074269663, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 82000, 'num_agent_steps_trained': 82000, 'num_env_steps_sampled': 82000, 'num_env_steps_trained': 82000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.4938956235354, 'num_env_steps_trained_throughput_per_sec': 178.4938956235354, 'timesteps_total': 82000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 82000, 'timers': {'training_iteration_time_ms': 6023.388, 'sample_time_ms': 4620.297, 'load_time_ms': 0.123, 'load_throughput': 8128496.124, 'learn_time_ms': 1402.776, 'learn_throughput': 712.872, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 82000, 'num_env_steps_trained': 82000, 'num_agent_steps_sampled': 82000, 'num_agent_steps_trained': 82000}, 'done': False, 'episodes_total': 17, 'training_iteration': 82, 'trial_id': 'default', 'date': '2024-09-13_05-52-42', 'timestamp': 1726206762, 'time_this_iter_s': 5.602579593658447, 'time_total_s': 497.37421345710754, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab7b910>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 497.37421345710754, 'iterations_since_restore': 82, 'perf': {'cpu_util_percent': 12.025, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.14372885851633, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.718801784515382, 'policy_loss': -0.0692584335449196, 'vf_loss': 9.786789662497384, 'vf_explained_var': -3.178914388020833e-08, 'kl': 0.00847031010392446, 'entropy': 2.818284703436352, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 17325.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 83000, 'num_env_steps_trained': 83000, 'num_agent_steps_sampled': 83000, 'num_agent_steps_trained': 83000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 83000, 'num_agent_steps_trained': 83000, 'num_env_steps_sampled': 83000, 'num_env_steps_trained': 83000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.14115157672614, 'num_env_steps_trained_throughput_per_sec': 128.14115157672614, 'timesteps_total': 83000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 83000, 'timers': {'training_iteration_time_ms': 6237.01, 'sample_time_ms': 4835.238, 'load_time_ms': 0.124, 'load_throughput': 8089303.761, 'learn_time_ms': 1401.456, 'learn_throughput': 713.544, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 83000, 'num_env_steps_trained': 83000, 'num_agent_steps_sampled': 83000, 'num_agent_steps_trained': 83000}, 'done': False, 'episodes_total': 18, 'training_iteration': 83, 'trial_id': 'default', 'date': '2024-09-13_05-52-50', 'timestamp': 1726206770, 'time_this_iter_s': 7.804046154022217, 'time_total_s': 505.17825961112976, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab40c10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 505.17825961112976, 'iterations_since_restore': 83, 'perf': {'cpu_util_percent': 11.045454545454545, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.8012218498048327, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.866099207741874, 'policy_loss': -0.10730066989060669, 'vf_loss': 9.971751094999767, 'vf_explained_var': -2.1855036417643228e-08, 'kl': 0.010991867213964585, 'entropy': 2.7971517483393353, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 17535.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 84000, 'num_env_steps_trained': 84000, 'num_agent_steps_sampled': 84000, 'num_agent_steps_trained': 84000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 84000, 'num_agent_steps_trained': 84000, 'num_env_steps_sampled': 84000, 'num_env_steps_trained': 84000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.35467698849146, 'num_env_steps_trained_throughput_per_sec': 179.35467698849146, 'timesteps_total': 84000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 84000, 'timers': {'training_iteration_time_ms': 6011.553, 'sample_time_ms': 4612.305, 'load_time_ms': 0.123, 'load_throughput': 8101804.134, 'learn_time_ms': 1398.932, 'learn_throughput': 714.831, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 84000, 'num_env_steps_trained': 84000, 'num_agent_steps_sampled': 84000, 'num_agent_steps_trained': 84000}, 'done': False, 'episodes_total': 18, 'training_iteration': 84, 'trial_id': 'default', 'date': '2024-09-13_05-52-55', 'timestamp': 1726206775, 'time_this_iter_s': 5.575686931610107, 'time_total_s': 510.75394654273987, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea7fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 510.75394654273987, 'iterations_since_restore': 84, 'perf': {'cpu_util_percent': 11.8625, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.014350463662829, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.876234890165783, 'policy_loss': -0.0912320026684375, 'vf_loss': 9.96605442592076, 'vf_explained_var': -5.3928011939639136e-09, 'kl': 0.009416607359768663, 'entropy': 2.88609230858939, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 17745.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000, 'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.4916586078157, 'num_env_steps_trained_throughput_per_sec': 179.4916586078157, 'timesteps_total': 85000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 85000, 'timers': {'training_iteration_time_ms': 6007.894, 'sample_time_ms': 4612.091, 'load_time_ms': 0.122, 'load_throughput': 8174437.731, 'learn_time_ms': 1395.491, 'learn_throughput': 716.594, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000}, 'done': False, 'episodes_total': 18, 'training_iteration': 85, 'trial_id': 'default', 'date': '2024-09-13_05-53-01', 'timestamp': 1726206781, 'time_this_iter_s': 5.571429014205933, 'time_total_s': 516.3253755569458, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65960e450>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 516.3253755569458, 'iterations_since_restore': 85, 'perf': {'cpu_util_percent': 11.7625, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.1169890477543785, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.770270079658145, 'policy_loss': -0.08642019335003126, 'vf_loss': 9.854278346470425, 'vf_explained_var': 8.798780895414807e-09, 'kl': 0.0160796991665155, 'entropy': 2.772365068254017, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 17955.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 86000, 'num_env_steps_trained': 86000, 'num_agent_steps_sampled': 86000, 'num_agent_steps_trained': 86000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 86000, 'num_agent_steps_trained': 86000, 'num_env_steps_sampled': 86000, 'num_env_steps_trained': 86000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.0759733293926, 'num_env_steps_trained_throughput_per_sec': 180.0759733293926, 'timesteps_total': 86000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 86000, 'timers': {'training_iteration_time_ms': 6013.456, 'sample_time_ms': 4618.776, 'load_time_ms': 0.122, 'load_throughput': 8225738.38, 'learn_time_ms': 1394.368, 'learn_throughput': 717.171, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 86000, 'num_env_steps_trained': 86000, 'num_agent_steps_sampled': 86000, 'num_agent_steps_trained': 86000}, 'done': False, 'episodes_total': 18, 'training_iteration': 86, 'trial_id': 'default', 'date': '2024-09-13_05-53-06', 'timestamp': 1726206786, 'time_this_iter_s': 5.553358554840088, 'time_total_s': 521.8787341117859, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab3cdd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 521.8787341117859, 'iterations_since_restore': 86, 'perf': {'cpu_util_percent': 11.8375, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.038682216122037, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.717311030342465, 'policy_loss': -0.09954297077797708, 'vf_loss': 9.81487519854591, 'vf_explained_var': -4.825137910388765e-09, 'kl': 0.013192140524222937, 'entropy': 2.6930096001852126, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 18165.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 87000, 'num_env_steps_trained': 87000, 'num_agent_steps_sampled': 87000, 'num_agent_steps_trained': 87000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 623.3265983868636, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15707781007881508, 'mean_inference_ms': 0.9492639172995444, 'mean_action_processing_ms': 0.1380689256280315, 'mean_env_wait_ms': 3.4890708961786587, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 87000, 'num_agent_steps_trained': 87000, 'num_env_steps_sampled': 87000, 'num_env_steps_trained': 87000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.8115193983876, 'num_env_steps_trained_throughput_per_sec': 179.8115193983876, 'timesteps_total': 87000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 87000, 'timers': {'training_iteration_time_ms': 6014.74, 'sample_time_ms': 4619.291, 'load_time_ms': 0.122, 'load_throughput': 8206425.357, 'learn_time_ms': 1395.135, 'learn_throughput': 716.776, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 87000, 'num_env_steps_trained': 87000, 'num_agent_steps_sampled': 87000, 'num_agent_steps_trained': 87000}, 'done': False, 'episodes_total': 18, 'training_iteration': 87, 'trial_id': 'default', 'date': '2024-09-13_05-53-12', 'timestamp': 1726206792, 'time_this_iter_s': 5.561516046524048, 'time_total_s': 527.4402501583099, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c672410>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 527.4402501583099, 'iterations_since_restore': 87, 'perf': {'cpu_util_percent': 11.9625, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.241962822846004, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.82275422414144, 'policy_loss': -0.15547426151377813, 'vf_loss': 9.976289290473575, 'vf_explained_var': -9.65027582077753e-09, 'kl': 0.012927915517087132, 'entropy': 2.679696916398548, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 18375.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 88000, 'num_env_steps_trained': 88000, 'num_agent_steps_sampled': 88000, 'num_agent_steps_trained': 88000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 88000, 'num_agent_steps_trained': 88000, 'num_env_steps_sampled': 88000, 'num_env_steps_trained': 88000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 129.24079126730823, 'num_env_steps_trained_throughput_per_sec': 129.24079126730823, 'timesteps_total': 88000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 88000, 'timers': {'training_iteration_time_ms': 6235.677, 'sample_time_ms': 4842.319, 'load_time_ms': 0.122, 'load_throughput': 8208031.311, 'learn_time_ms': 1393.045, 'learn_throughput': 717.852, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 88000, 'num_env_steps_trained': 88000, 'num_agent_steps_sampled': 88000, 'num_agent_steps_trained': 88000}, 'done': False, 'episodes_total': 19, 'training_iteration': 88, 'trial_id': 'default', 'date': '2024-09-13_05-53-20', 'timestamp': 1726206800, 'time_this_iter_s': 7.737653493881226, 'time_total_s': 535.1779036521912, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab6c850>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 535.1779036521912, 'iterations_since_restore': 88, 'perf': {'cpu_util_percent': 11.445454545454544, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.102586132571811, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.795199693952288, 'policy_loss': -0.05786476987635805, 'vf_loss': 9.85121481305077, 'vf_explained_var': -7.09579104468936e-09, 'kl': 0.01233109791140866, 'entropy': 2.6895833900996617, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 18585.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 89000, 'num_env_steps_trained': 89000, 'num_agent_steps_sampled': 89000, 'num_agent_steps_trained': 89000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 89000, 'num_agent_steps_trained': 89000, 'num_env_steps_sampled': 89000, 'num_env_steps_trained': 89000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.44866437030046, 'num_env_steps_trained_throughput_per_sec': 181.44866437030046, 'timesteps_total': 89000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 89000, 'timers': {'training_iteration_time_ms': 6007.033, 'sample_time_ms': 4613.817, 'load_time_ms': 0.122, 'load_throughput': 8180815.292, 'learn_time_ms': 1392.903, 'learn_throughput': 717.925, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 89000, 'num_env_steps_trained': 89000, 'num_agent_steps_sampled': 89000, 'num_agent_steps_trained': 89000}, 'done': False, 'episodes_total': 19, 'training_iteration': 89, 'trial_id': 'default', 'date': '2024-09-13_05-53-25', 'timestamp': 1726206805, 'time_this_iter_s': 5.511342763900757, 'time_total_s': 540.6892464160919, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65960ef10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 540.6892464160919, 'iterations_since_restore': 89, 'perf': {'cpu_util_percent': 11.85, 'ram_util_percent': 12.55}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.9309451131593613, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.833138674781436, 'policy_loss': -0.043557511908667426, 'vf_loss': 9.87555685043335, 'vf_explained_var': -1.3056255522228423e-08, 'kl': 0.007595498437599803, 'entropy': 2.7741259029933385, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 18795.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000, 'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.74626421232122, 'num_env_steps_trained_throughput_per_sec': 180.74626421232122, 'timesteps_total': 90000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 90000, 'timers': {'training_iteration_time_ms': 6009.195, 'sample_time_ms': 4614.169, 'load_time_ms': 0.123, 'load_throughput': 8161712.395, 'learn_time_ms': 1394.711, 'learn_throughput': 716.995, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000}, 'done': False, 'episodes_total': 19, 'training_iteration': 90, 'trial_id': 'default', 'date': '2024-09-13_05-53-31', 'timestamp': 1726206811, 'time_this_iter_s': 5.532760858535767, 'time_total_s': 546.2220072746277, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658432d10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 546.2220072746277, 'iterations_since_restore': 90, 'perf': {'cpu_util_percent': 11.8, 'ram_util_percent': 12.525}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.563471964427403, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.832140777224586, 'policy_loss': 0.040320600019324394, 'vf_loss': 9.790932105836415, 'vf_explained_var': -2.333152861822219e-05, 'kl': 0.005920519761587395, 'entropy': 2.8171552499135335, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 19005.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 91000, 'num_env_steps_trained': 91000, 'num_agent_steps_sampled': 91000, 'num_agent_steps_trained': 91000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 91000, 'num_agent_steps_trained': 91000, 'num_env_steps_sampled': 91000, 'num_env_steps_trained': 91000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.90195677173702, 'num_env_steps_trained_throughput_per_sec': 176.90195677173702, 'timesteps_total': 91000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 91000, 'timers': {'training_iteration_time_ms': 6010.181, 'sample_time_ms': 4613.182, 'load_time_ms': 0.114, 'load_throughput': 8752721.202, 'learn_time_ms': 1396.691, 'learn_throughput': 715.978, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 91000, 'num_env_steps_trained': 91000, 'num_agent_steps_sampled': 91000, 'num_agent_steps_trained': 91000}, 'done': False, 'episodes_total': 19, 'training_iteration': 91, 'trial_id': 'default', 'date': '2024-09-13_05-53-37', 'timestamp': 1726206817, 'time_this_iter_s': 5.653032302856445, 'time_total_s': 551.8750395774841, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659557c90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 551.8750395774841, 'iterations_since_restore': 91, 'perf': {'cpu_util_percent': 11.525, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.460187031541552, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.880265944344657, 'policy_loss': -0.005957933293566817, 'vf_loss': 9.884335091000512, 'vf_explained_var': 1.7029898507254464e-09, 'kl': 0.012591468163199929, 'entropy': 2.7651654913311914, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 19215.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 92000, 'num_env_steps_trained': 92000, 'num_agent_steps_sampled': 92000, 'num_agent_steps_trained': 92000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 672.0796921703675, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15716107477037253, 'mean_inference_ms': 0.9497038120774626, 'mean_action_processing_ms': 0.13814788666001518, 'mean_env_wait_ms': 3.4847495073402137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 92000, 'num_agent_steps_trained': 92000, 'num_env_steps_sampled': 92000, 'num_env_steps_trained': 92000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.57779070885036, 'num_env_steps_trained_throughput_per_sec': 176.57779070885036, 'timesteps_total': 92000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 92000, 'timers': {'training_iteration_time_ms': 6016.261, 'sample_time_ms': 4617.288, 'load_time_ms': 0.114, 'load_throughput': 8780205.15, 'learn_time_ms': 1398.666, 'learn_throughput': 714.967, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 92000, 'num_env_steps_trained': 92000, 'num_agent_steps_sampled': 92000, 'num_agent_steps_trained': 92000}, 'done': False, 'episodes_total': 19, 'training_iteration': 92, 'trial_id': 'default', 'date': '2024-09-13_05-53-42', 'timestamp': 1726206822, 'time_this_iter_s': 5.66337251663208, 'time_total_s': 557.5384120941162, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659763c90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 557.5384120941162, 'iterations_since_restore': 92, 'perf': {'cpu_util_percent': 11.799999999999999, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.4146095551195597, 'cur_kl_coeff': 0.15, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.674686563582647, 'policy_loss': -0.17714722813772305, 'vf_loss': 9.848724283490862, 'vf_explained_var': 1.7597561790829613e-08, 'kl': 0.020730311842981748, 'entropy': 2.6257442599251157, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 19425.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 93000, 'num_env_steps_trained': 93000, 'num_agent_steps_sampled': 93000, 'num_agent_steps_trained': 93000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 93000, 'num_agent_steps_trained': 93000, 'num_env_steps_sampled': 93000, 'num_env_steps_trained': 93000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.74376008280997, 'num_env_steps_trained_throughput_per_sec': 127.74376008280997, 'timesteps_total': 93000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 93000, 'timers': {'training_iteration_time_ms': 6018.688, 'sample_time_ms': 4620.72, 'load_time_ms': 0.113, 'load_throughput': 8839418.335, 'learn_time_ms': 1397.661, 'learn_throughput': 715.481, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 93000, 'num_env_steps_trained': 93000, 'num_agent_steps_sampled': 93000, 'num_agent_steps_trained': 93000}, 'done': False, 'episodes_total': 20, 'training_iteration': 93, 'trial_id': 'default', 'date': '2024-09-13_05-53-50', 'timestamp': 1726206830, 'time_this_iter_s': 7.828324317932129, 'time_total_s': 565.3667364120483, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea7fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 565.3667364120483, 'iterations_since_restore': 93, 'perf': {'cpu_util_percent': 10.9, 'ram_util_percent': 12.545454545454545}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.5687271118164063, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.682436929430281, 'policy_loss': -0.15981299394652956, 'vf_loss': 9.83976445879255, 'vf_explained_var': -2.2706531343005954e-09, 'kl': 0.01104631482767661, 'entropy': 2.5373960812886556, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 19635.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 94000, 'num_env_steps_trained': 94000, 'num_agent_steps_sampled': 94000, 'num_agent_steps_trained': 94000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 94000, 'num_agent_steps_trained': 94000, 'num_env_steps_sampled': 94000, 'num_env_steps_trained': 94000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.9817032302461, 'num_env_steps_trained_throughput_per_sec': 180.9817032302461, 'timesteps_total': 94000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 94000, 'timers': {'training_iteration_time_ms': 6013.676, 'sample_time_ms': 4612.772, 'load_time_ms': 0.113, 'load_throughput': 8856216.216, 'learn_time_ms': 1400.597, 'learn_throughput': 713.981, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 94000, 'num_env_steps_trained': 94000, 'num_agent_steps_sampled': 94000, 'num_agent_steps_trained': 94000}, 'done': False, 'episodes_total': 20, 'training_iteration': 94, 'trial_id': 'default', 'date': '2024-09-13_05-53-56', 'timestamp': 1726206836, 'time_this_iter_s': 5.525564193725586, 'time_total_s': 570.8923006057739, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659755310>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 570.8923006057739, 'iterations_since_restore': 94, 'perf': {'cpu_util_percent': 11.55, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.323064453261239, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.632861818586077, 'policy_loss': -0.12623715382956324, 'vf_loss': 9.75626140322004, 'vf_explained_var': 5.960464477539063e-09, 'kl': 0.01261140802515521, 'entropy': 2.434111336299351, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 19845.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000, 'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.16069047882422, 'num_env_steps_trained_throughput_per_sec': 182.16069047882422, 'timesteps_total': 95000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 95000, 'timers': {'training_iteration_time_ms': 6005.513, 'sample_time_ms': 4605.353, 'load_time_ms': 0.113, 'load_throughput': 8826397.306, 'learn_time_ms': 1399.85, 'learn_throughput': 714.362, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000}, 'done': False, 'episodes_total': 20, 'training_iteration': 95, 'trial_id': 'default', 'date': '2024-09-13_05-54-01', 'timestamp': 1726206841, 'time_this_iter_s': 5.489799976348877, 'time_total_s': 576.3821005821228, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c671cd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 576.3821005821228, 'iterations_since_restore': 95, 'perf': {'cpu_util_percent': 11.9625, 'ram_util_percent': 12.5125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.288733236562638, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.705401720319475, 'policy_loss': -0.16451934576034546, 'vf_loss': 9.86535995120094, 'vf_explained_var': 4.257474626813616e-09, 'kl': 0.02027147304414999, 'entropy': 2.289635427792867, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 20055.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 96000, 'num_env_steps_trained': 96000, 'num_agent_steps_sampled': 96000, 'num_agent_steps_trained': 96000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 723.8293207291666, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1572372001442192, 'mean_inference_ms': 0.9501300679049656, 'mean_action_processing_ms': 0.13822357505061197, 'mean_env_wait_ms': 3.480723807894993, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 96000, 'num_agent_steps_trained': 96000, 'num_env_steps_sampled': 96000, 'num_env_steps_trained': 96000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.68251432466397, 'num_env_steps_trained_throughput_per_sec': 178.68251432466397, 'timesteps_total': 96000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 96000, 'timers': {'training_iteration_time_ms': 6009.843, 'sample_time_ms': 4613.957, 'load_time_ms': 0.113, 'load_throughput': 8841281.619, 'learn_time_ms': 1395.579, 'learn_throughput': 716.549, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 96000, 'num_env_steps_trained': 96000, 'num_agent_steps_sampled': 96000, 'num_agent_steps_trained': 96000}, 'done': False, 'episodes_total': 20, 'training_iteration': 96, 'trial_id': 'default', 'date': '2024-09-13_05-54-07', 'timestamp': 1726206847, 'time_this_iter_s': 5.596664905548096, 'time_total_s': 581.9787654876709, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659601b90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 581.9787654876709, 'iterations_since_restore': 96, 'perf': {'cpu_util_percent': 11.575, 'ram_util_percent': 12.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.962932120618366, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.695237132481166, 'policy_loss': 0.03994307471882729, 'vf_loss': 9.65263363974435, 'vf_explained_var': 1.7029898507254464e-09, 'kl': 0.007882752685968544, 'entropy': 2.2319379988170804, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 20265.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 97000, 'num_env_steps_trained': 97000, 'num_agent_steps_sampled': 97000, 'num_agent_steps_trained': 97000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 97000, 'num_agent_steps_trained': 97000, 'num_env_steps_sampled': 97000, 'num_env_steps_trained': 97000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 130.475186111976, 'num_env_steps_trained_throughput_per_sec': 130.475186111976, 'timesteps_total': 97000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 97000, 'timers': {'training_iteration_time_ms': 6220.135, 'sample_time_ms': 4822.149, 'load_time_ms': 0.113, 'load_throughput': 8854346.633, 'learn_time_ms': 1397.678, 'learn_throughput': 715.472, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 97000, 'num_env_steps_trained': 97000, 'num_agent_steps_sampled': 97000, 'num_agent_steps_trained': 97000}, 'done': False, 'episodes_total': 21, 'training_iteration': 97, 'trial_id': 'default', 'date': '2024-09-13_05-54-14', 'timestamp': 1726206854, 'time_this_iter_s': 7.664452314376831, 'time_total_s': 589.6432178020477, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab83f90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 589.6432178020477, 'iterations_since_restore': 97, 'perf': {'cpu_util_percent': 11.127272727272727, 'ram_util_percent': 12.509090909090908}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.700793106215341, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.839140923817952, 'policy_loss': -0.0009734140975134713, 'vf_loss': 9.837204265594483, 'vf_explained_var': 1.0501770746140254e-08, 'kl': 0.008622570124238631, 'entropy': 2.33482909429641, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 20475.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 98000, 'num_env_steps_trained': 98000, 'num_agent_steps_sampled': 98000, 'num_agent_steps_trained': 98000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 98000, 'num_agent_steps_trained': 98000, 'num_env_steps_sampled': 98000, 'num_env_steps_trained': 98000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.40823223138054, 'num_env_steps_trained_throughput_per_sec': 181.40823223138054, 'timesteps_total': 98000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 98000, 'timers': {'training_iteration_time_ms': 5997.628, 'sample_time_ms': 4593.054, 'load_time_ms': 0.117, 'load_throughput': 8552822.186, 'learn_time_ms': 1404.257, 'learn_throughput': 712.12, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 98000, 'num_env_steps_trained': 98000, 'num_agent_steps_sampled': 98000, 'num_agent_steps_trained': 98000}, 'done': False, 'episodes_total': 21, 'training_iteration': 98, 'trial_id': 'default', 'date': '2024-09-13_05-54-20', 'timestamp': 1726206860, 'time_this_iter_s': 5.512599468231201, 'time_total_s': 595.1558172702789, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c671e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 595.1558172702789, 'iterations_since_restore': 98, 'perf': {'cpu_util_percent': 11.557142857142855, 'ram_util_percent': 12.585714285714285}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.193941345668974, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.849764151800246, 'policy_loss': 0.0024382320188340687, 'vf_loss': 9.844253476460775, 'vf_explained_var': -8.514949253627232e-09, 'kl': 0.009103768509313798, 'entropy': 2.3301290864036197, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 20685.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 99000, 'num_env_steps_trained': 99000, 'num_agent_steps_sampled': 99000, 'num_agent_steps_trained': 99000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 99000, 'num_agent_steps_trained': 99000, 'num_env_steps_sampled': 99000, 'num_env_steps_trained': 99000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.46443291145988, 'num_env_steps_trained_throughput_per_sec': 179.46443291145988, 'timesteps_total': 99000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 99000, 'timers': {'training_iteration_time_ms': 6003.721, 'sample_time_ms': 4598.016, 'load_time_ms': 0.121, 'load_throughput': 8240282.908, 'learn_time_ms': 1405.379, 'learn_throughput': 711.552, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 99000, 'num_env_steps_trained': 99000, 'num_agent_steps_sampled': 99000, 'num_agent_steps_trained': 99000}, 'done': False, 'episodes_total': 21, 'training_iteration': 99, 'trial_id': 'default', 'date': '2024-09-13_05-54-25', 'timestamp': 1726206865, 'time_this_iter_s': 5.572306156158447, 'time_total_s': 600.7281234264374, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659624f10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 600.7281234264374, 'iterations_since_restore': 99, 'perf': {'cpu_util_percent': 12.037500000000001, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.281706341107687, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.66458117167155, 'policy_loss': 0.01598035515773864, 'vf_loss': 9.645913841610863, 'vf_explained_var': -2.0152046566917784e-08, 'kl': 0.007961220813394036, 'entropy': 2.29222989877065, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 20895.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.69752633796517, 'num_env_steps_trained_throughput_per_sec': 180.69752633796517, 'timesteps_total': 100000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 100000, 'timers': {'training_iteration_time_ms': 6003.871, 'sample_time_ms': 4595.295, 'load_time_ms': 0.121, 'load_throughput': 8272788.955, 'learn_time_ms': 1408.25, 'learn_throughput': 710.101, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'done': False, 'episodes_total': 21, 'training_iteration': 100, 'trial_id': 'default', 'date': '2024-09-13_05-54-31', 'timestamp': 1726206871, 'time_this_iter_s': 5.5342607498168945, 'time_total_s': 606.2623841762543, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65960c890>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 606.2623841762543, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 11.85, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.191505679630098, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.724138323465983, 'policy_loss': -0.08226991693178813, 'vf_loss': 9.803371819995698, 'vf_explained_var': -1.2488592238653274e-08, 'kl': 0.008996780137697903, 'entropy': 2.3568551279249643, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 21105.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 101000, 'num_env_steps_trained': 101000, 'num_agent_steps_sampled': 101000, 'num_agent_steps_trained': 101000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 767.4459122313158, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15729996304133145, 'mean_inference_ms': 0.9504631005392028, 'mean_action_processing_ms': 0.13828641612513434, 'mean_env_wait_ms': 3.477166250082968, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 101000, 'num_agent_steps_trained': 101000, 'num_env_steps_sampled': 101000, 'num_env_steps_trained': 101000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.9586428562255, 'num_env_steps_trained_throughput_per_sec': 178.9586428562255, 'timesteps_total': 101000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 101000, 'timers': {'training_iteration_time_ms': 5997.374, 'sample_time_ms': 4586.545, 'load_time_ms': 0.126, 'load_throughput': 7936242.195, 'learn_time_ms': 1410.502, 'learn_throughput': 708.967, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 101000, 'num_env_steps_trained': 101000, 'num_agent_steps_sampled': 101000, 'num_agent_steps_trained': 101000}, 'done': False, 'episodes_total': 21, 'training_iteration': 101, 'trial_id': 'default', 'date': '2024-09-13_05-54-37', 'timestamp': 1726206877, 'time_this_iter_s': 5.588029623031616, 'time_total_s': 611.8504137992859, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab41a10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 611.8504137992859, 'iterations_since_restore': 101, 'perf': {'cpu_util_percent': 11.8125, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.9242746074994406, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.484785093579973, 'policy_loss': -0.2013177859530385, 'vf_loss': 9.683351814179193, 'vf_explained_var': -1.0501770746140254e-08, 'kl': 0.008151227332806836, 'entropy': 2.308127230689639, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 21315.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 102000, 'num_env_steps_trained': 102000, 'num_agent_steps_sampled': 102000, 'num_agent_steps_trained': 102000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 102000, 'num_agent_steps_trained': 102000, 'num_env_steps_sampled': 102000, 'num_env_steps_trained': 102000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.4068319361811, 'num_env_steps_trained_throughput_per_sec': 128.4068319361811, 'timesteps_total': 102000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 102000, 'timers': {'training_iteration_time_ms': 6209.826, 'sample_time_ms': 4797.969, 'load_time_ms': 0.127, 'load_throughput': 7864811.551, 'learn_time_ms': 1411.527, 'learn_throughput': 708.453, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 102000, 'num_env_steps_trained': 102000, 'num_agent_steps_sampled': 102000, 'num_agent_steps_trained': 102000}, 'done': False, 'episodes_total': 22, 'training_iteration': 102, 'trial_id': 'default', 'date': '2024-09-13_05-54-44', 'timestamp': 1726206884, 'time_this_iter_s': 7.787907123565674, 'time_total_s': 619.6383209228516, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab79810>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 619.6383209228516, 'iterations_since_restore': 102, 'perf': {'cpu_util_percent': 11.281818181818181, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.83355192002796, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.695349688757034, 'policy_loss': -0.11404050851152056, 'vf_loss': 9.805568313598632, 'vf_explained_var': 7.379622686476935e-09, 'kl': 0.011324101656126625, 'entropy': 2.262116947628203, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 21525.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 103000, 'num_env_steps_trained': 103000, 'num_agent_steps_sampled': 103000, 'num_agent_steps_trained': 103000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 103000, 'num_agent_steps_trained': 103000, 'num_env_steps_sampled': 103000, 'num_env_steps_trained': 103000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.15765781966496, 'num_env_steps_trained_throughput_per_sec': 179.15765781966496, 'timesteps_total': 103000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 103000, 'timers': {'training_iteration_time_ms': 5985.177, 'sample_time_ms': 4570.173, 'load_time_ms': 0.126, 'load_throughput': 7918263.168, 'learn_time_ms': 1414.675, 'learn_throughput': 706.876, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 103000, 'num_env_steps_trained': 103000, 'num_agent_steps_sampled': 103000, 'num_agent_steps_trained': 103000}, 'done': False, 'episodes_total': 22, 'training_iteration': 103, 'trial_id': 'default', 'date': '2024-09-13_05-54-50', 'timestamp': 1726206890, 'time_this_iter_s': 5.581824541091919, 'time_total_s': 625.2201454639435, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597f7790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 625.2201454639435, 'iterations_since_restore': 103, 'perf': {'cpu_util_percent': 11.850000000000001, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.5602813164393106, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.732136535644532, 'policy_loss': -0.12436680861172222, 'vf_loss': 9.851191143762497, 'vf_explained_var': -4.3647629874093195e-05, 'kl': 0.015739754292527847, 'entropy': 2.184823924019223, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 21735.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 104000, 'num_env_steps_trained': 104000, 'num_agent_steps_sampled': 104000, 'num_agent_steps_trained': 104000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 104000, 'num_agent_steps_trained': 104000, 'num_env_steps_sampled': 104000, 'num_env_steps_trained': 104000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.67964654316697, 'num_env_steps_trained_throughput_per_sec': 180.67964654316697, 'timesteps_total': 104000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 104000, 'timers': {'training_iteration_time_ms': 5986.101, 'sample_time_ms': 4567.829, 'load_time_ms': 0.129, 'load_throughput': 7778753.709, 'learn_time_ms': 1417.94, 'learn_throughput': 705.248, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 104000, 'num_env_steps_trained': 104000, 'num_agent_steps_sampled': 104000, 'num_agent_steps_trained': 104000}, 'done': False, 'episodes_total': 22, 'training_iteration': 104, 'trial_id': 'default', 'date': '2024-09-13_05-54-56', 'timestamp': 1726206896, 'time_this_iter_s': 5.534806251525879, 'time_total_s': 630.7549517154694, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659505290>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 630.7549517154694, 'iterations_since_restore': 104, 'perf': {'cpu_util_percent': 11.774999999999999, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.8394252453531537, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.789976660410563, 'policy_loss': -0.08442307398432777, 'vf_loss': 9.87259654090518, 'vf_explained_var': -2.1003541492280507e-08, 'kl': 0.0053427790784986605, 'entropy': 2.222517518770127, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 21945.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 804.9728447058474, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15736849720913657, 'mean_inference_ms': 0.9507415159687571, 'mean_action_processing_ms': 0.13834088921087545, 'mean_env_wait_ms': 3.4737341070736374, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000, 'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.8898290315941, 'num_env_steps_trained_throughput_per_sec': 177.8898290315941, 'timesteps_total': 105000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 105000, 'timers': {'training_iteration_time_ms': 5999.281, 'sample_time_ms': 4576.009, 'load_time_ms': 0.13, 'load_throughput': 7680468.779, 'learn_time_ms': 1422.938, 'learn_throughput': 702.771, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000}, 'done': False, 'episodes_total': 22, 'training_iteration': 105, 'trial_id': 'default', 'date': '2024-09-13_05-55-01', 'timestamp': 1726206901, 'time_this_iter_s': 5.621614694595337, 'time_total_s': 636.3765664100647, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658486690>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 636.3765664100647, 'iterations_since_restore': 105, 'perf': {'cpu_util_percent': 12.100000000000001, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.8006447425910403, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.77311390922183, 'policy_loss': -0.06090745528539022, 'vf_loss': 9.832210445404053, 'vf_explained_var': -8.514949253627232e-10, 'kl': 0.005365558524066622, 'entropy': 2.175824226651873, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 22155.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 106000, 'num_env_steps_trained': 106000, 'num_agent_steps_sampled': 106000, 'num_agent_steps_trained': 106000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 106000, 'num_agent_steps_trained': 106000, 'num_env_steps_sampled': 106000, 'num_env_steps_trained': 106000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 129.50229059485997, 'num_env_steps_trained_throughput_per_sec': 129.50229059485997, 'timesteps_total': 106000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 106000, 'timers': {'training_iteration_time_ms': 6211.816, 'sample_time_ms': 4790.488, 'load_time_ms': 0.13, 'load_throughput': 7697383.006, 'learn_time_ms': 1420.992, 'learn_throughput': 703.734, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 106000, 'num_env_steps_trained': 106000, 'num_agent_steps_sampled': 106000, 'num_agent_steps_trained': 106000}, 'done': False, 'episodes_total': 23, 'training_iteration': 106, 'trial_id': 'default', 'date': '2024-09-13_05-55-09', 'timestamp': 1726206909, 'time_this_iter_s': 7.7220330238342285, 'time_total_s': 644.0985994338989, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65959ae10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 644.0985994338989, 'iterations_since_restore': 106, 'perf': {'cpu_util_percent': 11.081818181818184, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.7682712543578374, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.849215752737862, 'policy_loss': -0.11235748685541608, 'vf_loss': 9.959435708182198, 'vf_explained_var': -1.4475413731166295e-08, 'kl': 0.006333445199180417, 'entropy': 2.1290562062036424, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 22365.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 107000, 'num_env_steps_trained': 107000, 'num_agent_steps_sampled': 107000, 'num_agent_steps_trained': 107000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 107000, 'num_agent_steps_trained': 107000, 'num_env_steps_sampled': 107000, 'num_env_steps_trained': 107000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.24162918028534, 'num_env_steps_trained_throughput_per_sec': 180.24162918028534, 'timesteps_total': 107000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 107000, 'timers': {'training_iteration_time_ms': 6000.197, 'sample_time_ms': 4575.319, 'load_time_ms': 0.138, 'load_throughput': 7229065.839, 'learn_time_ms': 1424.53, 'learn_throughput': 701.986, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 107000, 'num_env_steps_trained': 107000, 'num_agent_steps_sampled': 107000, 'num_agent_steps_trained': 107000}, 'done': False, 'episodes_total': 23, 'training_iteration': 107, 'trial_id': 'default', 'date': '2024-09-13_05-55-14', 'timestamp': 1726206914, 'time_this_iter_s': 5.548273801803589, 'time_total_s': 649.6468732357025, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659624990>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 649.6468732357025, 'iterations_since_restore': 107, 'perf': {'cpu_util_percent': 11.7375, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.866437827405475, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.877937957218714, 'policy_loss': -0.10700513273477555, 'vf_loss': 9.983241131192162, 'vf_explained_var': 1.986821492513021e-09, 'kl': 0.005042841383796586, 'entropy': 2.2059098039354597, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 22575.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 108000, 'num_env_steps_trained': 108000, 'num_agent_steps_sampled': 108000, 'num_agent_steps_trained': 108000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 108000, 'num_agent_steps_trained': 108000, 'num_env_steps_sampled': 108000, 'num_env_steps_trained': 108000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.65513781367432, 'num_env_steps_trained_throughput_per_sec': 178.65513781367432, 'timesteps_total': 108000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 108000, 'timers': {'training_iteration_time_ms': 6008.692, 'sample_time_ms': 4582.215, 'load_time_ms': 0.135, 'load_throughput': 7392146.634, 'learn_time_ms': 1426.134, 'learn_throughput': 701.196, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 108000, 'num_env_steps_trained': 108000, 'num_agent_steps_sampled': 108000, 'num_agent_steps_trained': 108000}, 'done': False, 'episodes_total': 23, 'training_iteration': 108, 'trial_id': 'default', 'date': '2024-09-13_05-55-20', 'timestamp': 1726206920, 'time_this_iter_s': 5.597534894943237, 'time_total_s': 655.2444081306458, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659505ad0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 655.2444081306458, 'iterations_since_restore': 108, 'perf': {'cpu_util_percent': 12.075, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.00582166654723, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.593374202364966, 'policy_loss': -0.10533944013572874, 'vf_loss': 9.695742112114315, 'vf_explained_var': 0.001992917912346976, 'kl': 0.008804617788215788, 'entropy': 2.218943471000308, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 22785.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 109000, 'num_env_steps_trained': 109000, 'num_agent_steps_sampled': 109000, 'num_agent_steps_trained': 109000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 109000, 'num_agent_steps_trained': 109000, 'num_env_steps_sampled': 109000, 'num_env_steps_trained': 109000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.62704609223297, 'num_env_steps_trained_throughput_per_sec': 176.62704609223297, 'timesteps_total': 109000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 109000, 'timers': {'training_iteration_time_ms': 6017.644, 'sample_time_ms': 4587.042, 'load_time_ms': 0.135, 'load_throughput': 7390844.053, 'learn_time_ms': 1430.262, 'learn_throughput': 699.173, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 109000, 'num_env_steps_trained': 109000, 'num_agent_steps_sampled': 109000, 'num_agent_steps_trained': 109000}, 'done': False, 'episodes_total': 23, 'training_iteration': 109, 'trial_id': 'default', 'date': '2024-09-13_05-55-26', 'timestamp': 1726206926, 'time_this_iter_s': 5.661798477172852, 'time_total_s': 660.9062066078186, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c670e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 660.9062066078186, 'iterations_since_restore': 109, 'perf': {'cpu_util_percent': 12.0625, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.215636840888432, 'cur_kl_coeff': 0.3375, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.852036081041609, 'policy_loss': -0.11764907297633943, 'vf_loss': 9.96806300935291, 'vf_explained_var': -1.0785602387927827e-08, 'kl': 0.004806301299201382, 'entropy': 2.256619434129624, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 22995.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 841.8286019540682, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1574354659449806, 'mean_inference_ms': 0.9510034212078516, 'mean_action_processing_ms': 0.13839184997881435, 'mean_env_wait_ms': 3.4706505407740447, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000, 'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 173.00818346942887, 'num_env_steps_trained_throughput_per_sec': 173.00818346942887, 'timesteps_total': 110000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 110000, 'timers': {'training_iteration_time_ms': 6042.24, 'sample_time_ms': 4611.129, 'load_time_ms': 0.135, 'load_throughput': 7390844.053, 'learn_time_ms': 1430.772, 'learn_throughput': 698.923, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000}, 'done': False, 'episodes_total': 23, 'training_iteration': 110, 'trial_id': 'default', 'date': '2024-09-13_05-55-32', 'timestamp': 1726206932, 'time_this_iter_s': 5.780222654342651, 'time_total_s': 666.6864292621613, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65959f750>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 666.6864292621613, 'iterations_since_restore': 110, 'perf': {'cpu_util_percent': 12.177777777777777, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.8272077844256445, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.720358644212995, 'policy_loss': -0.06317766171525277, 'vf_loss': 9.781388923100062, 'vf_explained_var': -2.071970985049293e-08, 'kl': 0.012725293937962538, 'entropy': 2.2053725197201683, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 23205.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 111000, 'num_env_steps_trained': 111000, 'num_agent_steps_sampled': 111000, 'num_agent_steps_trained': 111000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 111000, 'num_agent_steps_trained': 111000, 'num_env_steps_sampled': 111000, 'num_env_steps_trained': 111000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.0347281696769, 'num_env_steps_trained_throughput_per_sec': 128.0347281696769, 'timesteps_total': 111000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 111000, 'timers': {'training_iteration_time_ms': 6264.49, 'sample_time_ms': 4838.097, 'load_time_ms': 0.13, 'load_throughput': 7684690.363, 'learn_time_ms': 1426.061, 'learn_throughput': 701.232, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 111000, 'num_env_steps_trained': 111000, 'num_agent_steps_sampled': 111000, 'num_agent_steps_trained': 111000}, 'done': False, 'episodes_total': 24, 'training_iteration': 111, 'trial_id': 'default', 'date': '2024-09-13_05-55-39', 'timestamp': 1726206939, 'time_this_iter_s': 7.810554504394531, 'time_total_s': 674.4969837665558, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65848bed0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 674.4969837665558, 'iterations_since_restore': 111, 'perf': {'cpu_util_percent': 10.990909090909092, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.513240162247703, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.862606634412494, 'policy_loss': 0.01950832832427252, 'vf_loss': 9.84101003919329, 'vf_explained_var': -1.419158208937872e-08, 'kl': 0.012374932222883285, 'entropy': 2.1701279606137955, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 23415.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 112000, 'num_env_steps_trained': 112000, 'num_agent_steps_sampled': 112000, 'num_agent_steps_trained': 112000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 112000, 'num_agent_steps_trained': 112000, 'num_env_steps_sampled': 112000, 'num_env_steps_trained': 112000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.80181647393817, 'num_env_steps_trained_throughput_per_sec': 180.80181647393817, 'timesteps_total': 112000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 112000, 'timers': {'training_iteration_time_ms': 6038.807, 'sample_time_ms': 4611.776, 'load_time_ms': 0.129, 'load_throughput': 7737140.749, 'learn_time_ms': 1426.702, 'learn_throughput': 700.917, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 112000, 'num_env_steps_trained': 112000, 'num_agent_steps_sampled': 112000, 'num_agent_steps_trained': 112000}, 'done': False, 'episodes_total': 24, 'training_iteration': 112, 'trial_id': 'default', 'date': '2024-09-13_05-55-45', 'timestamp': 1726206945, 'time_this_iter_s': 5.531071186065674, 'time_total_s': 680.0280549526215, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658433c50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 680.0280549526215, 'iterations_since_restore': 112, 'perf': {'cpu_util_percent': 12.037500000000001, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.320170311133067, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.88220896493821, 'policy_loss': 0.02372700667807034, 'vf_loss': 9.856375626155309, 'vf_explained_var': -1.3056255522228423e-08, 'kl': 0.012482234138726546, 'entropy': 2.115984396707444, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 23625.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 113000, 'num_env_steps_trained': 113000, 'num_agent_steps_sampled': 113000, 'num_agent_steps_trained': 113000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 113000, 'num_agent_steps_trained': 113000, 'num_env_steps_sampled': 113000, 'num_env_steps_trained': 113000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.16784769001993, 'num_env_steps_trained_throughput_per_sec': 178.16784769001993, 'timesteps_total': 113000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 113000, 'timers': {'training_iteration_time_ms': 6041.908, 'sample_time_ms': 4612.39, 'load_time_ms': 0.13, 'load_throughput': 7683282.653, 'learn_time_ms': 1429.188, 'learn_throughput': 699.698, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 113000, 'num_env_steps_trained': 113000, 'num_agent_steps_sampled': 113000, 'num_agent_steps_trained': 113000}, 'done': False, 'episodes_total': 24, 'training_iteration': 113, 'trial_id': 'default', 'date': '2024-09-13_05-55-51', 'timestamp': 1726206951, 'time_this_iter_s': 5.6128456592559814, 'time_total_s': 685.6409006118774, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658430cd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 685.6409006118774, 'iterations_since_restore': 113, 'perf': {'cpu_util_percent': 11.725000000000001, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.3431545933087667, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.705550652458554, 'policy_loss': 0.07234808504581451, 'vf_loss': 9.631507964361282, 'vf_explained_var': -4.541306268601191e-09, 'kl': 0.010042516967015776, 'entropy': 2.1710292793455577, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 23835.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 114000, 'num_env_steps_trained': 114000, 'num_agent_steps_sampled': 114000, 'num_agent_steps_trained': 114000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 114000, 'num_agent_steps_trained': 114000, 'num_env_steps_sampled': 114000, 'num_env_steps_trained': 114000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.60065819303063, 'num_env_steps_trained_throughput_per_sec': 180.60065819303063, 'timesteps_total': 114000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 114000, 'timers': {'training_iteration_time_ms': 6042.15, 'sample_time_ms': 4609.467, 'load_time_ms': 0.134, 'load_throughput': 7465831.257, 'learn_time_ms': 1432.347, 'learn_throughput': 698.155, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 114000, 'num_env_steps_trained': 114000, 'num_agent_steps_sampled': 114000, 'num_agent_steps_trained': 114000}, 'done': False, 'episodes_total': 24, 'training_iteration': 114, 'trial_id': 'default', 'date': '2024-09-13_05-55-56', 'timestamp': 1726206956, 'time_this_iter_s': 5.5372474193573, 'time_total_s': 691.1781480312347, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65cf95dd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 691.1781480312347, 'iterations_since_restore': 114, 'perf': {'cpu_util_percent': 11.962499999999999, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.6036798602058773, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.883455231076194, 'policy_loss': 0.020669846130268916, 'vf_loss': 9.859602996281215, 'vf_explained_var': 6.244296119326637e-09, 'kl': 0.018859015715341817, 'entropy': 2.042958591097877, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 24045.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000}, 'sampler_results': {'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1852.563946723092, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 875.9853562364365, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15751361643331832, 'mean_inference_ms': 0.9512921699181893, 'mean_action_processing_ms': 0.1384378774147534, 'mean_env_wait_ms': 3.46772112906091, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000, 'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.73585877804786, 'num_env_steps_trained_throughput_per_sec': 180.73585877804786, 'timesteps_total': 115000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 115000, 'timers': {'training_iteration_time_ms': 6033.298, 'sample_time_ms': 4599.028, 'load_time_ms': 0.132, 'load_throughput': 7549143.269, 'learn_time_ms': 1433.936, 'learn_throughput': 697.381, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000}, 'done': False, 'episodes_total': 24, 'training_iteration': 115, 'trial_id': 'default', 'date': '2024-09-13_05-56-02', 'timestamp': 1726206962, 'time_this_iter_s': 5.533086061477661, 'time_total_s': 696.7112340927124, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597f5010>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 696.7112340927124, 'iterations_since_restore': 115, 'perf': {'cpu_util_percent': 12.0, 'ram_util_percent': 12.6}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.844981137911479, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.576701650165376, 'policy_loss': -0.20796084542359625, 'vf_loss': 9.782510457720075, 'vf_explained_var': 3.1221480596633185e-09, 'kl': 0.012752383988256389, 'entropy': 1.9538045128186543, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 24255.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 116000, 'num_env_steps_trained': 116000, 'num_agent_steps_sampled': 116000, 'num_agent_steps_trained': 116000}, 'sampler_results': {'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 116000, 'num_agent_steps_trained': 116000, 'num_env_steps_sampled': 116000, 'num_env_steps_trained': 116000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.39008033649439, 'num_env_steps_trained_throughput_per_sec': 127.39008033649439, 'timesteps_total': 116000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 116000, 'timers': {'training_iteration_time_ms': 6046.1, 'sample_time_ms': 4600.228, 'load_time_ms': 0.133, 'load_throughput': 7542355.691, 'learn_time_ms': 1445.539, 'learn_throughput': 691.783, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 116000, 'num_env_steps_trained': 116000, 'num_agent_steps_sampled': 116000, 'num_agent_steps_trained': 116000}, 'done': False, 'episodes_total': 25, 'training_iteration': 116, 'trial_id': 'default', 'date': '2024-09-13_05-56-09', 'timestamp': 1726206969, 'time_this_iter_s': 7.850074052810669, 'time_total_s': 704.5613081455231, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658486c10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 704.5613081455231, 'iterations_since_restore': 116, 'perf': {'cpu_util_percent': 11.272727272727272, 'ram_util_percent': 12.627272727272725}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.6781464849199565, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.662337571098691, 'policy_loss': -0.17895652272161983, 'vf_loss': 9.838744177137102, 'vf_explained_var': 3.6898113432384674e-09, 'kl': 0.015110693002706368, 'entropy': 1.826238397189549, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 24465.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 117000, 'num_env_steps_trained': 117000, 'num_agent_steps_sampled': 117000, 'num_agent_steps_trained': 117000}, 'sampler_results': {'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 117000, 'num_agent_steps_trained': 117000, 'num_env_steps_sampled': 117000, 'num_env_steps_trained': 117000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.9139678217087, 'num_env_steps_trained_throughput_per_sec': 177.9139678217087, 'timesteps_total': 117000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 117000, 'timers': {'training_iteration_time_ms': 6053.358, 'sample_time_ms': 4605.852, 'load_time_ms': 0.124, 'load_throughput': 8056673.07, 'learn_time_ms': 1447.187, 'learn_throughput': 690.996, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 117000, 'num_env_steps_trained': 117000, 'num_agent_steps_sampled': 117000, 'num_agent_steps_trained': 117000}, 'done': False, 'episodes_total': 25, 'training_iteration': 117, 'trial_id': 'default', 'date': '2024-09-13_05-56-15', 'timestamp': 1726206975, 'time_this_iter_s': 5.620847463607788, 'time_total_s': 710.1821556091309, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab825d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 710.1821556091309, 'iterations_since_restore': 117, 'perf': {'cpu_util_percent': 11.912500000000001, 'ram_util_percent': 12.6125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.5146561247961863, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.693750431424096, 'policy_loss': -0.15984422599098513, 'vf_loss': 9.851251502264114, 'vf_explained_var': 6.8119594029017855e-09, 'kl': 0.01388515704865789, 'entropy': 1.7714950851031712, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 24675.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 118000, 'num_env_steps_trained': 118000, 'num_agent_steps_sampled': 118000, 'num_agent_steps_trained': 118000}, 'sampler_results': {'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 118000, 'num_agent_steps_trained': 118000, 'num_env_steps_sampled': 118000, 'num_env_steps_trained': 118000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.21683145314574, 'num_env_steps_trained_throughput_per_sec': 180.21683145314574, 'timesteps_total': 118000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 118000, 'timers': {'training_iteration_time_ms': 6048.508, 'sample_time_ms': 4600.863, 'load_time_ms': 0.124, 'load_throughput': 8079953.766, 'learn_time_ms': 1447.326, 'learn_throughput': 690.93, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 118000, 'num_env_steps_trained': 118000, 'num_agent_steps_sampled': 118000, 'num_agent_steps_trained': 118000}, 'done': False, 'episodes_total': 25, 'training_iteration': 118, 'trial_id': 'default', 'date': '2024-09-13_05-56-21', 'timestamp': 1726206981, 'time_this_iter_s': 5.549025058746338, 'time_total_s': 715.7311806678772, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658487450>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 715.7311806678772, 'iterations_since_restore': 118, 'perf': {'cpu_util_percent': 11.75, 'ram_util_percent': 12.6625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.109936035247076, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.726169304620653, 'policy_loss': -0.16397822208347776, 'vf_loss': 9.888816306704566, 'vf_explained_var': -6.244296119326637e-09, 'kl': 0.007888418322614771, 'entropy': 1.8057841499646505, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 24885.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 119000, 'num_env_steps_trained': 119000, 'num_agent_steps_sampled': 119000, 'num_agent_steps_trained': 119000}, 'sampler_results': {'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 1909.2917532335048, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 917.3176121163192, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15759192381050569, 'mean_inference_ms': 0.9515362135513117, 'mean_action_processing_ms': 0.13847907341460844, 'mean_env_wait_ms': 3.4648621719581736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 119000, 'num_agent_steps_trained': 119000, 'num_env_steps_sampled': 119000, 'num_env_steps_trained': 119000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 184.78358845923773, 'num_env_steps_trained_throughput_per_sec': 184.78358845923773, 'timesteps_total': 119000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 119000, 'timers': {'training_iteration_time_ms': 6023.517, 'sample_time_ms': 4574.287, 'load_time_ms': 0.119, 'load_throughput': 8412162.054, 'learn_time_ms': 1448.916, 'learn_throughput': 690.171, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 119000, 'num_env_steps_trained': 119000, 'num_agent_steps_sampled': 119000, 'num_agent_steps_trained': 119000}, 'done': False, 'episodes_total': 25, 'training_iteration': 119, 'trial_id': 'default', 'date': '2024-09-13_05-56-26', 'timestamp': 1726206986, 'time_this_iter_s': 5.411914110183716, 'time_total_s': 721.1430947780609, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659762690>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 721.1430947780609, 'iterations_since_restore': 119, 'perf': {'cpu_util_percent': 12.037500000000001, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.431174648375738, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.54294331414359, 'policy_loss': -0.15474891384087858, 'vf_loss': 9.695193258921305, 'vf_explained_var': -2.639634268624442e-08, 'kl': 0.014808707445107367, 'entropy': 1.7248041800090246, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 25095.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000}, 'sampler_results': {'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000, 'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.3799169897855, 'num_env_steps_trained_throughput_per_sec': 127.3799169897855, 'timesteps_total': 120000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 120000, 'timers': {'training_iteration_time_ms': 6230.562, 'sample_time_ms': 4787.479, 'load_time_ms': 0.119, 'load_throughput': 8400368.516, 'learn_time_ms': 1442.769, 'learn_throughput': 693.112, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000}, 'done': False, 'episodes_total': 26, 'training_iteration': 120, 'trial_id': 'default', 'date': '2024-09-13_05-56-34', 'timestamp': 1726206994, 'time_this_iter_s': 7.85069465637207, 'time_total_s': 728.993789434433, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6595229d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 728.993789434433, 'iterations_since_restore': 120, 'perf': {'cpu_util_percent': 11.072727272727272, 'ram_util_percent': 12.609090909090908}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.612241344224839, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.746680459522066, 'policy_loss': -0.10732811166062242, 'vf_loss': 9.85230240594773, 'vf_explained_var': -1.2772423880440848e-08, 'kl': 0.010110623047235378, 'entropy': 1.692088788463956, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 25305.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 121000, 'num_env_steps_trained': 121000, 'num_agent_steps_sampled': 121000, 'num_agent_steps_trained': 121000}, 'sampler_results': {'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 121000, 'num_agent_steps_trained': 121000, 'num_env_steps_sampled': 121000, 'num_env_steps_trained': 121000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.28434708876898, 'num_env_steps_trained_throughput_per_sec': 178.28434708876898, 'timesteps_total': 121000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 121000, 'timers': {'training_iteration_time_ms': 6010.426, 'sample_time_ms': 4558.52, 'load_time_ms': 0.119, 'load_throughput': 8412162.054, 'learn_time_ms': 1451.592, 'learn_throughput': 688.899, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 121000, 'num_env_steps_trained': 121000, 'num_agent_steps_sampled': 121000, 'num_agent_steps_trained': 121000}, 'done': False, 'episodes_total': 26, 'training_iteration': 121, 'trial_id': 'default', 'date': '2024-09-13_05-56-40', 'timestamp': 1726207000, 'time_this_iter_s': 5.609183311462402, 'time_total_s': 734.6029727458954, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab7a7d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 734.6029727458954, 'iterations_since_restore': 121, 'perf': {'cpu_util_percent': 11.9, 'ram_util_percent': 12.625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.105545112064907, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.778295948391868, 'policy_loss': -0.0813895749549071, 'vf_loss': 9.857822331928071, 'vf_explained_var': -5.108969552176339e-09, 'kl': 0.011041053609612154, 'entropy': 1.5976965501194909, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 25515.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 122000, 'num_env_steps_trained': 122000, 'num_agent_steps_sampled': 122000, 'num_agent_steps_trained': 122000}, 'sampler_results': {'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 122000, 'num_agent_steps_trained': 122000, 'num_env_steps_sampled': 122000, 'num_env_steps_trained': 122000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 185.73984507567798, 'num_env_steps_trained_throughput_per_sec': 185.73984507567798, 'timesteps_total': 122000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 122000, 'timers': {'training_iteration_time_ms': 5995.722, 'sample_time_ms': 4537.13, 'load_time_ms': 0.119, 'load_throughput': 8427373.92, 'learn_time_ms': 1458.279, 'learn_throughput': 685.74, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 122000, 'num_env_steps_trained': 122000, 'num_agent_steps_sampled': 122000, 'num_agent_steps_trained': 122000}, 'done': False, 'episodes_total': 26, 'training_iteration': 122, 'trial_id': 'default', 'date': '2024-09-13_05-56-45', 'timestamp': 1726207005, 'time_this_iter_s': 5.384023666381836, 'time_total_s': 739.9869964122772, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659767790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 739.9869964122772, 'iterations_since_restore': 122, 'perf': {'cpu_util_percent': 12.299999999999999, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.880694608461289, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.786891410464332, 'policy_loss': -0.07675789750757672, 'vf_loss': 9.861677001771472, 'vf_explained_var': 3.4059797014508928e-09, 'kl': 0.011687897988079161, 'entropy': 1.512060915288471, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 25725.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 123000, 'num_env_steps_trained': 123000, 'num_agent_steps_sampled': 123000, 'num_agent_steps_trained': 123000}, 'sampler_results': {'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 123000, 'num_agent_steps_trained': 123000, 'num_env_steps_sampled': 123000, 'num_env_steps_trained': 123000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.08140858622082, 'num_env_steps_trained_throughput_per_sec': 180.08140858622082, 'timesteps_total': 123000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 123000, 'timers': {'training_iteration_time_ms': 5989.758, 'sample_time_ms': 4525.498, 'load_time_ms': 0.124, 'load_throughput': 8097111.969, 'learn_time_ms': 1463.939, 'learn_throughput': 683.088, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 123000, 'num_env_steps_trained': 123000, 'num_agent_steps_sampled': 123000, 'num_agent_steps_trained': 123000}, 'done': False, 'episodes_total': 26, 'training_iteration': 123, 'trial_id': 'default', 'date': '2024-09-13_05-56-51', 'timestamp': 1726207011, 'time_this_iter_s': 5.553205490112305, 'time_total_s': 745.5402019023895, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab798d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 745.5402019023895, 'iterations_since_restore': 123, 'perf': {'cpu_util_percent': 11.014285714285714, 'ram_util_percent': 12.700000000000001}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.144460085460118, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.786760398319789, 'policy_loss': -0.06341470302570434, 'vf_loss': 9.848498312632243, 'vf_explained_var': -3.746577671595982e-08, 'kl': 0.009936770764415164, 'entropy': 1.5128698916662306, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 25935.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 124000, 'num_env_steps_trained': 124000, 'num_agent_steps_sampled': 124000, 'num_agent_steps_trained': 124000}, 'sampler_results': {'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2456.3451325737838, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 976.5109782877602, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15766689951388868, 'mean_inference_ms': 0.9517320107615774, 'mean_action_processing_ms': 0.13851282886954433, 'mean_env_wait_ms': 3.4622651258433925, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 124000, 'num_agent_steps_trained': 124000, 'num_env_steps_sampled': 124000, 'num_env_steps_trained': 124000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 174.89358909256822, 'num_env_steps_trained_throughput_per_sec': 174.89358909256822, 'timesteps_total': 124000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 124000, 'timers': {'training_iteration_time_ms': 6007.826, 'sample_time_ms': 4538.197, 'load_time_ms': 0.122, 'load_throughput': 8169661.083, 'learn_time_ms': 1469.31, 'learn_throughput': 680.592, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 124000, 'num_env_steps_trained': 124000, 'num_agent_steps_sampled': 124000, 'num_agent_steps_trained': 124000}, 'done': False, 'episodes_total': 26, 'training_iteration': 124, 'trial_id': 'default', 'date': '2024-09-13_05-56-56', 'timestamp': 1726207016, 'time_this_iter_s': 5.717914819717407, 'time_total_s': 751.2581167221069, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658412c50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 751.2581167221069, 'iterations_since_restore': 124, 'perf': {'cpu_util_percent': 13.022222222222222, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.847884495485397, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.657375490097772, 'policy_loss': -0.16362883452148663, 'vf_loss': 9.818064539773124, 'vf_explained_var': -2.128737313406808e-08, 'kl': 0.017421168133400722, 'entropy': 1.3571969282059442, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 26145.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000}, 'sampler_results': {'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000, 'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.27072182970112, 'num_env_steps_trained_throughput_per_sec': 127.27072182970112, 'timesteps_total': 125000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 125000, 'timers': {'training_iteration_time_ms': 6240.259, 'sample_time_ms': 4764.496, 'load_time_ms': 0.126, 'load_throughput': 7921254.013, 'learn_time_ms': 1475.44, 'learn_throughput': 677.764, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000}, 'done': False, 'episodes_total': 27, 'training_iteration': 125, 'trial_id': 'default', 'date': '2024-09-13_05-57-04', 'timestamp': 1726207024, 'time_this_iter_s': 7.857432126998901, 'time_total_s': 759.1155488491058, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65842a7d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 759.1155488491058, 'iterations_since_restore': 125, 'perf': {'cpu_util_percent': 11.145454545454545, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.8190888773827325, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.83363146554856, 'policy_loss': -0.02501998742421468, 'vf_loss': 9.855870165143694, 'vf_explained_var': -1.3340087164015998e-08, 'kl': 0.016481736328526, 'entropy': 1.3174088915189108, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 26355.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 126000, 'num_env_steps_trained': 126000, 'num_agent_steps_sampled': 126000, 'num_agent_steps_trained': 126000}, 'sampler_results': {'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 126000, 'num_agent_steps_trained': 126000, 'num_env_steps_sampled': 126000, 'num_env_steps_trained': 126000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.27087348808865, 'num_env_steps_trained_throughput_per_sec': 179.27087348808865, 'timesteps_total': 126000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 126000, 'timers': {'training_iteration_time_ms': 6013.085, 'sample_time_ms': 4532.031, 'load_time_ms': 0.126, 'load_throughput': 7922750.283, 'learn_time_ms': 1480.73, 'learn_throughput': 675.343, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 126000, 'num_env_steps_trained': 126000, 'num_agent_steps_sampled': 126000, 'num_agent_steps_trained': 126000}, 'done': False, 'episodes_total': 27, 'training_iteration': 126, 'trial_id': 'default', 'date': '2024-09-13_05-57-10', 'timestamp': 1726207030, 'time_this_iter_s': 5.578307151794434, 'time_total_s': 764.6938560009003, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658432410>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 764.6938560009003, 'iterations_since_restore': 126, 'perf': {'cpu_util_percent': 12.2, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.123208169142405, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.828141325996036, 'policy_loss': -0.04323855610120864, 'vf_loss': 9.868796216873896, 'vf_explained_var': -2.8383164178757443e-10, 'kl': 0.015310792706025433, 'entropy': 1.1780333797136942, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 26565.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 127000, 'num_env_steps_trained': 127000, 'num_agent_steps_sampled': 127000, 'num_agent_steps_trained': 127000}, 'sampler_results': {'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 127000, 'num_agent_steps_trained': 127000, 'num_env_steps_sampled': 127000, 'num_env_steps_trained': 127000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.76105663341116, 'num_env_steps_trained_throughput_per_sec': 180.76105663341116, 'timesteps_total': 127000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 127000, 'timers': {'training_iteration_time_ms': 6004.232, 'sample_time_ms': 4516.908, 'load_time_ms': 0.126, 'load_throughput': 7939246.64, 'learn_time_ms': 1486.999, 'learn_throughput': 672.495, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 127000, 'num_env_steps_trained': 127000, 'num_agent_steps_sampled': 127000, 'num_agent_steps_trained': 127000}, 'done': False, 'episodes_total': 27, 'training_iteration': 127, 'trial_id': 'default', 'date': '2024-09-13_05-57-15', 'timestamp': 1726207035, 'time_this_iter_s': 5.532331466674805, 'time_total_s': 770.2261874675751, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659624390>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 770.2261874675751, 'iterations_since_restore': 127, 'perf': {'cpu_util_percent': 12.275, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.396039459818885, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.862121368589856, 'policy_loss': -0.0031439098573866346, 'vf_loss': 9.863518206278483, 'vf_explained_var': -1.1353265671502977e-09, 'kl': 0.010353103052364619, 'entropy': 1.0925648036457243, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 26775.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 128000, 'num_env_steps_trained': 128000, 'num_agent_steps_sampled': 128000, 'num_agent_steps_trained': 128000}, 'sampler_results': {'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 128000, 'num_agent_steps_trained': 128000, 'num_env_steps_sampled': 128000, 'num_env_steps_trained': 128000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.44065899540595, 'num_env_steps_trained_throughput_per_sec': 182.44065899540595, 'timesteps_total': 128000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 128000, 'timers': {'training_iteration_time_ms': 5997.468, 'sample_time_ms': 4503.656, 'load_time_ms': 0.126, 'load_throughput': 7954303.053, 'learn_time_ms': 1493.489, 'learn_throughput': 669.573, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 128000, 'num_env_steps_trained': 128000, 'num_agent_steps_sampled': 128000, 'num_agent_steps_trained': 128000}, 'done': False, 'episodes_total': 27, 'training_iteration': 128, 'trial_id': 'default', 'date': '2024-09-13_05-57-21', 'timestamp': 1726207041, 'time_this_iter_s': 5.4813926219940186, 'time_total_s': 775.7075800895691, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea83d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 775.7075800895691, 'iterations_since_restore': 128, 'perf': {'cpu_util_percent': 11.962499999999999, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.283153093996502, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.88966307867141, 'policy_loss': 0.026383192500188238, 'vf_loss': 9.861589708782377, 'vf_explained_var': -1.2204760596865699e-08, 'kl': 0.010016272908597742, 'entropy': 1.0288767357667288, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 26985.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 129000, 'num_env_steps_trained': 129000, 'num_agent_steps_sampled': 129000, 'num_agent_steps_trained': 129000}, 'sampler_results': {'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2609.4243499131903, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1036.9892513109244, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15774022008737787, 'mean_inference_ms': 0.9518846763986063, 'mean_action_processing_ms': 0.13854243530590196, 'mean_env_wait_ms': 3.45967989921872, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 129000, 'num_agent_steps_trained': 129000, 'num_env_steps_sampled': 129000, 'num_env_steps_trained': 129000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.85029004566024, 'num_env_steps_trained_throughput_per_sec': 178.85029004566024, 'timesteps_total': 129000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 129000, 'timers': {'training_iteration_time_ms': 6015.421, 'sample_time_ms': 4517.446, 'load_time_ms': 0.127, 'load_throughput': 7888478.465, 'learn_time_ms': 1497.65, 'learn_throughput': 667.713, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 129000, 'num_env_steps_trained': 129000, 'num_agent_steps_sampled': 129000, 'num_agent_steps_trained': 129000}, 'done': False, 'episodes_total': 27, 'training_iteration': 129, 'trial_id': 'default', 'date': '2024-09-13_05-57-26', 'timestamp': 1726207046, 'time_this_iter_s': 5.591450452804565, 'time_total_s': 781.2990305423737, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab82510>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 781.2990305423737, 'iterations_since_restore': 129, 'perf': {'cpu_util_percent': 11.925, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.200253236861456, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.731056862785703, 'policy_loss': -0.14296917816003163, 'vf_loss': 9.871329025995164, 'vf_explained_var': -1.0501770746140254e-08, 'kl': 0.015982555925819767, 'entropy': 0.9608870863914489, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 27195.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000}, 'sampler_results': {'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000, 'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 126.39753857881664, 'num_env_steps_trained_throughput_per_sec': 126.39753857881664, 'timesteps_total': 130000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 130000, 'timers': {'training_iteration_time_ms': 6021.523, 'sample_time_ms': 4507.378, 'load_time_ms': 0.127, 'load_throughput': 7879586.699, 'learn_time_ms': 1513.817, 'learn_throughput': 660.582, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000}, 'done': False, 'episodes_total': 28, 'training_iteration': 130, 'trial_id': 'default', 'date': '2024-09-13_05-57-34', 'timestamp': 1726207054, 'time_this_iter_s': 7.911758184432983, 'time_total_s': 789.2107887268066, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6584329d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 789.2107887268066, 'iterations_since_restore': 130, 'perf': {'cpu_util_percent': 11.2, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.4132041238603135, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.845577521551222, 'policy_loss': -0.13444125070458368, 'vf_loss': 9.978704797653926, 'vf_explained_var': -6.528127761114211e-09, 'kl': 0.007786002014819224, 'entropy': 0.9825057776201339, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 27405.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 131000, 'num_env_steps_trained': 131000, 'num_agent_steps_sampled': 131000, 'num_agent_steps_trained': 131000}, 'sampler_results': {'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 131000, 'num_agent_steps_trained': 131000, 'num_env_steps_sampled': 131000, 'num_env_steps_trained': 131000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.10530652766064, 'num_env_steps_trained_throughput_per_sec': 181.10530652766064, 'timesteps_total': 131000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 131000, 'timers': {'training_iteration_time_ms': 6012.786, 'sample_time_ms': 4494.291, 'load_time_ms': 0.127, 'load_throughput': 7851561.213, 'learn_time_ms': 1518.161, 'learn_throughput': 658.692, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 131000, 'num_env_steps_trained': 131000, 'num_agent_steps_sampled': 131000, 'num_agent_steps_trained': 131000}, 'done': False, 'episodes_total': 28, 'training_iteration': 131, 'trial_id': 'default', 'date': '2024-09-13_05-57-40', 'timestamp': 1726207060, 'time_this_iter_s': 5.5218141078948975, 'time_total_s': 794.7326028347015, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab83f10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 794.7326028347015, 'iterations_since_restore': 131, 'perf': {'cpu_util_percent': 12.25, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.2798984788713, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.833971990857805, 'policy_loss': -0.1292059968159135, 'vf_loss': 9.961575680687314, 'vf_explained_var': -1.986821492513021e-09, 'kl': 0.009495235630025299, 'entropy': 0.9853809563886552, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 27615.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 132000, 'num_env_steps_trained': 132000, 'num_agent_steps_sampled': 132000, 'num_agent_steps_trained': 132000}, 'sampler_results': {'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 132000, 'num_agent_steps_trained': 132000, 'num_env_steps_sampled': 132000, 'num_env_steps_trained': 132000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.3639517836894, 'num_env_steps_trained_throughput_per_sec': 181.3639517836894, 'timesteps_total': 132000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 132000, 'timers': {'training_iteration_time_ms': 6025.776, 'sample_time_ms': 4505.877, 'load_time_ms': 0.127, 'load_throughput': 7860389.805, 'learn_time_ms': 1519.565, 'learn_throughput': 658.083, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 132000, 'num_env_steps_trained': 132000, 'num_agent_steps_sampled': 132000, 'num_agent_steps_trained': 132000}, 'done': False, 'episodes_total': 28, 'training_iteration': 132, 'trial_id': 'default', 'date': '2024-09-13_05-57-45', 'timestamp': 1726207065, 'time_this_iter_s': 5.513936996459961, 'time_total_s': 800.2465398311615, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab6c090>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 800.2465398311615, 'iterations_since_restore': 132, 'perf': {'cpu_util_percent': 12.212499999999999, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.7749692729541233, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.833583818163191, 'policy_loss': -0.1498322864373525, 'vf_loss': 9.981136026836577, 'vf_explained_var': 1.1353265671502977e-09, 'kl': 0.01351107050570492, 'entropy': 1.062071235690798, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 27825.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 133000, 'num_env_steps_trained': 133000, 'num_agent_steps_sampled': 133000, 'num_agent_steps_trained': 133000}, 'sampler_results': {'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2679.1696343966973, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1095.6385507068449, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15780798682253688, 'mean_inference_ms': 0.9520094016164821, 'mean_action_processing_ms': 0.13856692032094567, 'mean_env_wait_ms': 3.4570856911274888, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 133000, 'num_agent_steps_trained': 133000, 'num_env_steps_sampled': 133000, 'num_env_steps_trained': 133000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.04108880305864, 'num_env_steps_trained_throughput_per_sec': 180.04108880305864, 'timesteps_total': 133000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 133000, 'timers': {'training_iteration_time_ms': 6025.9, 'sample_time_ms': 4509.449, 'load_time_ms': 0.122, 'load_throughput': 8201611.263, 'learn_time_ms': 1516.124, 'learn_throughput': 659.577, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 133000, 'num_env_steps_trained': 133000, 'num_agent_steps_sampled': 133000, 'num_agent_steps_trained': 133000}, 'done': False, 'episodes_total': 28, 'training_iteration': 133, 'trial_id': 'default', 'date': '2024-09-13_05-57-51', 'timestamp': 1726207071, 'time_this_iter_s': 5.554502248764038, 'time_total_s': 805.8010420799255, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658486290>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 805.8010420799255, 'iterations_since_restore': 133, 'perf': {'cpu_util_percent': 12.2125, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.748610196227119, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.76693084807623, 'policy_loss': -0.0837454986625484, 'vf_loss': 9.84834037962414, 'vf_explained_var': 1.1353265671502977e-09, 'kl': 0.013843028505202696, 'entropy': 1.071991971560887, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 28035.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 134000, 'num_env_steps_trained': 134000, 'num_agent_steps_sampled': 134000, 'num_agent_steps_trained': 134000}, 'sampler_results': {'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 134000, 'num_agent_steps_trained': 134000, 'num_env_steps_sampled': 134000, 'num_env_steps_trained': 134000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 125.71368215422505, 'num_env_steps_trained_throughput_per_sec': 125.71368215422505, 'timesteps_total': 134000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 134000, 'timers': {'training_iteration_time_ms': 6249.582, 'sample_time_ms': 4750.086, 'load_time_ms': 0.117, 'load_throughput': 8526741.208, 'learn_time_ms': 1499.175, 'learn_throughput': 667.034, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 134000, 'num_env_steps_trained': 134000, 'num_agent_steps_sampled': 134000, 'num_agent_steps_trained': 134000}, 'done': False, 'episodes_total': 29, 'training_iteration': 134, 'trial_id': 'default', 'date': '2024-09-13_05-57-59', 'timestamp': 1726207079, 'time_this_iter_s': 7.954755067825317, 'time_total_s': 813.7557971477509, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea5090>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 813.7557971477509, 'iterations_since_restore': 134, 'perf': {'cpu_util_percent': 11.163636363636364, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.9525196722575595, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.836171894981748, 'policy_loss': -0.024429529479571752, 'vf_loss': 9.8576321828933, 'vf_explained_var': -9.934107462565104e-09, 'kl': 0.017594978518796586, 'entropy': 1.0668890987123762, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 28245.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000}, 'sampler_results': {'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000, 'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.53717311687262, 'num_env_steps_trained_throughput_per_sec': 178.53717311687262, 'timesteps_total': 135000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 135000, 'timers': {'training_iteration_time_ms': 6023.962, 'sample_time_ms': 4524.374, 'load_time_ms': 0.114, 'load_throughput': 8772859.234, 'learn_time_ms': 1499.273, 'learn_throughput': 666.99, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000}, 'done': False, 'episodes_total': 29, 'training_iteration': 135, 'trial_id': 'default', 'date': '2024-09-13_05-58-04', 'timestamp': 1726207084, 'time_this_iter_s': 5.601238012313843, 'time_total_s': 819.3570351600647, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab41fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 819.3570351600647, 'iterations_since_restore': 135, 'perf': {'cpu_util_percent': 11.85, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.862557045618693, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.80868019830613, 'policy_loss': -0.06446919668288457, 'vf_loss': 9.871477177029565, 'vf_explained_var': 6.244296119326637e-09, 'kl': 0.00990961409476038, 'entropy': 1.0493473893120175, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 28455.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 136000, 'num_env_steps_trained': 136000, 'num_agent_steps_sampled': 136000, 'num_agent_steps_trained': 136000}, 'sampler_results': {'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 136000, 'num_agent_steps_trained': 136000, 'num_env_steps_sampled': 136000, 'num_env_steps_trained': 136000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.92909059772626, 'num_env_steps_trained_throughput_per_sec': 179.92909059772626, 'timesteps_total': 136000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 136000, 'timers': {'training_iteration_time_ms': 6021.922, 'sample_time_ms': 4522.05, 'load_time_ms': 0.114, 'load_throughput': 8785722.664, 'learn_time_ms': 1499.554, 'learn_throughput': 666.865, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 136000, 'num_env_steps_trained': 136000, 'num_agent_steps_sampled': 136000, 'num_agent_steps_trained': 136000}, 'done': False, 'episodes_total': 29, 'training_iteration': 136, 'trial_id': 'default', 'date': '2024-09-13_05-58-10', 'timestamp': 1726207090, 'time_this_iter_s': 5.557924509048462, 'time_total_s': 824.9149596691132, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab84490>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 824.9149596691132, 'iterations_since_restore': 136, 'perf': {'cpu_util_percent': 11.9875, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.199658569835481, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.782946949913388, 'policy_loss': -0.08530096511046091, 'vf_loss': 9.866331845238095, 'vf_explained_var': -2.5544847760881695e-08, 'kl': 0.011354042459390238, 'entropy': 0.9206928145317804, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 28665.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 137000, 'num_env_steps_trained': 137000, 'num_agent_steps_sampled': 137000, 'num_agent_steps_trained': 137000}, 'sampler_results': {'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 137000, 'num_agent_steps_trained': 137000, 'num_env_steps_sampled': 137000, 'num_env_steps_trained': 137000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.8647629943194, 'num_env_steps_trained_throughput_per_sec': 179.8647629943194, 'timesteps_total': 137000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 137000, 'timers': {'training_iteration_time_ms': 6024.678, 'sample_time_ms': 4525.804, 'load_time_ms': 0.114, 'load_throughput': 8758204.218, 'learn_time_ms': 1498.555, 'learn_throughput': 667.31, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 137000, 'num_env_steps_trained': 137000, 'num_agent_steps_sampled': 137000, 'num_agent_steps_trained': 137000}, 'done': False, 'episodes_total': 29, 'training_iteration': 137, 'trial_id': 'default', 'date': '2024-09-13_05-58-16', 'timestamp': 1726207096, 'time_this_iter_s': 5.559899806976318, 'time_total_s': 830.4748594760895, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab6c090>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 830.4748594760895, 'iterations_since_restore': 137, 'perf': {'cpu_util_percent': 11.975000000000001, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.300004770642235, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.738200224013555, 'policy_loss': -0.1261465271313985, 'vf_loss': 9.862209756033762, 'vf_explained_var': -1.4475413731166295e-08, 'kl': 0.012663352321916628, 'entropy': 0.8688266189325423, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 28875.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 138000, 'num_env_steps_trained': 138000, 'num_agent_steps_sampled': 138000, 'num_agent_steps_trained': 138000}, 'sampler_results': {'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2859.536118120654, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1156.4626047555969, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15787122042320328, 'mean_inference_ms': 0.9521135490442333, 'mean_action_processing_ms': 0.13858706577793967, 'mean_env_wait_ms': 3.454707610088955, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 138000, 'num_agent_steps_trained': 138000, 'num_env_steps_sampled': 138000, 'num_env_steps_trained': 138000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.48884834901895, 'num_env_steps_trained_throughput_per_sec': 180.48884834901895, 'timesteps_total': 138000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 138000, 'timers': {'training_iteration_time_ms': 6030.606, 'sample_time_ms': 4532.42, 'load_time_ms': 0.115, 'load_throughput': 8687456.504, 'learn_time_ms': 1497.866, 'learn_throughput': 667.617, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 138000, 'num_env_steps_trained': 138000, 'num_agent_steps_sampled': 138000, 'num_agent_steps_trained': 138000}, 'done': False, 'episodes_total': 29, 'training_iteration': 138, 'trial_id': 'default', 'date': '2024-09-13_05-58-21', 'timestamp': 1726207101, 'time_this_iter_s': 5.5406787395477295, 'time_total_s': 836.0155382156372, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658486810>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 836.0155382156372, 'iterations_since_restore': 138, 'perf': {'cpu_util_percent': 12.425, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.5083748068128315, 'cur_kl_coeff': 0.16875, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.609948912121, 'policy_loss': -0.21663504555998814, 'vf_loss': 9.82296446845645, 'vf_explained_var': 7.09579104468936e-09, 'kl': 0.021448944493923587, 'entropy': 0.7500514810993558, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 29085.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 139000, 'num_env_steps_trained': 139000, 'num_agent_steps_sampled': 139000, 'num_agent_steps_trained': 139000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 139000, 'num_agent_steps_trained': 139000, 'num_env_steps_sampled': 139000, 'num_env_steps_trained': 139000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 126.14277780128623, 'num_env_steps_trained_throughput_per_sec': 126.14277780128623, 'timesteps_total': 139000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 139000, 'timers': {'training_iteration_time_ms': 6264.231, 'sample_time_ms': 4764.89, 'load_time_ms': 0.114, 'load_throughput': 8747245.047, 'learn_time_ms': 1499.022, 'learn_throughput': 667.101, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 139000, 'num_env_steps_trained': 139000, 'num_agent_steps_sampled': 139000, 'num_agent_steps_trained': 139000}, 'done': False, 'episodes_total': 30, 'training_iteration': 139, 'trial_id': 'default', 'date': '2024-09-13_05-58-29', 'timestamp': 1726207109, 'time_this_iter_s': 7.927708387374878, 'time_total_s': 843.9432466030121, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658488ad0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 843.9432466030121, 'iterations_since_restore': 139, 'perf': {'cpu_util_percent': 11.027272727272727, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.383749541214534, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.734430367606027, 'policy_loss': -0.13903753069185076, 'vf_loss': 9.871633370717367, 'vf_explained_var': -7.663454328264508e-09, 'kl': 0.007247126203410151, 'entropy': 0.7110923982801891, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 29295.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000, 'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.3844679877581, 'num_env_steps_trained_throughput_per_sec': 182.3844679877581, 'timesteps_total': 140000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 140000, 'timers': {'training_iteration_time_ms': 6021.369, 'sample_time_ms': 4525.183, 'load_time_ms': 0.114, 'load_throughput': 8741775.74, 'learn_time_ms': 1495.866, 'learn_throughput': 668.509, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000}, 'done': False, 'episodes_total': 30, 'training_iteration': 140, 'trial_id': 'default', 'date': '2024-09-13_05-58-35', 'timestamp': 1726207115, 'time_this_iter_s': 5.483119964599609, 'time_total_s': 849.4263665676117, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab42a10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 849.4263665676117, 'iterations_since_restore': 140, 'perf': {'cpu_util_percent': 12.0375, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.468828206970578, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.749922039395287, 'policy_loss': -0.1363620521589404, 'vf_loss': 9.883694748651413, 'vf_explained_var': -1.8449056716192337e-08, 'kl': 0.010229333271716068, 'entropy': 0.6566819324379876, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 29505.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 141000, 'num_env_steps_trained': 141000, 'num_agent_steps_sampled': 141000, 'num_agent_steps_trained': 141000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 141000, 'num_agent_steps_trained': 141000, 'num_env_steps_sampled': 141000, 'num_env_steps_trained': 141000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.25324727265829, 'num_env_steps_trained_throughput_per_sec': 181.25324727265829, 'timesteps_total': 141000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 141000, 'timers': {'training_iteration_time_ms': 6020.918, 'sample_time_ms': 4527.599, 'load_time_ms': 0.115, 'load_throughput': 8721779.996, 'learn_time_ms': 1492.997, 'learn_throughput': 669.794, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 141000, 'num_env_steps_trained': 141000, 'num_agent_steps_sampled': 141000, 'num_agent_steps_trained': 141000}, 'done': False, 'episodes_total': 30, 'training_iteration': 141, 'trial_id': 'default', 'date': '2024-09-13_05-58-40', 'timestamp': 1726207120, 'time_this_iter_s': 5.517340898513794, 'time_total_s': 854.9437074661255, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab6c990>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 854.9437074661255, 'iterations_since_restore': 141, 'perf': {'cpu_util_percent': 12.3625, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.15190908908844, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.785744789668492, 'policy_loss': -0.10627146065235138, 'vf_loss': 9.888602756318592, 'vf_explained_var': 4.825137910388765e-09, 'kl': 0.013485146071027321, 'entropy': 0.5605396299135117, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 29715.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 142000, 'num_env_steps_trained': 142000, 'num_agent_steps_sampled': 142000, 'num_agent_steps_trained': 142000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1216.8389179173894, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15792759951238605, 'mean_inference_ms': 0.952202561847829, 'mean_action_processing_ms': 0.13860254895013563, 'mean_env_wait_ms': 3.452349588437497, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 142000, 'num_agent_steps_trained': 142000, 'num_env_steps_sampled': 142000, 'num_env_steps_trained': 142000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.53664221449117, 'num_env_steps_trained_throughput_per_sec': 180.53664221449117, 'timesteps_total': 142000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 142000, 'timers': {'training_iteration_time_ms': 6023.445, 'sample_time_ms': 4531.329, 'load_time_ms': 0.115, 'load_throughput': 8696462.783, 'learn_time_ms': 1491.792, 'learn_throughput': 670.335, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 142000, 'num_env_steps_trained': 142000, 'num_agent_steps_sampled': 142000, 'num_agent_steps_trained': 142000}, 'done': False, 'episodes_total': 30, 'training_iteration': 142, 'trial_id': 'default', 'date': '2024-09-13_05-58-46', 'timestamp': 1726207126, 'time_this_iter_s': 5.539202451705933, 'time_total_s': 860.4829099178314, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597f6bd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 860.4829099178314, 'iterations_since_restore': 142, 'perf': {'cpu_util_percent': 12.15, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.686196886925471, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.607329250517346, 'policy_loss': -0.0846580826810428, 'vf_loss': 9.689627474830264, 'vf_explained_var': 2.5544847760881697e-09, 'kl': 0.009322923363097823, 'entropy': 0.4912657394295647, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 29925.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 143000, 'num_env_steps_trained': 143000, 'num_agent_steps_sampled': 143000, 'num_agent_steps_trained': 143000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 143000, 'num_agent_steps_trained': 143000, 'num_env_steps_sampled': 143000, 'num_env_steps_trained': 143000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.14823718745446, 'num_env_steps_trained_throughput_per_sec': 127.14823718745446, 'timesteps_total': 143000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 143000, 'timers': {'training_iteration_time_ms': 6254.5, 'sample_time_ms': 4774.759, 'load_time_ms': 0.115, 'load_throughput': 8730857.619, 'learn_time_ms': 1479.419, 'learn_throughput': 675.941, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 143000, 'num_env_steps_trained': 143000, 'num_agent_steps_sampled': 143000, 'num_agent_steps_trained': 143000}, 'done': False, 'episodes_total': 31, 'training_iteration': 143, 'trial_id': 'default', 'date': '2024-09-13_05-58-54', 'timestamp': 1726207134, 'time_this_iter_s': 7.865006685256958, 'time_total_s': 868.3479166030884, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65842bf50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 868.3479166030884, 'iterations_since_restore': 143, 'perf': {'cpu_util_percent': 11.60909090909091, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.189505914279393, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.823710509708949, 'policy_loss': -0.04260729189429965, 'vf_loss': 9.862006187438965, 'vf_explained_var': 2.8383164178757443e-10, 'kl': 0.017033488558705234, 'entropy': 0.28590029619988944, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 30135.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 144000, 'num_env_steps_trained': 144000, 'num_agent_steps_sampled': 144000, 'num_agent_steps_trained': 144000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 144000, 'num_agent_steps_trained': 144000, 'num_env_steps_sampled': 144000, 'num_env_steps_trained': 144000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 184.00206186697667, 'num_env_steps_trained_throughput_per_sec': 184.00206186697667, 'timesteps_total': 144000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 144000, 'timers': {'training_iteration_time_ms': 6002.514, 'sample_time_ms': 4511.081, 'load_time_ms': 0.114, 'load_throughput': 8736313.268, 'learn_time_ms': 1491.111, 'learn_throughput': 670.641, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 144000, 'num_env_steps_trained': 144000, 'num_agent_steps_sampled': 144000, 'num_agent_steps_trained': 144000}, 'done': False, 'episodes_total': 31, 'training_iteration': 144, 'trial_id': 'default', 'date': '2024-09-13_05-58-59', 'timestamp': 1726207139, 'time_this_iter_s': 5.434890031814575, 'time_total_s': 873.782806634903, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65842b590>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 873.782806634903, 'iterations_since_restore': 144, 'perf': {'cpu_util_percent': 11.3, 'ram_util_percent': 12.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.081167364688147, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.886013403392973, 'policy_loss': 0.020135646136034104, 'vf_loss': 9.863435826982771, 'vf_explained_var': -5.960464477539063e-09, 'kl': 0.009647282491954016, 'entropy': 0.2298410164458411, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 30345.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000, 'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 183.84049587226036, 'num_env_steps_trained_throughput_per_sec': 183.84049587226036, 'timesteps_total': 145000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 145000, 'timers': {'training_iteration_time_ms': 5986.357, 'sample_time_ms': 4499.909, 'load_time_ms': 0.114, 'load_throughput': 8765525.601, 'learn_time_ms': 1486.126, 'learn_throughput': 672.89, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000}, 'done': False, 'episodes_total': 31, 'training_iteration': 145, 'trial_id': 'default', 'date': '2024-09-13_05-59-04', 'timestamp': 1726207144, 'time_this_iter_s': 5.43966269493103, 'time_total_s': 879.222469329834, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea7fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 879.222469329834, 'iterations_since_restore': 145, 'perf': {'cpu_util_percent': 11.975, 'ram_util_percent': 12.775}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.579296133064088, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.892985975174676, 'policy_loss': 0.01946293413860812, 'vf_loss': 9.871619392576672, 'vf_explained_var': 1.986821492513021e-09, 'kl': 0.0075206456246852274, 'entropy': 0.3104473910161427, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 30555.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 146000, 'num_env_steps_trained': 146000, 'num_agent_steps_sampled': 146000, 'num_agent_steps_trained': 146000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 146000, 'num_agent_steps_trained': 146000, 'num_env_steps_sampled': 146000, 'num_env_steps_trained': 146000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 185.57154414862416, 'num_env_steps_trained_throughput_per_sec': 185.57154414862416, 'timesteps_total': 146000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 146000, 'timers': {'training_iteration_time_ms': 5969.458, 'sample_time_ms': 4490.093, 'load_time_ms': 0.115, 'load_throughput': 8700070.525, 'learn_time_ms': 1479.044, 'learn_throughput': 676.112, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 146000, 'num_env_steps_trained': 146000, 'num_agent_steps_sampled': 146000, 'num_agent_steps_trained': 146000}, 'done': False, 'episodes_total': 31, 'training_iteration': 146, 'trial_id': 'default', 'date': '2024-09-13_05-59-10', 'timestamp': 1726207150, 'time_this_iter_s': 5.388923168182373, 'time_total_s': 884.6113924980164, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65847cc10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 884.6113924980164, 'iterations_since_restore': 146, 'perf': {'cpu_util_percent': 11.142857142857142, 'ram_util_percent': 12.771428571428572}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.088765635944548, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.892524691990443, 'policy_loss': 0.03690900249140603, 'vf_loss': 9.853324849264963, 'vf_explained_var': -1.0501770746140254e-08, 'kl': 0.009049975554357693, 'entropy': 0.2815319323823566, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 30765.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 147000, 'num_env_steps_trained': 147000, 'num_agent_steps_sampled': 147000, 'num_agent_steps_trained': 147000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1273.0288291211632, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1579782524482745, 'mean_inference_ms': 0.9522681793693686, 'mean_action_processing_ms': 0.13861424206571202, 'mean_env_wait_ms': 3.450161257252676, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 147000, 'num_agent_steps_trained': 147000, 'num_env_steps_sampled': 147000, 'num_env_steps_trained': 147000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.30626440898564, 'num_env_steps_trained_throughput_per_sec': 182.30626440898564, 'timesteps_total': 147000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 147000, 'timers': {'training_iteration_time_ms': 5962.012, 'sample_time_ms': 4491.109, 'load_time_ms': 0.115, 'load_throughput': 8678468.86, 'learn_time_ms': 1470.583, 'learn_throughput': 680.003, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 147000, 'num_env_steps_trained': 147000, 'num_agent_steps_sampled': 147000, 'num_agent_steps_trained': 147000}, 'done': False, 'episodes_total': 31, 'training_iteration': 147, 'trial_id': 'default', 'date': '2024-09-13_05-59-15', 'timestamp': 1726207155, 'time_this_iter_s': 5.485447883605957, 'time_total_s': 890.0968403816223, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659766310>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 890.0968403816223, 'iterations_since_restore': 147, 'perf': {'cpu_util_percent': 12.1875, 'ram_util_percent': 12.7625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.569580841064453, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.77519049417405, 'policy_loss': -0.055026678403928164, 'vf_loss': 9.828199291229248, 'vf_explained_var': 1.3907750447591146e-08, 'kl': 0.007971983660121125, 'entropy': 0.3641211538087754, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 30975.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 148000, 'num_env_steps_trained': 148000, 'num_agent_steps_sampled': 148000, 'num_agent_steps_trained': 148000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 148000, 'num_agent_steps_trained': 148000, 'num_env_steps_sampled': 148000, 'num_env_steps_trained': 148000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 126.02380914179079, 'num_env_steps_trained_throughput_per_sec': 126.02380914179079, 'timesteps_total': 148000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 148000, 'timers': {'training_iteration_time_ms': 6201.462, 'sample_time_ms': 4737.257, 'load_time_ms': 0.114, 'load_throughput': 8756375.783, 'learn_time_ms': 1463.884, 'learn_throughput': 683.114, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 148000, 'num_env_steps_trained': 148000, 'num_agent_steps_sampled': 148000, 'num_agent_steps_trained': 148000}, 'done': False, 'episodes_total': 32, 'training_iteration': 148, 'trial_id': 'default', 'date': '2024-09-13_05-59-23', 'timestamp': 1726207163, 'time_this_iter_s': 7.935245990753174, 'time_total_s': 898.0320863723755, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658484950>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 898.0320863723755, 'iterations_since_restore': 148, 'perf': {'cpu_util_percent': 11.65, 'ram_util_percent': 12.775}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.04433316276187, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.907324196043469, 'policy_loss': 0.05234227343684151, 'vf_loss': 9.851992030370804, 'vf_explained_var': -4.825137910388765e-09, 'kl': 0.011811882300978975, 'entropy': 0.3048342948868161, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 31185.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 149000, 'num_env_steps_trained': 149000, 'num_agent_steps_sampled': 149000, 'num_agent_steps_trained': 149000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 149000, 'num_agent_steps_trained': 149000, 'num_env_steps_sampled': 149000, 'num_env_steps_trained': 149000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 171.03132610908162, 'num_env_steps_trained_throughput_per_sec': 171.03132610908162, 'timesteps_total': 149000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 149000, 'timers': {'training_iteration_time_ms': 5993.398, 'sample_time_ms': 4536.349, 'load_time_ms': 0.115, 'load_throughput': 8721779.996, 'learn_time_ms': 1456.728, 'learn_throughput': 686.47, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 149000, 'num_env_steps_trained': 149000, 'num_agent_steps_sampled': 149000, 'num_agent_steps_trained': 149000}, 'done': False, 'episodes_total': 32, 'training_iteration': 149, 'trial_id': 'default', 'date': '2024-09-13_05-59-29', 'timestamp': 1726207169, 'time_this_iter_s': 5.847071409225464, 'time_total_s': 903.879157781601, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65cace6d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 903.879157781601, 'iterations_since_restore': 149, 'perf': {'cpu_util_percent': 11.675, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.940202146484738, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.866373643420992, 'policy_loss': -0.0033911727723621187, 'vf_loss': 9.866557307470412, 'vf_explained_var': 8.514949253627232e-09, 'kl': 0.012671609374402237, 'entropy': 0.20543934248742604, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 31395.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000, 'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.1579181172007, 'num_env_steps_trained_throughput_per_sec': 176.1579181172007, 'timesteps_total': 150000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 150000, 'timers': {'training_iteration_time_ms': 6012.779, 'sample_time_ms': 4560.691, 'load_time_ms': 0.115, 'load_throughput': 8723594.01, 'learn_time_ms': 1451.769, 'learn_throughput': 688.815, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000}, 'done': False, 'episodes_total': 32, 'training_iteration': 150, 'trial_id': 'default', 'date': '2024-09-13_05-59-35', 'timestamp': 1726207175, 'time_this_iter_s': 5.676900386810303, 'time_total_s': 909.5560581684113, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab81950>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 909.5560581684113, 'iterations_since_restore': 150, 'perf': {'cpu_util_percent': 11.825000000000001, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.83883995896294, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.880071408408028, 'policy_loss': 0.019962006714195013, 'vf_loss': 9.85747829618908, 'vf_explained_var': -1.5326908656529016e-08, 'kl': 0.010394699801136586, 'entropy': 0.2623966384501684, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 31605.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 151000, 'num_env_steps_trained': 151000, 'num_agent_steps_sampled': 151000, 'num_agent_steps_trained': 151000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 151000, 'num_agent_steps_trained': 151000, 'num_env_steps_sampled': 151000, 'num_env_steps_trained': 151000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.03082204716478, 'num_env_steps_trained_throughput_per_sec': 176.03082204716478, 'timesteps_total': 151000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 151000, 'timers': {'training_iteration_time_ms': 6029.147, 'sample_time_ms': 4579.79, 'load_time_ms': 0.114, 'load_throughput': 8763694.108, 'learn_time_ms': 1449.042, 'learn_throughput': 690.111, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 151000, 'num_env_steps_trained': 151000, 'num_agent_steps_sampled': 151000, 'num_agent_steps_trained': 151000}, 'done': False, 'episodes_total': 32, 'training_iteration': 151, 'trial_id': 'default', 'date': '2024-09-13_05-59-41', 'timestamp': 1726207181, 'time_this_iter_s': 5.681039571762085, 'time_total_s': 915.2370977401733, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659762690>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 915.2370977401733, 'iterations_since_restore': 151, 'perf': {'cpu_util_percent': 11.5625, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.507367278280713, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.851128478277298, 'policy_loss': -0.004305063737999825, 'vf_loss': 9.853227247510638, 'vf_explained_var': -1.986821492513021e-09, 'kl': 0.008716058480162641, 'entropy': 0.17634885779448917, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 31815.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 152000, 'num_env_steps_trained': 152000, 'num_agent_steps_sampled': 152000, 'num_agent_steps_trained': 152000}, 'sampler_results': {'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2967.751999609366, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1325.6827822089297, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15802062709344375, 'mean_inference_ms': 0.9523007206808478, 'mean_action_processing_ms': 0.1386212607180846, 'mean_env_wait_ms': 3.4479803234997815, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 152000, 'num_agent_steps_trained': 152000, 'num_env_steps_sampled': 152000, 'num_env_steps_trained': 152000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.6222570191924, 'num_env_steps_trained_throughput_per_sec': 179.6222570191924, 'timesteps_total': 152000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 152000, 'timers': {'training_iteration_time_ms': 6031.966, 'sample_time_ms': 4586.11, 'load_time_ms': 0.115, 'load_throughput': 8732675.411, 'learn_time_ms': 1445.541, 'learn_throughput': 691.783, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 152000, 'num_env_steps_trained': 152000, 'num_agent_steps_sampled': 152000, 'num_agent_steps_trained': 152000}, 'done': False, 'episodes_total': 32, 'training_iteration': 152, 'trial_id': 'default', 'date': '2024-09-13_05-59-46', 'timestamp': 1726207186, 'time_this_iter_s': 5.567406177520752, 'time_total_s': 920.8045039176941, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c671cd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 920.8045039176941, 'iterations_since_restore': 152, 'perf': {'cpu_util_percent': 12.024999999999999, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.919464785712106, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.675319717043923, 'policy_loss': -0.14540665610915138, 'vf_loss': 9.818345224289667, 'vf_explained_var': -1.163709731329055e-08, 'kl': 0.009407090942252356, 'entropy': 0.04395122811907814, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 32025.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 153000, 'num_env_steps_trained': 153000, 'num_agent_steps_sampled': 153000, 'num_agent_steps_trained': 153000}, 'sampler_results': {'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 153000, 'num_agent_steps_trained': 153000, 'num_env_steps_sampled': 153000, 'num_env_steps_trained': 153000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 128.54095626681845, 'num_env_steps_trained_throughput_per_sec': 128.54095626681845, 'timesteps_total': 153000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 153000, 'timers': {'training_iteration_time_ms': 6023.445, 'sample_time_ms': 4567.784, 'load_time_ms': 0.115, 'load_throughput': 8716342.477, 'learn_time_ms': 1455.344, 'learn_throughput': 687.123, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 153000, 'num_env_steps_trained': 153000, 'num_agent_steps_sampled': 153000, 'num_agent_steps_trained': 153000}, 'done': False, 'episodes_total': 33, 'training_iteration': 153, 'trial_id': 'default', 'date': '2024-09-13_05-59-54', 'timestamp': 1726207194, 'time_this_iter_s': 7.779814004898071, 'time_total_s': 928.5843179225922, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab43610>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 928.5843179225922, 'iterations_since_restore': 153, 'perf': {'cpu_util_percent': 11.054545454545455, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.993267348834446, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.832580434708369, 'policy_loss': -0.15527139429801276, 'vf_loss': 9.985012227012998, 'vf_explained_var': 5.3928011939639136e-09, 'kl': 0.011217728922132695, 'entropy': 0.006014479058129447, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 32235.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 154000, 'num_env_steps_trained': 154000, 'num_agent_steps_sampled': 154000, 'num_agent_steps_trained': 154000}, 'sampler_results': {'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 154000, 'num_agent_steps_trained': 154000, 'num_env_steps_sampled': 154000, 'num_env_steps_trained': 154000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.6596536978747, 'num_env_steps_trained_throughput_per_sec': 180.6596536978747, 'timesteps_total': 154000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 154000, 'timers': {'training_iteration_time_ms': 6033.499, 'sample_time_ms': 4578.525, 'load_time_ms': 0.115, 'load_throughput': 8723594.01, 'learn_time_ms': 1454.658, 'learn_throughput': 687.447, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 154000, 'num_env_steps_trained': 154000, 'num_agent_steps_sampled': 154000, 'num_agent_steps_trained': 154000}, 'done': False, 'episodes_total': 33, 'training_iteration': 154, 'trial_id': 'default', 'date': '2024-09-13_05-59-59', 'timestamp': 1726207199, 'time_this_iter_s': 5.535446643829346, 'time_total_s': 934.1197645664215, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab79210>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 934.1197645664215, 'iterations_since_restore': 154, 'perf': {'cpu_util_percent': 11.925, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.964252562749953, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.835396339779809, 'policy_loss': -0.14995895737693424, 'vf_loss': 9.981908285050165, 'vf_explained_var': -2.7247837611607142e-08, 'kl': 0.013617740713657426, 'entropy': -0.048445814280282884, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 32445.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000}, 'sampler_results': {'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000, 'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.45724439117546, 'num_env_steps_trained_throughput_per_sec': 181.45724439117546, 'timesteps_total': 155000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 155000, 'timers': {'training_iteration_time_ms': 6040.644, 'sample_time_ms': 4587.564, 'load_time_ms': 0.115, 'load_throughput': 8674879.007, 'learn_time_ms': 1452.762, 'learn_throughput': 688.344, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000}, 'done': False, 'episodes_total': 33, 'training_iteration': 155, 'trial_id': 'default', 'date': '2024-09-13_06-00-05', 'timestamp': 1726207205, 'time_this_iter_s': 5.511141061782837, 'time_total_s': 939.6309056282043, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab827d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 939.6309056282043, 'iterations_since_restore': 155, 'perf': {'cpu_util_percent': 12.137500000000001, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.424691176414489, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.828859070369175, 'policy_loss': -0.15913524272895996, 'vf_loss': 9.985563250950404, 'vf_explained_var': -1.617840358189174e-08, 'kl': 0.009604273217042887, 'entropy': -0.031376880974996656, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 32655.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 156000, 'num_env_steps_trained': 156000, 'num_agent_steps_sampled': 156000, 'num_agent_steps_trained': 156000}, 'sampler_results': {'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 2976.103179448776, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1375.6955215192281, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1580611372728553, 'mean_inference_ms': 0.9523448672013684, 'mean_action_processing_ms': 0.13863070188262275, 'mean_env_wait_ms': 3.445929202530392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 156000, 'num_agent_steps_trained': 156000, 'num_env_steps_sampled': 156000, 'num_env_steps_trained': 156000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.28011742850015, 'num_env_steps_trained_throughput_per_sec': 181.28011742850015, 'timesteps_total': 156000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 156000, 'timers': {'training_iteration_time_ms': 6053.4, 'sample_time_ms': 4599.436, 'load_time_ms': 0.115, 'load_throughput': 8698266.28, 'learn_time_ms': 1453.645, 'learn_throughput': 687.926, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 156000, 'num_env_steps_trained': 156000, 'num_agent_steps_sampled': 156000, 'num_agent_steps_trained': 156000}, 'done': False, 'episodes_total': 33, 'training_iteration': 156, 'trial_id': 'default', 'date': '2024-09-13_06-00-10', 'timestamp': 1726207210, 'time_this_iter_s': 5.516497611999512, 'time_total_s': 945.1474032402039, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65959b150>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 945.1474032402039, 'iterations_since_restore': 156, 'perf': {'cpu_util_percent': 12.05, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.477841898940858, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.615538778759184, 'policy_loss': -0.21170497142842837, 'vf_loss': 9.82279136748541, 'vf_explained_var': -3.1221480596633185e-09, 'kl': 0.017589500682481142, 'entropy': -0.1504998241152082, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 32865.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 157000, 'num_env_steps_trained': 157000, 'num_agent_steps_sampled': 157000, 'num_agent_steps_trained': 157000}, 'sampler_results': {'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 157000, 'num_agent_steps_trained': 157000, 'num_env_steps_sampled': 157000, 'num_env_steps_trained': 157000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.74069823352961, 'num_env_steps_trained_throughput_per_sec': 127.74069823352961, 'timesteps_total': 157000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 157000, 'timers': {'training_iteration_time_ms': 6287.709, 'sample_time_ms': 4842.007, 'load_time_ms': 0.114, 'load_throughput': 8772859.234, 'learn_time_ms': 1445.384, 'learn_throughput': 691.858, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 157000, 'num_env_steps_trained': 157000, 'num_agent_steps_sampled': 157000, 'num_agent_steps_trained': 157000}, 'done': False, 'episodes_total': 34, 'training_iteration': 157, 'trial_id': 'default', 'date': '2024-09-13_06-00-18', 'timestamp': 1726207218, 'time_this_iter_s': 7.828539609909058, 'time_total_s': 952.9759428501129, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658480d10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 952.9759428501129, 'iterations_since_restore': 157, 'perf': {'cpu_util_percent': 11.827272727272726, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.489066847165426, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.756043406895229, 'policy_loss': -0.11040548123862771, 'vf_loss': 9.862538246881394, 'vf_explained_var': -9.366444178989955e-09, 'kl': 0.015449333506937129, 'entropy': -0.30552402280625846, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 33075.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 158000, 'num_env_steps_trained': 158000, 'num_agent_steps_sampled': 158000, 'num_agent_steps_trained': 158000}, 'sampler_results': {'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 158000, 'num_agent_steps_trained': 158000, 'num_env_steps_sampled': 158000, 'num_env_steps_trained': 158000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 183.66437378709946, 'num_env_steps_trained_throughput_per_sec': 183.66437378709946, 'timesteps_total': 158000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 158000, 'timers': {'training_iteration_time_ms': 6038.679, 'sample_time_ms': 4591.739, 'load_time_ms': 0.115, 'load_throughput': 8710911.734, 'learn_time_ms': 1446.623, 'learn_throughput': 691.265, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 158000, 'num_env_steps_trained': 158000, 'num_agent_steps_sampled': 158000, 'num_agent_steps_trained': 158000}, 'done': False, 'episodes_total': 34, 'training_iteration': 158, 'trial_id': 'default', 'date': '2024-09-13_06-00-24', 'timestamp': 1726207224, 'time_this_iter_s': 5.444899797439575, 'time_total_s': 958.4208426475525, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658486090>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 958.4208426475525, 'iterations_since_restore': 158, 'perf': {'cpu_util_percent': 10.95, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.386988788559323, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.778422355651855, 'policy_loss': -0.08560621834227017, 'vf_loss': 9.861915928976876, 'vf_explained_var': -3.6898113432384674e-09, 'kl': 0.008346125179447213, 'entropy': -0.3185529115654173, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 33285.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 159000, 'num_env_steps_trained': 159000, 'num_agent_steps_sampled': 159000, 'num_agent_steps_trained': 159000}, 'sampler_results': {'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 159000, 'num_agent_steps_trained': 159000, 'num_env_steps_sampled': 159000, 'num_env_steps_trained': 159000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.5673191330056, 'num_env_steps_trained_throughput_per_sec': 180.5673191330056, 'timesteps_total': 159000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 159000, 'timers': {'training_iteration_time_ms': 6007.801, 'sample_time_ms': 4559.252, 'load_time_ms': 0.114, 'load_throughput': 8736313.268, 'learn_time_ms': 1448.23, 'learn_throughput': 690.498, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 159000, 'num_env_steps_trained': 159000, 'num_agent_steps_sampled': 159000, 'num_agent_steps_trained': 159000}, 'done': False, 'episodes_total': 34, 'training_iteration': 159, 'trial_id': 'default', 'date': '2024-09-13_06-00-29', 'timestamp': 1726207229, 'time_this_iter_s': 5.538293123245239, 'time_total_s': 963.9591357707977, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658433690>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 963.9591357707977, 'iterations_since_restore': 159, 'perf': {'cpu_util_percent': 12.4, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.133081936836243, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.796291255950928, 'policy_loss': -0.0754211100084441, 'vf_loss': 9.868217568170456, 'vf_explained_var': -7.379622686476935e-09, 'kl': 0.013806644032211764, 'entropy': -0.44126548511641367, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 33495.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000}, 'sampler_results': {'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000, 'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.95252476052707, 'num_env_steps_trained_throughput_per_sec': 180.95252476052707, 'timesteps_total': 160000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 160000, 'timers': {'training_iteration_time_ms': 5992.76, 'sample_time_ms': 4543.376, 'load_time_ms': 0.114, 'load_throughput': 8747245.047, 'learn_time_ms': 1449.066, 'learn_throughput': 690.1, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000}, 'done': False, 'episodes_total': 34, 'training_iteration': 160, 'trial_id': 'default', 'date': '2024-09-13_06-00-35', 'timestamp': 1726207235, 'time_this_iter_s': 5.526525020599365, 'time_total_s': 969.4856607913971, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658487790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 969.4856607913971, 'iterations_since_restore': 160, 'perf': {'cpu_util_percent': 11.8625, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.305516495023455, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.797505682990664, 'policy_loss': -0.06302684013332639, 'vf_loss': 9.85748715627761, 'vf_explained_var': -9.934107462565104e-09, 'kl': 0.012030782136328896, 'entropy': -0.4675004835639681, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 33705.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 161000, 'num_env_steps_trained': 161000, 'num_agent_steps_sampled': 161000, 'num_agent_steps_trained': 161000}, 'sampler_results': {'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3003.1112230902763, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1423.5606892124943, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15809874240199492, 'mean_inference_ms': 0.9523829233772655, 'mean_action_processing_ms': 0.13863912427663583, 'mean_env_wait_ms': 3.4440266351938975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 161000, 'num_agent_steps_trained': 161000, 'num_env_steps_sampled': 161000, 'num_env_steps_trained': 161000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 177.1996566276719, 'num_env_steps_trained_throughput_per_sec': 177.1996566276719, 'timesteps_total': 161000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 161000, 'timers': {'training_iteration_time_ms': 5989.013, 'sample_time_ms': 4537.556, 'load_time_ms': 0.115, 'load_throughput': 8732675.411, 'learn_time_ms': 1451.141, 'learn_throughput': 689.113, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 161000, 'num_env_steps_trained': 161000, 'num_agent_steps_sampled': 161000, 'num_agent_steps_trained': 161000}, 'done': False, 'episodes_total': 34, 'training_iteration': 161, 'trial_id': 'default', 'date': '2024-09-13_06-00-41', 'timestamp': 1726207241, 'time_this_iter_s': 5.643527984619141, 'time_total_s': 975.1291887760162, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6584868d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 975.1291887760162, 'iterations_since_restore': 161, 'perf': {'cpu_util_percent': 12.0375, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.724045627457755, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.711654000055223, 'policy_loss': -0.11609724799082392, 'vf_loss': 9.825821799323672, 'vf_explained_var': -9.65027582077753e-09, 'kl': 0.007622666111066374, 'entropy': -0.47753896613915764, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 33915.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 162000, 'num_env_steps_trained': 162000, 'num_agent_steps_sampled': 162000, 'num_agent_steps_trained': 162000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 162000, 'num_agent_steps_trained': 162000, 'num_env_steps_sampled': 162000, 'num_env_steps_trained': 162000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 125.75626687947138, 'num_env_steps_trained_throughput_per_sec': 125.75626687947138, 'timesteps_total': 162000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 162000, 'timers': {'training_iteration_time_ms': 6227.478, 'sample_time_ms': 4774.561, 'load_time_ms': 0.114, 'load_throughput': 8761863.38, 'learn_time_ms': 1452.602, 'learn_throughput': 688.42, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 162000, 'num_env_steps_trained': 162000, 'num_agent_steps_sampled': 162000, 'num_agent_steps_trained': 162000}, 'done': False, 'episodes_total': 35, 'training_iteration': 162, 'trial_id': 'default', 'date': '2024-09-13_06-00-48', 'timestamp': 1726207248, 'time_this_iter_s': 7.952078104019165, 'time_total_s': 983.0812668800354, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65960fcd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 983.0812668800354, 'iterations_since_restore': 162, 'perf': {'cpu_util_percent': 11.0, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.951422835531689, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.848880740574428, 'policy_loss': -0.02563608785470327, 'vf_loss': 9.871874922797794, 'vf_explained_var': -5.3928011939639136e-09, 'kl': 0.010437109380395155, 'entropy': -0.6318372891062782, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 34125.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 163000, 'num_env_steps_trained': 163000, 'num_agent_steps_sampled': 163000, 'num_agent_steps_trained': 163000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 163000, 'num_agent_steps_trained': 163000, 'num_env_steps_sampled': 163000, 'num_env_steps_trained': 163000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.80502755007674, 'num_env_steps_trained_throughput_per_sec': 180.80502755007674, 'timesteps_total': 163000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 163000, 'timers': {'training_iteration_time_ms': 6002.598, 'sample_time_ms': 4549.419, 'load_time_ms': 0.114, 'load_throughput': 8760033.417, 'learn_time_ms': 1452.864, 'learn_throughput': 688.296, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 163000, 'num_env_steps_trained': 163000, 'num_agent_steps_sampled': 163000, 'num_agent_steps_trained': 163000}, 'done': False, 'episodes_total': 35, 'training_iteration': 163, 'trial_id': 'default', 'date': '2024-09-13_06-00-54', 'timestamp': 1726207254, 'time_this_iter_s': 5.5309975147247314, 'time_total_s': 988.6122643947601, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658486090>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 988.6122643947601, 'iterations_since_restore': 163, 'perf': {'cpu_util_percent': 11.9, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.010642702238901, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.838519164494105, 'policy_loss': -0.048568415269255635, 'vf_loss': 9.884217012496222, 'vf_explained_var': -2.2990362984793528e-08, 'kl': 0.01134092420771991, 'entropy': -0.6628825806436085, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 34335.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 164000, 'num_env_steps_trained': 164000, 'num_agent_steps_sampled': 164000, 'num_agent_steps_trained': 164000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 164000, 'num_agent_steps_trained': 164000, 'num_env_steps_sampled': 164000, 'num_env_steps_trained': 164000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 183.59232536400208, 'num_env_steps_trained_throughput_per_sec': 183.59232536400208, 'timesteps_total': 164000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 164000, 'timers': {'training_iteration_time_ms': 5993.756, 'sample_time_ms': 4539.514, 'load_time_ms': 0.114, 'load_throughput': 8756375.783, 'learn_time_ms': 1453.927, 'learn_throughput': 687.792, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 164000, 'num_env_steps_trained': 164000, 'num_agent_steps_sampled': 164000, 'num_agent_steps_trained': 164000}, 'done': False, 'episodes_total': 35, 'training_iteration': 164, 'trial_id': 'default', 'date': '2024-09-13_06-00-59', 'timestamp': 1726207259, 'time_this_iter_s': 5.447026252746582, 'time_total_s': 994.0592906475067, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab7add0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 994.0592906475067, 'iterations_since_restore': 164, 'perf': {'cpu_util_percent': 11.899999999999999, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.657906855288006, 'cur_kl_coeff': 0.253125, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.909988707587832, 'policy_loss': 0.018141749359312512, 'vf_loss': 9.89080528077625, 'vf_explained_var': -2.2422699701218378e-08, 'kl': 0.0041152382810348545, 'entropy': -0.5945158657573518, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 34545.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1469.3175827579357, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1581321698991148, 'mean_inference_ms': 0.9524191507111766, 'mean_action_processing_ms': 0.13864619295473074, 'mean_env_wait_ms': 3.4421575103265996, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000, 'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 178.41380103002894, 'num_env_steps_trained_throughput_per_sec': 178.41380103002894, 'timesteps_total': 165000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 165000, 'timers': {'training_iteration_time_ms': 6003.157, 'sample_time_ms': 4545.065, 'load_time_ms': 0.114, 'load_throughput': 8780205.15, 'learn_time_ms': 1457.776, 'learn_throughput': 685.976, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000}, 'done': False, 'episodes_total': 35, 'training_iteration': 165, 'trial_id': 'default', 'date': '2024-09-13_06-01-05', 'timestamp': 1726207265, 'time_this_iter_s': 5.605123281478882, 'time_total_s': 999.6644139289856, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597685d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 999.6644139289856, 'iterations_since_restore': 165, 'perf': {'cpu_util_percent': 12.275, 'ram_util_percent': 12.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.2883884089333675, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.708431720733643, 'policy_loss': 0.01184217401647142, 'vf_loss': 9.694528448014033, 'vf_explained_var': -1.1920928955078126e-08, 'kl': 0.016285239633899298, 'entropy': -0.7215808766228812, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 34755.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 166000, 'num_env_steps_trained': 166000, 'num_agent_steps_sampled': 166000, 'num_agent_steps_trained': 166000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 166000, 'num_agent_steps_trained': 166000, 'num_env_steps_sampled': 166000, 'num_env_steps_trained': 166000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 125.1098173693114, 'num_env_steps_trained_throughput_per_sec': 125.1098173693114, 'timesteps_total': 166000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 166000, 'timers': {'training_iteration_time_ms': 6250.822, 'sample_time_ms': 4800.267, 'load_time_ms': 0.114, 'load_throughput': 8807862.243, 'learn_time_ms': 1450.243, 'learn_throughput': 689.54, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 166000, 'num_env_steps_trained': 166000, 'num_agent_steps_sampled': 166000, 'num_agent_steps_trained': 166000}, 'done': False, 'episodes_total': 36, 'training_iteration': 166, 'trial_id': 'default', 'date': '2024-09-13_06-01-13', 'timestamp': 1726207273, 'time_this_iter_s': 7.993172645568848, 'time_total_s': 1007.6575865745544, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6584302d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1007.6575865745544, 'iterations_since_restore': 166, 'perf': {'cpu_util_percent': 11.590909090909092, 'ram_util_percent': 12.80909090909091}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.619560976255508, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.877249844868977, 'policy_loss': 0.02458732390687579, 'vf_loss': 9.850997002919515, 'vf_explained_var': -8.231117611839658e-09, 'kl': 0.013159955955121849, 'entropy': -0.6203285208770207, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 34965.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 167000, 'num_env_steps_trained': 167000, 'num_agent_steps_sampled': 167000, 'num_agent_steps_trained': 167000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 167000, 'num_agent_steps_trained': 167000, 'num_env_steps_sampled': 167000, 'num_env_steps_trained': 167000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 185.42812135050502, 'num_env_steps_trained_throughput_per_sec': 185.42812135050502, 'timesteps_total': 167000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 167000, 'timers': {'training_iteration_time_ms': 6007.279, 'sample_time_ms': 4545.926, 'load_time_ms': 0.114, 'load_throughput': 8760033.417, 'learn_time_ms': 1461.042, 'learn_throughput': 684.443, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 167000, 'num_env_steps_trained': 167000, 'num_agent_steps_sampled': 167000, 'num_agent_steps_trained': 167000}, 'done': False, 'episodes_total': 36, 'training_iteration': 167, 'trial_id': 'default', 'date': '2024-09-13_06-01-19', 'timestamp': 1726207279, 'time_this_iter_s': 5.393107891082764, 'time_total_s': 1013.0506944656372, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c670e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1013.0506944656372, 'iterations_since_restore': 167, 'perf': {'cpu_util_percent': 11.175, 'ram_util_percent': 12.825000000000001}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.729726983252026, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.90695371173677, 'policy_loss': 0.049748555109614415, 'vf_loss': 9.855777790432885, 'vf_explained_var': -2.8383164178757443e-10, 'kl': 0.01127821917755146, 'entropy': -0.4726379428591047, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 35175.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 168000, 'num_env_steps_trained': 168000, 'num_agent_steps_sampled': 168000, 'num_agent_steps_trained': 168000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 168000, 'num_agent_steps_trained': 168000, 'num_env_steps_sampled': 168000, 'num_env_steps_trained': 168000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.15990459519213, 'num_env_steps_trained_throughput_per_sec': 180.15990459519213, 'timesteps_total': 168000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 168000, 'timers': {'training_iteration_time_ms': 6017.87, 'sample_time_ms': 4556.78, 'load_time_ms': 0.113, 'load_throughput': 8828255.104, 'learn_time_ms': 1460.781, 'learn_throughput': 684.565, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 168000, 'num_env_steps_trained': 168000, 'num_agent_steps_sampled': 168000, 'num_agent_steps_trained': 168000}, 'done': False, 'episodes_total': 36, 'training_iteration': 168, 'trial_id': 'default', 'date': '2024-09-13_06-01-24', 'timestamp': 1726207284, 'time_this_iter_s': 5.550798416137695, 'time_total_s': 1018.6014928817749, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab831d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1018.6014928817749, 'iterations_since_restore': 168, 'perf': {'cpu_util_percent': 12.2625, 'ram_util_percent': 12.875}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.92696784564427, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.891425387064617, 'policy_loss': 0.030056526015202204, 'vf_loss': 9.859939543406169, 'vf_explained_var': -8.514949253627232e-10, 'kl': 0.011293094462442761, 'entropy': -0.4321614029861632, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 35385.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 169000, 'num_env_steps_trained': 169000, 'num_agent_steps_sampled': 169000, 'num_agent_steps_trained': 169000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 169000, 'num_agent_steps_trained': 169000, 'num_env_steps_sampled': 169000, 'num_env_steps_trained': 169000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.4706851765464, 'num_env_steps_trained_throughput_per_sec': 181.4706851765464, 'timesteps_total': 169000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 169000, 'timers': {'training_iteration_time_ms': 6015.113, 'sample_time_ms': 4553.74, 'load_time_ms': 0.113, 'load_throughput': 8867450.317, 'learn_time_ms': 1461.066, 'learn_throughput': 684.432, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 169000, 'num_env_steps_trained': 169000, 'num_agent_steps_sampled': 169000, 'num_agent_steps_trained': 169000}, 'done': False, 'episodes_total': 36, 'training_iteration': 169, 'trial_id': 'default', 'date': '2024-09-13_06-01-30', 'timestamp': 1726207290, 'time_this_iter_s': 5.510716676712036, 'time_total_s': 1024.112209558487, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65848abd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1024.112209558487, 'iterations_since_restore': 169, 'perf': {'cpu_util_percent': 12.5875, 'ram_util_percent': 12.8625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.605821540242149, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.899629343123664, 'policy_loss': 0.01398624905518123, 'vf_loss': 9.884494163876488, 'vf_explained_var': -2.128737313406808e-08, 'kl': 0.009078069136982541, 'entropy': -0.3086617156153634, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 35595.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1512.0498719816978, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15816534579036584, 'mean_inference_ms': 0.9524697601517454, 'mean_action_processing_ms': 0.138653858814718, 'mean_env_wait_ms': 3.440412205558084, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000, 'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.0271176145135, 'num_env_steps_trained_throughput_per_sec': 181.0271176145135, 'timesteps_total': 170000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 170000, 'timers': {'training_iteration_time_ms': 6014.885, 'sample_time_ms': 4553.557, 'load_time_ms': 0.113, 'load_throughput': 8867450.317, 'learn_time_ms': 1461.018, 'learn_throughput': 684.454, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000}, 'done': False, 'episodes_total': 36, 'training_iteration': 170, 'trial_id': 'default', 'date': '2024-09-13_06-01-35', 'timestamp': 1726207295, 'time_this_iter_s': 5.524230718612671, 'time_total_s': 1029.6364402770996, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab800d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1029.6364402770996, 'iterations_since_restore': 170, 'perf': {'cpu_util_percent': 11.8, 'ram_util_percent': 12.8625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.1824037574586415, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.705531747000558, 'policy_loss': -0.11465039980553446, 'vf_loss': 9.818817710876464, 'vf_explained_var': -2.5544847760881697e-09, 'kl': 0.010780604307988792, 'entropy': -0.29785131428922923, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 35805.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 171000, 'num_env_steps_trained': 171000, 'num_agent_steps_sampled': 171000, 'num_agent_steps_trained': 171000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 171000, 'num_agent_steps_trained': 171000, 'num_env_steps_sampled': 171000, 'num_env_steps_trained': 171000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 126.06762355497494, 'num_env_steps_trained_throughput_per_sec': 126.06762355497494, 'timesteps_total': 171000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 171000, 'timers': {'training_iteration_time_ms': 6243.775, 'sample_time_ms': 4783.88, 'load_time_ms': 0.113, 'load_throughput': 8837555.836, 'learn_time_ms': 1459.585, 'learn_throughput': 685.126, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 171000, 'num_env_steps_trained': 171000, 'num_agent_steps_sampled': 171000, 'num_agent_steps_trained': 171000}, 'done': False, 'episodes_total': 37, 'training_iteration': 171, 'trial_id': 'default', 'date': '2024-09-13_06-01-43', 'timestamp': 1726207303, 'time_this_iter_s': 7.932443618774414, 'time_total_s': 1037.568883895874, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c670e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1037.568883895874, 'iterations_since_restore': 171, 'perf': {'cpu_util_percent': 11.545454545454545, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.5024093241918655, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.800892125992547, 'policy_loss': -0.0579141602629707, 'vf_loss': 9.856962308429537, 'vf_explained_var': -1.0785602387927827e-08, 'kl': 0.014569435590930928, 'entropy': -0.3149348742905117, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 36015.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 172000, 'num_env_steps_trained': 172000, 'num_agent_steps_sampled': 172000, 'num_agent_steps_trained': 172000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 172000, 'num_agent_steps_trained': 172000, 'num_env_steps_sampled': 172000, 'num_env_steps_trained': 172000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.60395544805266, 'num_env_steps_trained_throughput_per_sec': 180.60395544805266, 'timesteps_total': 172000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 172000, 'timers': {'training_iteration_time_ms': 6002.283, 'sample_time_ms': 4541.939, 'load_time_ms': 0.113, 'load_throughput': 8846876.186, 'learn_time_ms': 1460.031, 'learn_throughput': 684.917, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 172000, 'num_env_steps_trained': 172000, 'num_agent_steps_sampled': 172000, 'num_agent_steps_trained': 172000}, 'done': False, 'episodes_total': 37, 'training_iteration': 172, 'trial_id': 'default', 'date': '2024-09-13_06-01-49', 'timestamp': 1726207309, 'time_this_iter_s': 5.537203788757324, 'time_total_s': 1043.1060876846313, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659598450>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1043.1060876846313, 'iterations_since_restore': 172, 'perf': {'cpu_util_percent': 12.1625, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.004519686812446, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.75842984971546, 'policy_loss': -0.10431268314520518, 'vf_loss': 9.861141536349342, 'vf_explained_var': 5.108969552176339e-09, 'kl': 0.012650125186025632, 'entropy': -0.39649552475838434, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 36225.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 173000, 'num_env_steps_trained': 173000, 'num_agent_steps_sampled': 173000, 'num_agent_steps_trained': 173000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 173000, 'num_agent_steps_trained': 173000, 'num_env_steps_sampled': 173000, 'num_env_steps_trained': 173000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 179.55987815129575, 'num_env_steps_trained_throughput_per_sec': 179.55987815129575, 'timesteps_total': 173000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 173000, 'timers': {'training_iteration_time_ms': 6006.119, 'sample_time_ms': 4542.309, 'load_time_ms': 0.113, 'load_throughput': 8858086.589, 'learn_time_ms': 1463.496, 'learn_throughput': 683.296, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 173000, 'num_env_steps_trained': 173000, 'num_agent_steps_sampled': 173000, 'num_agent_steps_trained': 173000}, 'done': False, 'episodes_total': 37, 'training_iteration': 173, 'trial_id': 'default', 'date': '2024-09-13_06-01-54', 'timestamp': 1726207314, 'time_this_iter_s': 5.569350242614746, 'time_total_s': 1048.675437927246, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659555350>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1048.675437927246, 'iterations_since_restore': 173, 'perf': {'cpu_util_percent': 11.950000000000001, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.462007780869802, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.751954164959136, 'policy_loss': -0.11526966804549807, 'vf_loss': 9.865164988381522, 'vf_explained_var': -8.514949253627232e-09, 'kl': 0.016267461571121765, 'entropy': -0.533554094178336, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 36435.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 174000, 'num_env_steps_trained': 174000, 'num_agent_steps_sampled': 174000, 'num_agent_steps_trained': 174000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 174000, 'num_agent_steps_trained': 174000, 'num_env_steps_sampled': 174000, 'num_env_steps_trained': 174000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.6776117978105, 'num_env_steps_trained_throughput_per_sec': 181.6776117978105, 'timesteps_total': 174000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 174000, 'timers': {'training_iteration_time_ms': 6011.859, 'sample_time_ms': 4545.312, 'load_time_ms': 0.115, 'load_throughput': 8685657.486, 'learn_time_ms': 1466.231, 'learn_throughput': 682.021, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 174000, 'num_env_steps_trained': 174000, 'num_agent_steps_sampled': 174000, 'num_agent_steps_trained': 174000}, 'done': False, 'episodes_total': 37, 'training_iteration': 174, 'trial_id': 'default', 'date': '2024-09-13_06-02-00', 'timestamp': 1726207320, 'time_this_iter_s': 5.504441499710083, 'time_total_s': 1054.1798794269562, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea4850>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1054.1798794269562, 'iterations_since_restore': 174, 'perf': {'cpu_util_percent': 12.175, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.874855311711629, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.736606793176561, 'policy_loss': -0.12646503235612597, 'vf_loss': 9.8606109891619, 'vf_explained_var': -1.1920928955078126e-08, 'kl': 0.019443219036509838, 'entropy': -0.6572580476601918, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 36645.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000}, 'sampler_results': {'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3025.05196330295, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1551.197854532657, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15819437739073633, 'mean_inference_ms': 0.9525142972241982, 'mean_action_processing_ms': 0.13865909575769467, 'mean_env_wait_ms': 3.4386749784786748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000, 'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 182.5733604204855, 'num_env_steps_trained_throughput_per_sec': 182.5733604204855, 'timesteps_total': 175000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 175000, 'timers': {'training_iteration_time_ms': 5999.089, 'sample_time_ms': 4532.653, 'load_time_ms': 0.115, 'load_throughput': 8716342.477, 'learn_time_ms': 1466.12, 'learn_throughput': 682.072, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000}, 'done': False, 'episodes_total': 37, 'training_iteration': 175, 'trial_id': 'default', 'date': '2024-09-13_06-02-05', 'timestamp': 1726207325, 'time_this_iter_s': 5.477426528930664, 'time_total_s': 1059.6573059558868, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65848b510>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1059.6573059558868, 'iterations_since_restore': 175, 'perf': {'cpu_util_percent': 11.975, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.325191070919945, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.648947897411528, 'policy_loss': -0.1611036496148223, 'vf_loss': 9.80863216036842, 'vf_explained_var': -3.973642985026042e-09, 'kl': 0.01121483535236974, 'entropy': -0.6719805921827043, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 36855.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 176000, 'num_env_steps_trained': 176000, 'num_agent_steps_sampled': 176000, 'num_agent_steps_trained': 176000}, 'sampler_results': {'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 176000, 'num_agent_steps_trained': 176000, 'num_env_steps_sampled': 176000, 'num_env_steps_trained': 176000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.67829496017177, 'num_env_steps_trained_throughput_per_sec': 127.67829496017177, 'timesteps_total': 176000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 176000, 'timers': {'training_iteration_time_ms': 5983.01, 'sample_time_ms': 4506.458, 'load_time_ms': 0.115, 'load_throughput': 8716342.477, 'learn_time_ms': 1476.235, 'learn_throughput': 677.399, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 176000, 'num_env_steps_trained': 176000, 'num_agent_steps_sampled': 176000, 'num_agent_steps_trained': 176000}, 'done': False, 'episodes_total': 38, 'training_iteration': 176, 'trial_id': 'default', 'date': '2024-09-13_06-02-13', 'timestamp': 1726207333, 'time_this_iter_s': 7.832417964935303, 'time_total_s': 1067.4897239208221, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65843fcd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1067.4897239208221, 'iterations_since_restore': 176, 'perf': {'cpu_util_percent': 11.054545454545455, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.26095101038615, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.821426777612595, 'policy_loss': -0.16264545633679345, 'vf_loss': 9.982615257444836, 'vf_explained_var': -8.514949253627232e-10, 'kl': 0.011512367947545413, 'entropy': -0.7272278169790903, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 37065.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 177000, 'num_env_steps_trained': 177000, 'num_agent_steps_sampled': 177000, 'num_agent_steps_trained': 177000}, 'sampler_results': {'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 177000, 'num_agent_steps_trained': 177000, 'num_env_steps_sampled': 177000, 'num_env_steps_trained': 177000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.32429423315543, 'num_env_steps_trained_throughput_per_sec': 181.32429423315543, 'timesteps_total': 177000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 177000, 'timers': {'training_iteration_time_ms': 5995.215, 'sample_time_ms': 4517.196, 'load_time_ms': 0.116, 'load_throughput': 8646266.749, 'learn_time_ms': 1477.7, 'learn_throughput': 676.727, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 177000, 'num_env_steps_trained': 177000, 'num_agent_steps_sampled': 177000, 'num_agent_steps_trained': 177000}, 'done': False, 'episodes_total': 38, 'training_iteration': 177, 'trial_id': 'default', 'date': '2024-09-13_06-02-19', 'timestamp': 1726207339, 'time_this_iter_s': 5.515172481536865, 'time_total_s': 1073.004896402359, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c657790>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1073.004896402359, 'iterations_since_restore': 177, 'perf': {'cpu_util_percent': 12.0125, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.846146078336806, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.821610350835892, 'policy_loss': -0.15590183926480158, 'vf_loss': 9.976655796595983, 'vf_explained_var': 1.3340087164015998e-08, 'kl': 0.006766049593889804, 'entropy': -0.6647561726115999, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 37275.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 178000, 'num_env_steps_trained': 178000, 'num_agent_steps_sampled': 178000, 'num_agent_steps_trained': 178000}, 'sampler_results': {'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 178000, 'num_agent_steps_trained': 178000, 'num_env_steps_sampled': 178000, 'num_env_steps_trained': 178000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.05197862095676, 'num_env_steps_trained_throughput_per_sec': 180.05197862095676, 'timesteps_total': 178000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 178000, 'timers': {'training_iteration_time_ms': 5995.548, 'sample_time_ms': 4514.786, 'load_time_ms': 0.116, 'load_throughput': 8639143.151, 'learn_time_ms': 1480.44, 'learn_throughput': 675.475, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 178000, 'num_env_steps_trained': 178000, 'num_agent_steps_sampled': 178000, 'num_agent_steps_trained': 178000}, 'done': False, 'episodes_total': 38, 'training_iteration': 178, 'trial_id': 'default', 'date': '2024-09-13_06-02-24', 'timestamp': 1726207344, 'time_this_iter_s': 5.554135799407959, 'time_total_s': 1078.559032201767, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65c670e50>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1078.559032201767, 'iterations_since_restore': 178, 'perf': {'cpu_util_percent': 12.412500000000001, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.680216136432829, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.712296985444569, 'policy_loss': -0.16532960186402004, 'vf_loss': 9.876244072687058, 'vf_explained_var': 1.986821492513021e-09, 'kl': 0.01092333621054456, 'entropy': -0.7727400246120635, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 37485.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 179000, 'num_env_steps_trained': 179000, 'num_agent_steps_sampled': 179000, 'num_agent_steps_trained': 179000}, 'sampler_results': {'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3047.7216702256956, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1590.5800602087895, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15822037894529473, 'mean_inference_ms': 0.9525427532422435, 'mean_action_processing_ms': 0.13866181472574177, 'mean_env_wait_ms': 3.4369433094643145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 179000, 'num_agent_steps_trained': 179000, 'num_env_steps_sampled': 179000, 'num_env_steps_trained': 179000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 176.51126076213504, 'num_env_steps_trained_throughput_per_sec': 176.51126076213504, 'timesteps_total': 179000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 179000, 'timers': {'training_iteration_time_ms': 6011.031, 'sample_time_ms': 4516.113, 'load_time_ms': 0.116, 'load_throughput': 8623157.895, 'learn_time_ms': 1494.595, 'learn_throughput': 669.077, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 179000, 'num_env_steps_trained': 179000, 'num_agent_steps_sampled': 179000, 'num_agent_steps_trained': 179000}, 'done': False, 'episodes_total': 38, 'training_iteration': 179, 'trial_id': 'default', 'date': '2024-09-13_06-02-30', 'timestamp': 1726207350, 'time_this_iter_s': 5.665579080581665, 'time_total_s': 1084.2246112823486, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659763dd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1084.2246112823486, 'iterations_since_restore': 179, 'perf': {'cpu_util_percent': 12.15, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.828920320102148, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.614394355955579, 'policy_loss': -0.08577678803177106, 'vf_loss': 9.6987303234282, 'vf_explained_var': 2.5544847760881697e-09, 'kl': 0.01138410345759316, 'entropy': -0.7800110589890253, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 37695.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000}, 'sampler_results': {'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000, 'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 127.06006263964537, 'num_env_steps_trained_throughput_per_sec': 127.06006263964537, 'timesteps_total': 180000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 180000, 'timers': {'training_iteration_time_ms': 6245.657, 'sample_time_ms': 4762.909, 'load_time_ms': 0.116, 'load_throughput': 8612533.881, 'learn_time_ms': 1482.429, 'learn_throughput': 674.568, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000}, 'done': False, 'episodes_total': 39, 'training_iteration': 180, 'trial_id': 'default', 'date': '2024-09-13_06-02-38', 'timestamp': 1726207358, 'time_this_iter_s': 7.870474338531494, 'time_total_s': 1092.0950856208801, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6580649d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1092.0950856208801, 'iterations_since_restore': 180, 'perf': {'cpu_util_percent': 11.172727272727272, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.125226061684745, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.836815311795188, 'policy_loss': -0.021872228171144214, 'vf_loss': 9.85774850845337, 'vf_explained_var': -7.947285970052083e-09, 'kl': 0.0074197430033697475, 'entropy': -0.7892727088360559, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 37905.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 181000, 'num_env_steps_trained': 181000, 'num_agent_steps_sampled': 181000, 'num_agent_steps_trained': 181000}, 'sampler_results': {'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 181000, 'num_agent_steps_trained': 181000, 'num_env_steps_sampled': 181000, 'num_env_steps_trained': 181000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 181.08594646945127, 'num_env_steps_trained_throughput_per_sec': 181.08594646945127, 'timesteps_total': 181000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 181000, 'timers': {'training_iteration_time_ms': 6004.656, 'sample_time_ms': 4517.104, 'load_time_ms': 0.116, 'load_throughput': 8644484.749, 'learn_time_ms': 1487.235, 'learn_throughput': 672.389, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 181000, 'num_env_steps_trained': 181000, 'num_agent_steps_sampled': 181000, 'num_agent_steps_trained': 181000}, 'done': False, 'episodes_total': 39, 'training_iteration': 181, 'trial_id': 'default', 'date': '2024-09-13_06-02-43', 'timestamp': 1726207363, 'time_this_iter_s': 5.522413492202759, 'time_total_s': 1097.6174991130829, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab7b8d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1097.6174991130829, 'iterations_since_restore': 181, 'perf': {'cpu_util_percent': 11.7375, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.735952102570307, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.881526383899507, 'policy_loss': 0.015566966008572351, 'vf_loss': 9.864765108199347, 'vf_explained_var': -1.1353265671502977e-09, 'kl': 0.00943618338060346, 'entropy': -0.8652468329384213, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 38115.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 182000, 'num_env_steps_trained': 182000, 'num_agent_steps_sampled': 182000, 'num_agent_steps_trained': 182000}, 'sampler_results': {'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 182000, 'num_agent_steps_trained': 182000, 'num_env_steps_sampled': 182000, 'num_env_steps_trained': 182000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 180.4305852672543, 'num_env_steps_trained_throughput_per_sec': 180.4305852672543, 'timesteps_total': 182000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 182000, 'timers': {'training_iteration_time_ms': 6005.188, 'sample_time_ms': 4513.887, 'load_time_ms': 0.116, 'load_throughput': 8640922.95, 'learn_time_ms': 1490.988, 'learn_throughput': 670.696, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 182000, 'num_env_steps_trained': 182000, 'num_agent_steps_sampled': 182000, 'num_agent_steps_trained': 182000}, 'done': False, 'episodes_total': 39, 'training_iteration': 182, 'trial_id': 'default', 'date': '2024-09-13_06-02-49', 'timestamp': 1726207369, 'time_this_iter_s': 5.5424768924713135, 'time_total_s': 1103.1599760055542, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659766290>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1103.1599760055542, 'iterations_since_restore': 182, 'perf': {'cpu_util_percent': 12.225, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 10.384414376531328, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.899173173450288, 'policy_loss': 0.027686238590450513, 'vf_loss': 9.869690341041201, 'vf_explained_var': -1.8165225074404764e-08, 'kl': 0.014195298304132718, 'entropy': -0.9062270224094391, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 38325.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 183000, 'num_env_steps_trained': 183000, 'num_agent_steps_sampled': 183000, 'num_agent_steps_trained': 183000}, 'sampler_results': {'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 183000, 'num_agent_steps_trained': 183000, 'num_env_steps_sampled': 183000, 'num_env_steps_trained': 183000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 187.73583051932766, 'num_env_steps_trained_throughput_per_sec': 187.73583051932766, 'timesteps_total': 183000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 183000, 'timers': {'training_iteration_time_ms': 5980.934, 'sample_time_ms': 4508.668, 'load_time_ms': 0.116, 'load_throughput': 8626705.06, 'learn_time_ms': 1471.954, 'learn_throughput': 679.369, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 183000, 'num_env_steps_trained': 183000, 'num_agent_steps_sampled': 183000, 'num_agent_steps_trained': 183000}, 'done': False, 'episodes_total': 39, 'training_iteration': 183, 'trial_id': 'default', 'date': '2024-09-13_06-02-54', 'timestamp': 1726207374, 'time_this_iter_s': 5.32680869102478, 'time_total_s': 1108.486784696579, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab6dfd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1108.486784696579, 'iterations_since_restore': 183, 'perf': {'cpu_util_percent': 6.799999999999999, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.248101040295191, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.887772614615304, 'policy_loss': 0.02991485471526782, 'vf_loss': 9.856160331907727, 'vf_explained_var': -5.676632835751488e-09, 'kl': 0.013411588084861814, 'entropy': -0.9757961378211066, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 38535.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 184000, 'num_env_steps_trained': 184000, 'num_agent_steps_sampled': 184000, 'num_agent_steps_trained': 184000}, 'sampler_results': {'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3070.05103678385, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1628.5152134543039, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15824530732705364, 'mean_inference_ms': 0.9525719798345292, 'mean_action_processing_ms': 0.13866456977244734, 'mean_env_wait_ms': 3.4353224989035263, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 184000, 'num_agent_steps_trained': 184000, 'num_env_steps_sampled': 184000, 'num_env_steps_trained': 184000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 188.01571417729835, 'num_env_steps_trained_throughput_per_sec': 188.01571417729835, 'timesteps_total': 184000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 184000, 'timers': {'training_iteration_time_ms': 5962.379, 'sample_time_ms': 4510.163, 'load_time_ms': 0.114, 'load_throughput': 8791247.118, 'learn_time_ms': 1451.907, 'learn_throughput': 688.749, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 184000, 'num_env_steps_trained': 184000, 'num_agent_steps_sampled': 184000, 'num_agent_steps_trained': 184000}, 'done': False, 'episodes_total': 39, 'training_iteration': 184, 'trial_id': 'default', 'date': '2024-09-13_06-02-59', 'timestamp': 1726207379, 'time_this_iter_s': 5.318891763687134, 'time_total_s': 1113.805676460266, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659555850>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1113.805676460266, 'iterations_since_restore': 184, 'perf': {'cpu_util_percent': 6.157142857142857, 'ram_util_percent': 12.900000000000002}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 10.76188843817938, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.794037115006219, 'policy_loss': -0.02952572706909407, 'vf_loss': 9.82182502746582, 'vf_explained_var': 6.528127761114211e-09, 'kl': 0.013730713406888214, 'entropy': -1.044915060769944, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 38745.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000}, 'sampler_results': {'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000, 'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 131.45494056576877, 'num_env_steps_trained_throughput_per_sec': 131.45494056576877, 'timesteps_total': 185000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 185000, 'timers': {'training_iteration_time_ms': 6175.371, 'sample_time_ms': 4739.742, 'load_time_ms': 0.113, 'load_throughput': 8824540.29, 'learn_time_ms': 1435.321, 'learn_throughput': 696.708, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000}, 'done': False, 'episodes_total': 40, 'training_iteration': 185, 'trial_id': 'default', 'date': '2024-09-13_06-03-07', 'timestamp': 1726207387, 'time_this_iter_s': 7.607349395751953, 'time_total_s': 1121.413025856018, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab81110>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1121.413025856018, 'iterations_since_restore': 185, 'perf': {'cpu_util_percent': 5.927272727272728, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.049507028715951, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.889374437786284, 'policy_loss': 0.019568911904380436, 'vf_loss': 9.868664037613641, 'vf_explained_var': 1.8165225074404764e-08, 'kl': 0.00901920393211878, 'entropy': -1.0153928367864518, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 38955.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 186000, 'num_env_steps_trained': 186000, 'num_agent_steps_sampled': 186000, 'num_agent_steps_trained': 186000}, 'sampler_results': {'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 186000, 'num_agent_steps_trained': 186000, 'num_env_steps_sampled': 186000, 'num_env_steps_trained': 186000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 190.87434638579862, 'num_env_steps_trained_throughput_per_sec': 190.87434638579862, 'timesteps_total': 186000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 186000, 'timers': {'training_iteration_time_ms': 5916.058, 'sample_time_ms': 4496.393, 'load_time_ms': 0.114, 'load_throughput': 8794933.948, 'learn_time_ms': 1419.359, 'learn_throughput': 704.544, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 186000, 'num_env_steps_trained': 186000, 'num_agent_steps_sampled': 186000, 'num_agent_steps_trained': 186000}, 'done': False, 'episodes_total': 40, 'training_iteration': 186, 'trial_id': 'default', 'date': '2024-09-13_06-03-12', 'timestamp': 1726207392, 'time_this_iter_s': 5.23922324180603, 'time_total_s': 1126.652249097824, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659603bd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1126.652249097824, 'iterations_since_restore': 186, 'perf': {'cpu_util_percent': 6.475, 'ram_util_percent': 12.912500000000001}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 9.14082369236719, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.859952277228945, 'policy_loss': -0.012907224183990842, 'vf_loss': 9.87108977181571, 'vf_explained_var': 3.973642985026042e-09, 'kl': 0.013983568212210057, 'entropy': -1.1018290377798534, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 39165.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 187000, 'num_env_steps_trained': 187000, 'num_agent_steps_sampled': 187000, 'num_agent_steps_trained': 187000}, 'sampler_results': {'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 187000, 'num_agent_steps_trained': 187000, 'num_env_steps_sampled': 187000, 'num_env_steps_trained': 187000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 187.54997225185983, 'num_env_steps_trained_throughput_per_sec': 187.54997225185983, 'timesteps_total': 187000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 187000, 'timers': {'training_iteration_time_ms': 5897.751, 'sample_time_ms': 4492.479, 'load_time_ms': 0.114, 'load_throughput': 8802316.894, 'learn_time_ms': 1404.968, 'learn_throughput': 711.76, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 187000, 'num_env_steps_trained': 187000, 'num_agent_steps_sampled': 187000, 'num_agent_steps_trained': 187000}, 'done': False, 'episodes_total': 40, 'training_iteration': 187, 'trial_id': 'default', 'date': '2024-09-13_06-03-18', 'timestamp': 1726207398, 'time_this_iter_s': 5.332077741622925, 'time_total_s': 1131.984326839447, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65843d690>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1131.984326839447, 'iterations_since_restore': 187, 'perf': {'cpu_util_percent': 6.185714285714285, 'ram_util_percent': 12.900000000000002}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 10.269040477275848, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.8569639478411, 'policy_loss': -0.008849430155186426, 'vf_loss': 9.864027350289481, 'vf_explained_var': -7.379622686476935e-09, 'kl': 0.014111691453893675, 'entropy': -1.1982408137548537, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 39375.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 188000, 'num_env_steps_trained': 188000, 'num_agent_steps_sampled': 188000, 'num_agent_steps_trained': 188000}, 'sampler_results': {'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3190.8595789713595, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1667.57382259223, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1582699789843348, 'mean_inference_ms': 0.9525999601239921, 'mean_action_processing_ms': 0.13866500330203063, 'mean_env_wait_ms': 3.4336759486728816, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 188000, 'num_agent_steps_trained': 188000, 'num_env_steps_sampled': 188000, 'num_env_steps_trained': 188000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 187.36495032888118, 'num_env_steps_trained_throughput_per_sec': 187.36495032888118, 'timesteps_total': 188000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 188000, 'timers': {'training_iteration_time_ms': 5876.074, 'sample_time_ms': 4489.53, 'load_time_ms': 0.114, 'load_throughput': 8749069.67, 'learn_time_ms': 1386.239, 'learn_throughput': 721.376, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 188000, 'num_env_steps_trained': 188000, 'num_agent_steps_sampled': 188000, 'num_agent_steps_trained': 188000}, 'done': False, 'episodes_total': 40, 'training_iteration': 188, 'trial_id': 'default', 'date': '2024-09-13_06-03-23', 'timestamp': 1726207403, 'time_this_iter_s': 5.337352752685547, 'time_total_s': 1137.3216795921326, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659521350>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1137.3216795921326, 'iterations_since_restore': 188, 'perf': {'cpu_util_percent': 6.5125, 'ram_util_percent': 12.975}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.075991945039658, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.761840189070929, 'policy_loss': -0.04676848245518548, 'vf_loss': 9.807067644028436, 'vf_explained_var': -1.7029898507254463e-08, 'kl': 0.01217669649825769, 'entropy': -1.2193055499167669, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 39585.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 189000, 'num_env_steps_trained': 189000, 'num_agent_steps_sampled': 189000, 'num_agent_steps_trained': 189000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 189000, 'num_agent_steps_trained': 189000, 'num_env_steps_sampled': 189000, 'num_env_steps_trained': 189000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 131.11779698802923, 'num_env_steps_trained_throughput_per_sec': 131.11779698802923, 'timesteps_total': 189000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 189000, 'timers': {'training_iteration_time_ms': 6072.211, 'sample_time_ms': 4715.379, 'load_time_ms': 0.114, 'load_throughput': 8747245.047, 'learn_time_ms': 1356.529, 'learn_throughput': 737.176, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 189000, 'num_env_steps_trained': 189000, 'num_agent_steps_sampled': 189000, 'num_agent_steps_trained': 189000}, 'done': False, 'episodes_total': 41, 'training_iteration': 189, 'trial_id': 'default', 'date': '2024-09-13_06-03-31', 'timestamp': 1726207411, 'time_this_iter_s': 7.6269166469573975, 'time_total_s': 1144.94859623909, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6584897d0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1144.94859623909, 'iterations_since_restore': 189, 'perf': {'cpu_util_percent': 6.345454545454545, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 11.11325971285502, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.91771532240368, 'policy_loss': -0.06656041698796408, 'vf_loss': 9.983129914601644, 'vf_explained_var': -1.475924537295387e-08, 'kl': 0.009053973706752486, 'entropy': -1.262417613324665, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 39795.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000, 'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 188.45191591699856, 'num_env_steps_trained_throughput_per_sec': 188.45191591699856, 'timesteps_total': 190000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 190000, 'timers': {'training_iteration_time_ms': 5815.821, 'sample_time_ms': 4462.178, 'load_time_ms': 0.114, 'load_throughput': 8743598.082, 'learn_time_ms': 1353.338, 'learn_throughput': 738.913, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000}, 'done': False, 'episodes_total': 41, 'training_iteration': 190, 'trial_id': 'default', 'date': '2024-09-13_06-03-36', 'timestamp': 1726207416, 'time_this_iter_s': 5.306572675704956, 'time_total_s': 1150.255168914795, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb6597fbd90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1150.255168914795, 'iterations_since_restore': 190, 'perf': {'cpu_util_percent': 6.114285714285715, 'ram_util_percent': 12.900000000000002}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 9.589359882899693, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.872096524919783, 'policy_loss': -0.11168827464626659, 'vf_loss': 9.981377533503942, 'vf_explained_var': -1.873288835797991e-08, 'kl': 0.01902064558574552, 'entropy': -1.3806261232921055, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 40005.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 191000, 'num_env_steps_trained': 191000, 'num_agent_steps_sampled': 191000, 'num_agent_steps_trained': 191000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 191000, 'num_agent_steps_trained': 191000, 'num_env_steps_sampled': 191000, 'num_env_steps_trained': 191000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 194.0997669907244, 'num_env_steps_trained_throughput_per_sec': 194.0997669907244, 'timesteps_total': 191000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 191000, 'timers': {'training_iteration_time_ms': 5778.796, 'sample_time_ms': 4446.189, 'load_time_ms': 0.114, 'load_throughput': 8754548.111, 'learn_time_ms': 1332.302, 'learn_throughput': 750.58, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 191000, 'num_env_steps_trained': 191000, 'num_agent_steps_sampled': 191000, 'num_agent_steps_trained': 191000}, 'done': False, 'episodes_total': 41, 'training_iteration': 191, 'trial_id': 'default', 'date': '2024-09-13_06-03-41', 'timestamp': 1726207421, 'time_this_iter_s': 5.152161359786987, 'time_total_s': 1155.407330274582, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658485a90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1155.407330274582, 'iterations_since_restore': 191, 'perf': {'cpu_util_percent': 6.8375, 'ram_util_percent': 12.912500000000001}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 16.089158398764475, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.875265611921037, 'policy_loss': -0.10534497708791778, 'vf_loss': 9.97810781569708, 'vf_explained_var': -2.8666995820545016e-08, 'kl': 0.019775522848760694, 'entropy': -1.5545307131040664, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 40215.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 192000, 'num_env_steps_trained': 192000, 'num_agent_steps_sampled': 192000, 'num_agent_steps_trained': 192000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 192000, 'num_agent_steps_trained': 192000, 'num_env_steps_sampled': 192000, 'num_env_steps_trained': 192000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 189.96869502958523, 'num_env_steps_trained_throughput_per_sec': 189.96869502958523, 'timesteps_total': 192000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 192000, 'timers': {'training_iteration_time_ms': 5750.969, 'sample_time_ms': 4439.487, 'load_time_ms': 0.114, 'load_throughput': 8749069.67, 'learn_time_ms': 1311.179, 'learn_throughput': 762.673, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 192000, 'num_env_steps_trained': 192000, 'num_agent_steps_sampled': 192000, 'num_agent_steps_trained': 192000}, 'done': False, 'episodes_total': 41, 'training_iteration': 192, 'trial_id': 'default', 'date': '2024-09-13_06-03-46', 'timestamp': 1726207426, 'time_this_iter_s': 5.264215469360352, 'time_total_s': 1160.6715457439423, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab82e10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1160.6715457439423, 'iterations_since_restore': 192, 'perf': {'cpu_util_percent': 6.057142857142857, 'ram_util_percent': 12.914285714285715}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 11.843977857771375, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.871160139356341, 'policy_loss': -0.11519190087204888, 'vf_loss': 9.98468146551223, 'vf_explained_var': -1.419158208937872e-09, 'kl': 0.013199649344010194, 'entropy': -1.6489392558733622, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 40425.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1704.7762298822825, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15829376492268332, 'mean_inference_ms': 0.9526258611877453, 'mean_action_processing_ms': 0.1386633154871912, 'mean_env_wait_ms': 3.43208182968221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000, 'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 189.4275988743559, 'num_env_steps_trained_throughput_per_sec': 189.4275988743559, 'timesteps_total': 193000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 193000, 'timers': {'training_iteration_time_ms': 5746.211, 'sample_time_ms': 4433.212, 'load_time_ms': 0.114, 'load_throughput': 8761863.38, 'learn_time_ms': 1312.697, 'learn_throughput': 761.791, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000}, 'done': False, 'episodes_total': 41, 'training_iteration': 193, 'trial_id': 'default', 'date': '2024-09-13_06-03-52', 'timestamp': 1726207432, 'time_this_iter_s': 5.279241323471069, 'time_total_s': 1165.9507870674133, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb65847d290>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1165.9507870674133, 'iterations_since_restore': 193, 'perf': {'cpu_util_percent': 6.5875, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 10.301808968044462, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.625893188658214, 'policy_loss': -0.197488549019077, 'vf_loss': 9.822289080846877, 'vf_explained_var': -1.2204760596865699e-08, 'kl': 0.008633602770888295, 'entropy': -1.6153081451143538, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 40635.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 194000, 'num_env_steps_trained': 194000, 'num_agent_steps_sampled': 194000, 'num_agent_steps_trained': 194000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 194000, 'num_agent_steps_trained': 194000, 'num_env_steps_sampled': 194000, 'num_env_steps_trained': 194000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 131.2801200152617, 'num_env_steps_trained_throughput_per_sec': 131.2801200152617, 'timesteps_total': 194000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 194000, 'timers': {'training_iteration_time_ms': 5976.071, 'sample_time_ms': 4661.176, 'load_time_ms': 0.114, 'load_throughput': 8763694.108, 'learn_time_ms': 1314.591, 'learn_throughput': 760.693, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 194000, 'num_env_steps_trained': 194000, 'num_agent_steps_sampled': 194000, 'num_agent_steps_trained': 194000}, 'done': False, 'episodes_total': 42, 'training_iteration': 194, 'trial_id': 'default', 'date': '2024-09-13_06-03-59', 'timestamp': 1726207439, 'time_this_iter_s': 7.617485523223877, 'time_total_s': 1173.5682725906372, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659590490>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1173.5682725906372, 'iterations_since_restore': 194, 'perf': {'cpu_util_percent': 6.245454545454546, 'ram_util_percent': 12.927272727272726}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 12.393183005423772, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.752511124383835, 'policy_loss': -0.10326788865384601, 'vf_loss': 9.854107325417655, 'vf_explained_var': 1.3056255522228423e-08, 'kl': 0.01320836193405003, 'entropy': -1.5750460391952879, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 40845.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000, 'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 191.60126436705474, 'num_env_steps_trained_throughput_per_sec': 191.60126436705474, 'timesteps_total': 195000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 195000, 'timers': {'training_iteration_time_ms': 5737.271, 'sample_time_ms': 4423.145, 'load_time_ms': 0.114, 'load_throughput': 8776530.655, 'learn_time_ms': 1313.825, 'learn_throughput': 761.136, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000}, 'done': False, 'episodes_total': 42, 'training_iteration': 195, 'trial_id': 'default', 'date': '2024-09-13_06-04-05', 'timestamp': 1726207445, 'time_this_iter_s': 5.219363689422607, 'time_total_s': 1178.7876362800598, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bbea7fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1178.7876362800598, 'iterations_since_restore': 195, 'perf': {'cpu_util_percent': 6.171428571428572, 'ram_util_percent': 12.957142857142857}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 9.669449424743652, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.780315671648298, 'policy_loss': -0.09218518435955048, 'vf_loss': 9.870346482594808, 'vf_explained_var': 4.825137910388765e-09, 'kl': 0.01702243111060377, 'entropy': -1.6204094869749888, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 41055.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 196000, 'num_env_steps_trained': 196000, 'num_agent_steps_sampled': 196000, 'num_agent_steps_trained': 196000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 196000, 'num_agent_steps_trained': 196000, 'num_env_steps_sampled': 196000, 'num_env_steps_trained': 196000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 187.6913555690151, 'num_env_steps_trained_throughput_per_sec': 187.6913555690151, 'timesteps_total': 196000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 196000, 'timers': {'training_iteration_time_ms': 5746.156, 'sample_time_ms': 4432.375, 'load_time_ms': 0.116, 'load_throughput': 8653402.104, 'learn_time_ms': 1313.477, 'learn_throughput': 761.338, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 196000, 'num_env_steps_trained': 196000, 'num_agent_steps_sampled': 196000, 'num_agent_steps_trained': 196000}, 'done': False, 'episodes_total': 42, 'training_iteration': 196, 'trial_id': 'default', 'date': '2024-09-13_06-04-10', 'timestamp': 1726207450, 'time_this_iter_s': 5.328070640563965, 'time_total_s': 1184.1157069206238, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb7bab80750>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1184.1157069206238, 'iterations_since_restore': 196, 'perf': {'cpu_util_percent': 6.637499999999999, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.120643040112087, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.813244901384627, 'policy_loss': -0.04622160394986471, 'vf_loss': 9.857719130743117, 'vf_explained_var': -8.231117611839658e-09, 'kl': 0.013806720799073533, 'entropy': -1.779017374629066, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 41265.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 197000, 'num_env_steps_trained': 197000, 'num_agent_steps_sampled': 197000, 'num_agent_steps_trained': 197000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 197000, 'num_agent_steps_trained': 197000, 'num_env_steps_sampled': 197000, 'num_env_steps_trained': 197000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 185.6081285688752, 'num_env_steps_trained_throughput_per_sec': 185.6081285688752, 'timesteps_total': 197000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 197000, 'timers': {'training_iteration_time_ms': 5751.734, 'sample_time_ms': 4438.491, 'load_time_ms': 0.114, 'load_throughput': 8754548.111, 'learn_time_ms': 1312.939, 'learn_throughput': 761.65, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 197000, 'num_env_steps_trained': 197000, 'num_agent_steps_sampled': 197000, 'num_agent_steps_trained': 197000}, 'done': False, 'episodes_total': 42, 'training_iteration': 197, 'trial_id': 'default', 'date': '2024-09-13_06-04-15', 'timestamp': 1726207455, 'time_this_iter_s': 5.387875318527222, 'time_total_s': 1189.503582239151, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659521b10>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1189.503582239151, 'iterations_since_restore': 197, 'perf': {'cpu_util_percent': 5.828571428571428, 'ram_util_percent': 12.900000000000002}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 12.320760533923195, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.819714986710322, 'policy_loss': -0.04220549944078639, 'vf_loss': 9.859968830290295, 'vf_explained_var': 5.676632835751489e-10, 'kl': 0.015420091886162116, 'entropy': -1.8671000162760416, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 41475.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 198000, 'num_env_steps_trained': 198000, 'num_agent_steps_sampled': 198000, 'num_agent_steps_trained': 198000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1738.126180051773, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15831534941681516, 'mean_inference_ms': 0.952645948265548, 'mean_action_processing_ms': 0.13865893776044874, 'mean_env_wait_ms': 3.4304404737182894, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 198000, 'num_agent_steps_trained': 198000, 'num_env_steps_sampled': 198000, 'num_env_steps_trained': 198000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 188.97457858884877, 'num_env_steps_trained_throughput_per_sec': 188.97457858884877, 'timesteps_total': 198000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 198000, 'timers': {'training_iteration_time_ms': 5747.188, 'sample_time_ms': 4431.577, 'load_time_ms': 0.114, 'load_throughput': 8787563.377, 'learn_time_ms': 1315.309, 'learn_throughput': 760.277, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 198000, 'num_env_steps_trained': 198000, 'num_agent_steps_sampled': 198000, 'num_agent_steps_trained': 198000}, 'done': False, 'episodes_total': 42, 'training_iteration': 198, 'trial_id': 'default', 'date': '2024-09-13_06-04-21', 'timestamp': 1726207461, 'time_this_iter_s': 5.2918901443481445, 'time_total_s': 1194.7954723834991, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659762a90>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1194.7954723834991, 'iterations_since_restore': 198, 'perf': {'cpu_util_percent': 6.625, 'ram_util_percent': 12.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 11.678957760901678, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.624231815338135, 'policy_loss': -0.18215736062487675, 'vf_loss': 9.804188769204275, 'vf_explained_var': -1.9584383283342634e-08, 'kl': 0.017385741044390238, 'entropy': -2.008026981921423, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 41685.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 199000, 'num_env_steps_trained': 199000, 'num_agent_steps_sampled': 199000, 'num_agent_steps_trained': 199000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1770.1346224977788, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783, 3114.4892052300283], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1583355901265503, 'mean_inference_ms': 0.9526628390440903, 'mean_action_processing_ms': 0.1386527094347903, 'mean_env_wait_ms': 3.4287807332001745, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1770.1346224977788, 'episode_len_mean': 4608.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783, 3114.4892052300283], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1583355901265503, 'mean_inference_ms': 0.9526628390440903, 'mean_action_processing_ms': 0.1386527094347903, 'mean_env_wait_ms': 3.4287807332001745, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 199000, 'num_agent_steps_trained': 199000, 'num_env_steps_sampled': 199000, 'num_env_steps_trained': 199000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 131.2763562628399, 'num_env_steps_trained_throughput_per_sec': 131.2763562628399, 'timesteps_total': 199000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 199000, 'timers': {'training_iteration_time_ms': 5746.267, 'sample_time_ms': 4429.735, 'load_time_ms': 0.114, 'load_throughput': 8774694.561, 'learn_time_ms': 1316.228, 'learn_throughput': 759.747, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 199000, 'num_env_steps_trained': 199000, 'num_agent_steps_sampled': 199000, 'num_agent_steps_trained': 199000}, 'done': False, 'episodes_total': 43, 'training_iteration': 199, 'trial_id': 'default', 'date': '2024-09-13_06-04-28', 'timestamp': 1726207468, 'time_this_iter_s': 7.617710828781128, 'time_total_s': 1202.4131832122803, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb658067fd0>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1202.4131832122803, 'iterations_since_restore': 199, 'perf': {'cpu_util_percent': 6.172727272727273, 'ram_util_percent': 12.963636363636363}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 12.500660739626204, 'cur_kl_coeff': 0.1265625, 'cur_lr': 0.00010000000000000002, 'total_loss': 9.675644979022799, 'policy_loss': -0.17539089449814388, 'vf_loss': 9.849290924980528, 'vf_explained_var': -3.178914388020833e-08, 'kl': 0.013787299720674726, 'entropy': -2.049899117151896, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 41895.5, 'diff_num_grad_updates_vs_sampler_policy': 104.5}}, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000}, 'sampler_results': {'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1770.1346224977788, 'episode_len_mean': 4608.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783, 3114.4892052300283], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1583355901265503, 'mean_inference_ms': 0.9526628390440903, 'mean_action_processing_ms': 0.1386527094347903, 'mean_env_wait_ms': 3.4287807332001745, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 3192.8725214843785, 'episode_reward_min': -534.3759895182294, 'episode_reward_mean': 1770.1346224977788, 'episode_len_mean': 4608.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-375.6073166666661, -485.84682467447846, -534.3759895182294, -382.9558075086806, -362.98076304253425, -228.26136458333337, -212.97378602430524, 200.11550944010418, 337.99918446180607, 471.4494873697916, 1200.4949386284707, 1489.4856608072903, 1721.4506461588535, 1852.563946723092, 1818.9483842230914, 1517.5650389974012, 1670.5842143012112, 1522.2236118706587, 1549.6353802734395, 1707.0722633463504, 1639.777742274299, 1593.0384266710114, 1652.6552614149273, 1661.5907047309056, 1909.2917532335048, 2456.3451325737838, 2609.4243499131903, 2679.1696343966973, 2859.536118120654, 2967.751999609366, 2958.7261652343805, 2957.9553279296956, 2976.103179448776, 3003.1112230902763, 3025.05196330295, 3007.6799948133726, 2960.525226367184, 3047.7216702256956, 3070.05103678385, 3190.8595789713595, 3192.8725214843785, 3105.4741370008783, 3114.4892052300283], 'episode_lengths': [4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608, 4608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1583355901265503, 'mean_inference_ms': 0.9526628390440903, 'mean_action_processing_ms': 0.1386527094347903, 'mean_env_wait_ms': 3.4287807332001745, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 1000, 'num_env_steps_sampled_throughput_per_sec': 190.5732854974836, 'num_env_steps_trained_throughput_per_sec': 190.5732854974836, 'timesteps_total': 200000, 'num_steps_trained_this_iter': 1000, 'agent_timesteps_total': 200000, 'timers': {'training_iteration_time_ms': 5740.36, 'sample_time_ms': 4422.485, 'load_time_ms': 0.114, 'load_throughput': 8767357.86, 'learn_time_ms': 1317.569, 'learn_throughput': 758.973, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000}, 'done': False, 'episodes_total': 43, 'training_iteration': 200, 'trial_id': 'default', 'date': '2024-09-13_06-04-33', 'timestamp': 1726207473, 'time_this_iter_s': 5.247512578964233, 'time_total_s': 1207.6606957912445, 'pid': 141397, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat_0FEAST': Box(22.0, 30.0, (), float32), 'thermostat_0FWEST': Box(22.0, 30.0, (), float32), 'thermostat_1FEAST': Box(22.0, 30.0, (), float32), 'thermostat_1FWEST': Box(22.0, 30.0, (), float32)), 'observation_space': Dict('AHU COOLING COIL': Box(-inf, inf, (), float32), 'Fan Electricity Rate': Box(-inf, inf, (), float32), 'Office Occupancy': Box(-inf, inf, (), float32), 'humidity_0FEAST': Box(-inf, inf, (), float32), 'humidity_0FWEST': Box(-inf, inf, (), float32), 'humidity_1FEAST': Box(-inf, inf, (), float32), 'humidity_1FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_0FWEST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FEAST': Box(-inf, inf, (), float32), 'temperature:drybulb_1FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_0FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_0FWEST': Box(-inf, inf, (), float32), 'temperature:radiant_1FEAST': Box(-inf, inf, (), float32), 'temperature:radiant_1FWEST': Box(-inf, inf, (), float32)), 'reward_function': <__main__.RewardFunction object at 0x7fb659521350>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}, 'system': <function <lambda> at 0x7fb65c7ad940>}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0001, 'lr_schedule': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 1000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fb65cb63f60>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 1207.6606957912445, 'iterations_since_restore': 200, 'perf': {'cpu_util_percent': 6.285714285714286, 'ram_util_percent': 12.985714285714286}}\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    global algo\n",
    "    for _ in range(200):\n",
    "        print(algo.train())\n",
    "\n",
    "import asyncio\n",
    "async def run_train():\n",
    "    asyncio.get_running_loop().run_in_executor(None, train)\n",
    "\n",
    "await asyncio.create_task(run_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thermostat_1FWEST': array(27.501886, dtype=float32),\n",
       " 'thermostat_1FEAST': array(22., dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.workers.local_worker().env.action.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c\n",
    "\n",
    "# varlogger.plot({\n",
    "#     'traces': [\n",
    "#         dict(\n",
    "#             x='wallclock:calendar', \n",
    "#             y=Actuator.Ref(\n",
    "#                 type='Fan',\n",
    "#                 control_type='Fan Air Mass Flow Rate',\n",
    "#                 key='AIR LOOP AHU SUPPLY FAN',\n",
    "#             ),\n",
    "#         ),        \n",
    "#     ],\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varlogger.track('clock',\n",
    "#     'wallclock:calendar'\n",
    "# )\n",
    "\n",
    "varlogger.track('Fan Air Mass Flow Rate', Actuator.Ref(\n",
    "    type='Fan',\n",
    "    control_type='Fan Air Mass Flow Rate',\n",
    "    key='AIR LOOP AHU SUPPLY FAN',\n",
    "),\n",
    ")\n",
    "\n",
    "varlogger.track('thermostat_1FEAST',Actuator.Ref(\n",
    "    type='Schedule:Compact',\n",
    "    control_type='Schedule Value',\n",
    "    key='1FFIRSTFLOOREAST:OPENOFFICE',\n",
    ")\n",
    ")\n",
    "\n",
    "varlogger.track('thermostat_1FWEST',Actuator.Ref(\n",
    "    type='Schedule:Compact',\n",
    "    control_type='Schedule Value',\n",
    "    key='1FFIRSTFLOORWEST:OPENOFFICE COOLING SETPOINT SCHEDULE',\n",
    ")\n",
    ")\n",
    "\n",
    "varlogger.track('Zone Mean Air Temperature',OutputVariable.Ref(\n",
    "    type='Zone Mean Air Temperature',\n",
    "    key='1FFIRSTFLOORWEST:OPENOFFICE',\n",
    ")\n",
    ")\n",
    "\n",
    "varlogger.track(OutputVariable.Ref(\n",
    "    type='Zone Air Relative Humidity',\n",
    "    key='1FFIRSTFLOORWEST:OPENOFFICE',\n",
    ")\n",
    ")\n",
    "\n",
    "varlogger.track('Zone Mean Radiant Temperature',OutputVariable.Ref(\n",
    "    type='Zone Mean Radiant Temperature',\n",
    "    key='1FFIRSTFLOORWEST:OPENOFFICE',\n",
    ")\n",
    ")\n",
    "\n",
    "varlogger.track('Cooling Coil Total Cooling Rate',OutputVariable.Ref(\n",
    "    type='Cooling Coil Total Cooling Rate',\n",
    "    key='AIR LOOP AHU COOLING COIL',\n",
    ")\n",
    ")\n",
    "\n",
    "varlogger.track('Fan Electricity Rate',OutputVariable.Ref(\n",
    "    type='Fan Electricity Rate',\n",
    "    key='AIR LOOP AHU SUPPLY FAN',\n",
    ")\n",
    ")\n",
    "\n",
    "varlogger.track('Office Occupancy',OutputVariable.Ref(\n",
    "    type='Schedule Value',\n",
    "    key='Office_OpenOff_Occ',\n",
    ")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fan Air Mass Flow Rate': History.Record(ref=Actuator.Ref(type='Fan', control_type='Fan Air Mass Flow Rate', key='AIR LOOP AHU SUPPLY FAN'), values=deque([0.0], maxlen=10000)),\n",
       " 'thermostat_1FEAST': History.Record(ref=Actuator.Ref(type='Schedule:Compact', control_type='Schedule Value', key='1FFIRSTFLOOREAST:OPENOFFICE'), values=deque([], maxlen=10000)),\n",
       " 'thermostat_1FWEST': History.Record(ref=Actuator.Ref(type='Schedule:Compact', control_type='Schedule Value', key='1FFIRSTFLOORWEST:OPENOFFICE COOLING SETPOINT SCHEDULE'), values=deque([], maxlen=10000)),\n",
       " 'Zone Mean Air Temperature': History.Record(ref=OutputVariable.Ref(type='Zone Mean Air Temperature', key='1FFIRSTFLOORWEST:OPENOFFICE'), values=deque([], maxlen=10000)),\n",
       " OutputVariable.Ref(type='Zone Air Relative Humidity', key='1FFIRSTFLOORWEST:OPENOFFICE'): History.Record(ref=OutputVariable.Ref(type='Zone Air Relative Humidity', key='1FFIRSTFLOORWEST:OPENOFFICE'), values=deque([], maxlen=10000)),\n",
       " 'Zone Mean Radiant Temperature': History.Record(ref=OutputVariable.Ref(type='Zone Mean Radiant Temperature', key='1FFIRSTFLOORWEST:OPENOFFICE'), values=deque([], maxlen=10000)),\n",
       " 'Cooling Coil Total Cooling Rate': History.Record(ref=OutputVariable.Ref(type='Cooling Coil Total Cooling Rate', key='AIR LOOP AHU COOLING COIL'), values=deque([], maxlen=10000)),\n",
       " 'Fan Electricity Rate': History.Record(ref=OutputVariable.Ref(type='Fan Electricity Rate', key='AIR LOOP AHU SUPPLY FAN'), values=deque([], maxlen=10000)),\n",
       " 'Office Occupancy': History.Record(ref=OutputVariable.Ref(type='Schedule Value', key='Office_OpenOff_Occ'), values=deque([], maxlen=10000))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varlogger._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319f7e57a43e4627a8d3e56c804bd75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<energyplus.ooep.specs.tools.history.History.Plot at 0x7f7bb0d77650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varlogger.plot({\n",
    "    'traces': [\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='Fan Air Mass Flow Rate',\n",
    "        ),\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='thermostat_1FEAST',\n",
    "        ),\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='thermostat_1FWEST',\n",
    "        ),\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='Zone Mean Air Temperature',\n",
    "        ),\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='Zone Mean Radiant Temperature',\n",
    "        ),\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='Cooling Coil Total Cooling Rate',\n",
    "        ),\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='Fan Electricity Rate',\n",
    "        ),\n",
    "        dict(\n",
    "            x='clock', \n",
    "            y='Office Occupancy',\n",
    "        ),\n",
    "    ],\n",
    "}, autoupdate=1_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitables\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_itables_\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mvarlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m _itables_\u001b[38;5;241m.\u001b[39mshow(df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# df.to_csv('datasave/data.csv', index=False, sep=';')\u001b[39;00m\n",
      "File \u001b[0;32m~/lab/reports/apr01/.venv/lib/python3.11/site-packages/energyplus/ooep/specs/tools/history.py:209\u001b[0m, in \u001b[0;36mHistory.DataFrameConstructor.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_pandas_\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pandas_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lab/reports/apr01/.venv/lib/python3.11/site-packages/pandas/core/frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    763\u001b[0m     )\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/lab/reports/apr01/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lab/reports/apr01/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/lab/reports/apr01/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import itables as _itables_\n",
    "df = varlogger.dataframe()\n",
    "_itables_.show(df)\n",
    "# df.to_csv('datasave/data.csv', index=False, sep=';')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
